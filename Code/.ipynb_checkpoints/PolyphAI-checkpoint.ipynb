{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d361ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary imports\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from music21 import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c67e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "folder_path = 'Data/'\n",
    "test = []\n",
    "train = []\n",
    "validation = []\n",
    "for dirname in os.listdir(folder_path):\n",
    "    if dirname != '.DS_Store':\n",
    "        for filename in os.listdir(folder_path + dirname):\n",
    "            df = pd.read_csv(folder_path + dirname + '/' + filename)\n",
    "            transposed_df = df.transpose()\n",
    "            if dirname == 'test':\n",
    "                test.append(transposed_df)\n",
    "            if dirname == 'train':\n",
    "                train.append(transposed_df)\n",
    "            if dirname == 'valid':\n",
    "                validation.append(transposed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8606521",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "551e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim=50, n_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        lstm_output, (h,c) = self.lstm(x, hidden)\n",
    "        model_output = self.fc(lstm_output)\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e503",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "511051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, melody, harmonies, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(melody)\n",
    "        loss = criterion(output, harmonies)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c6e6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  99 Loss:  tensor(482.2510, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.9224, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.6712, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5469, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5453, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.0975, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.9408, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4718, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.3210, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.2364, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1099 Loss:  tensor(10.2081, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1199 Loss:  tensor(10.2015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1299 Loss:  tensor(10.1882, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1399 Loss:  tensor(10.1794, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1499 Loss:  tensor(10.1752, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1599 Loss:  tensor(10.1686, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1699 Loss:  tensor(10.1732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1799 Loss:  tensor(10.1621, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1899 Loss:  tensor(10.1499, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1999 Loss:  tensor(10.1373, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2099 Loss:  tensor(10.1309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2199 Loss:  tensor(10.0658, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2299 Loss:  tensor(10.0194, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2399 Loss:  tensor(9.9716, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2499 Loss:  tensor(9.9333, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2599 Loss:  tensor(9.8772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2699 Loss:  tensor(9.8246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2799 Loss:  tensor(9.7784, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2899 Loss:  tensor(9.7364, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2999 Loss:  tensor(9.6981, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3099 Loss:  tensor(9.6660, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3199 Loss:  tensor(9.6324, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3299 Loss:  tensor(9.6034, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3399 Loss:  tensor(9.5786, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3499 Loss:  tensor(9.5566, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3599 Loss:  tensor(9.5391, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3699 Loss:  tensor(9.5196, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3799 Loss:  tensor(9.5039, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3899 Loss:  tensor(9.4915, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3999 Loss:  tensor(9.4756, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4099 Loss:  tensor(9.4639, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4199 Loss:  tensor(9.4479, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4299 Loss:  tensor(9.4509, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4399 Loss:  tensor(9.3983, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4499 Loss:  tensor(9.3886, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4599 Loss:  tensor(9.4309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4699 Loss:  tensor(9.2587, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4799 Loss:  tensor(9.2326, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4899 Loss:  tensor(9.1521, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4999 Loss:  tensor(9.1026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5099 Loss:  tensor(9.0883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5199 Loss:  tensor(9.0744, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5299 Loss:  tensor(9.0607, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5399 Loss:  tensor(9.0175, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5499 Loss:  tensor(8.9798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5599 Loss:  tensor(9.0078, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5699 Loss:  tensor(8.9298, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5799 Loss:  tensor(8.9050, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5899 Loss:  tensor(8.8690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5999 Loss:  tensor(8.8288, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6099 Loss:  tensor(8.7824, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6199 Loss:  tensor(8.7320, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6299 Loss:  tensor(8.6712, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6399 Loss:  tensor(8.6071, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6499 Loss:  tensor(8.5409, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6599 Loss:  tensor(8.4780, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6699 Loss:  tensor(8.4082, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6799 Loss:  tensor(8.3451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6899 Loss:  tensor(8.2881, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6999 Loss:  tensor(8.2348, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7099 Loss:  tensor(8.1893, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7199 Loss:  tensor(8.1558, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7299 Loss:  tensor(8.1148, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7399 Loss:  tensor(8.1020, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7499 Loss:  tensor(8.0471, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7599 Loss:  tensor(7.9643, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7699 Loss:  tensor(7.9029, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7799 Loss:  tensor(7.8647, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7899 Loss:  tensor(7.8404, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7999 Loss:  tensor(7.8025, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8099 Loss:  tensor(7.7370, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8199 Loss:  tensor(7.7158, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8299 Loss:  tensor(7.6787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8399 Loss:  tensor(7.6588, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8499 Loss:  tensor(7.6356, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8599 Loss:  tensor(7.6050, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8699 Loss:  tensor(7.5834, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8799 Loss:  tensor(7.5794, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8899 Loss:  tensor(7.5913, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8999 Loss:  tensor(7.5309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9099 Loss:  tensor(7.5115, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9199 Loss:  tensor(7.7662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9299 Loss:  tensor(7.7257, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9399 Loss:  tensor(7.8848, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9499 Loss:  tensor(8.4145, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9599 Loss:  tensor(7.7907, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9699 Loss:  tensor(7.7308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9799 Loss:  tensor(7.6883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9899 Loss:  tensor(7.6856, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9999 Loss:  tensor(7.6471, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10099 Loss:  tensor(7.6347, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10199 Loss:  tensor(7.6116, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10299 Loss:  tensor(7.5914, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10399 Loss:  tensor(7.5735, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10499 Loss:  tensor(7.5673, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10599 Loss:  tensor(7.5169, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10699 Loss:  tensor(7.5048, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10799 Loss:  tensor(7.4505, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10899 Loss:  tensor(7.4228, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  10999 Loss:  tensor(8.7593, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11099 Loss:  tensor(8.7057, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11199 Loss:  tensor(8.6947, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11299 Loss:  tensor(8.6751, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11399 Loss:  tensor(8.6614, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11499 Loss:  tensor(8.6466, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11599 Loss:  tensor(8.6291, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11699 Loss:  tensor(8.6135, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11799 Loss:  tensor(8.6070, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11899 Loss:  tensor(8.5519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  11999 Loss:  tensor(8.5322, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12099 Loss:  tensor(8.5113, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12199 Loss:  tensor(7.8934, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12299 Loss:  tensor(7.5875, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12399 Loss:  tensor(7.5687, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12499 Loss:  tensor(7.5491, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12599 Loss:  tensor(7.5207, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12699 Loss:  tensor(7.5062, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12799 Loss:  tensor(7.4924, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12899 Loss:  tensor(7.4811, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  12999 Loss:  tensor(7.4677, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13099 Loss:  tensor(7.4543, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13199 Loss:  tensor(7.4610, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13299 Loss:  tensor(7.4547, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13399 Loss:  tensor(7.4210, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13499 Loss:  tensor(7.4154, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13599 Loss:  tensor(7.3588, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13699 Loss:  tensor(7.3646, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13799 Loss:  tensor(7.3647, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13899 Loss:  tensor(8.7448, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  13999 Loss:  tensor(8.7003, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  14099 Loss:  tensor(8.6807, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;241m1\u001b[39m, harmonies\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmelody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mharmonies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, melody, harmonies, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, harmonies)\n\u001b[0;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 7\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    429\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "for song in train:\n",
    "    melody = torch.tensor(song.iloc[0], dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1)\n",
    "    harmonies = torch.transpose(torch.tensor(song.iloc[1:].values, dtype=torch.float32),0,1).unsqueeze(0)\n",
    "    model = Model(1, harmonies.shape[2])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_model(model, melody, harmonies, optimizer, criterion, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b889de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny = pd.DataFrame([[67,62,59,43], [68,62,59,43]]).transpose()\n",
    "# melody = torch.tensor(tiny.iloc[0], dtype=torch.float32).unsqueeze(0).reshape(1,2,1)\n",
    "# harmonies = torch.transpose(torch.tensor(tiny.iloc[1:].values, dtype=torch.float32),0,1).unsqueeze(0)\n",
    "# model = Model(1, harmonies.shape[2])\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# train_model(model, melody, harmonies, optimizer, criterion, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f9e5e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv85324\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv85324_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv85324\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,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\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv85324_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv85324_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/foodrunner/CS370/PolyphAI/Code/output.xml')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melody = train[0].iloc[0]\n",
    "result = model(torch.tensor(melody, dtype=torch.float32).unsqueeze(0).reshape(1, train[0].shape[1], 1))\n",
    "\n",
    "score = stream.Score()\n",
    "melody_part = stream.Part()\n",
    "alto_part = stream.Part()\n",
    "tenor_part = stream.Part()\n",
    "bass_part = stream.Part()\n",
    "\n",
    "for pitch in melody:\n",
    "    melody_note = note.Note(int(pitch))\n",
    "    melody_part.append(melody_note)\n",
    "\n",
    "alto_notes = result[0, :, 0]\n",
    "tenor_notes = result[0, :, 1]\n",
    "bass_notes = result[0, :, 2]  \n",
    "\n",
    "for pitch in alto_notes:\n",
    "    alto_note = note.Note(int(pitch.item()))\n",
    "    alto_part.append(alto_note)\n",
    "for pitch in tenor_notes:\n",
    "     tenor_note = note.Note(int(pitch.item()))\n",
    "     tenor_part.append(tenor_note)\n",
    "for pitch in bass_notes:\n",
    "    bass_note = note.Note(int(pitch.item()))\n",
    "    bass_part.append(bass_note)\n",
    "\n",
    "score.append(melody_part)\n",
    "score.append(alto_part)\n",
    "score.append(tenor_part)\n",
    "score.append(bass_part)\n",
    "score.show('midi')\n",
    "score.write('musicxml', 'output.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune (hyperparameters, move around test data (refer to notes), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new data + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet music + audio (musicAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new models if time permits (follow steps 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end ** if time permits\n",
    "# - Interactive sheet music\n",
    "# - musescore front end??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121de9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
