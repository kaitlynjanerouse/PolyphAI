{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7d361ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary imports\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3c67e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Data\n",
    "def get_pitch_class(note):\n",
    "    return note % 12\n",
    "\n",
    "def find_matching_octave_note(df):\n",
    "    bass_line = df.iloc[3].values\n",
    "    last_bass_note = bass_line[-1]\n",
    "    return last_bass_note\n",
    "\n",
    "def explore_for_lowest_tonic(df, pitch_class):\n",
    "    bass_notes = df.iloc[3].values  \n",
    "    matching_notes = [note for note in bass_notes if get_pitch_class(note) == pitch_class]\n",
    "    if matching_notes:\n",
    "        return min(matching_notes) \n",
    "    else:\n",
    "        return bass_notes[0]\n",
    "\n",
    "def detect_tonic(df):\n",
    "    candidate_note = find_matching_octave_note(df)\n",
    "    pitch_class = get_pitch_class(candidate_note)\n",
    "    true_tonic_note = explore_for_lowest_tonic(df, pitch_class)\n",
    "    return true_tonic_note\n",
    "\n",
    "def key_transposition(df):\n",
    "    tonic_note = detect_tonic(df)\n",
    "    transpose_val = 48 - tonic_note\n",
    "    df = (df + transpose_val).clip(lower=0, upper=127)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_df(df):\n",
    "    X_std = df / 127\n",
    "    return X_std\n",
    "\n",
    "folder_path = 'Data/'\n",
    "test = []\n",
    "train = []\n",
    "validation = []\n",
    "for dirname in os.listdir(folder_path):\n",
    "    if dirname != '.DS_Store':\n",
    "        for filename in os.listdir(folder_path + dirname):\n",
    "            if filename != '.ipynb_checkpoints':\n",
    "                df = pd.read_csv(folder_path + dirname + '/' + filename)\n",
    "                transposed_df = key_transposition(df.transpose())\n",
    "                normalized_df = normalize_df(transposed_df)\n",
    "                if dirname == 'test':\n",
    "                    test.append(normalized_df)\n",
    "                if dirname == 'train':\n",
    "                    train.append(normalized_df)\n",
    "                if dirname == 'valid':\n",
    "                    validation.append(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8606521",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "551e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim=100, n_layers=2, dropout_rate=.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size * 128)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(next(self.parameters()).device),\n",
    "                torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(next(self.parameters()).device))\n",
    "\n",
    "    def forward(self, x, target=None, hidden=None, teacher_forcing=.5):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "        lstm_input = x[:, 0:1, :]\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            lstm_output, hidden = self.lstm(lstm_input, hidden)\n",
    "            lstm_output_step = lstm_output[:, -1, :] \n",
    "            model_output_step = self.fc(lstm_output_step)\n",
    "            model_output_step = model_output_step.view(batch_size, 3, 128)\n",
    "\n",
    "            outputs.append(model_output_step.unsqueeze(1))\n",
    "            \n",
    "            if target is not None and random.random() < teacher_forcing:\n",
    "                next_harmony = target[:, t:t+1, :]\n",
    "            else:\n",
    "                next_harmony = model_output_step.argmax(dim=-1).unsqueeze(1)\n",
    "\n",
    "            next_harmony = next_harmony.view(batch_size, 1, 3)\n",
    "\n",
    "            if t + 1 < seq_len:\n",
    "                melody_at_next_step = x[:, t + 1:t + 2, :1]  \n",
    "                lstm_input = torch.cat((melody_at_next_step, next_harmony), dim=2) \n",
    "\n",
    "        output = torch.cat(outputs, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e503",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "511051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "    for song_index, song in enumerate(train[:150]):\n",
    "        print(f\"Training on song {song_index + 1}\")\n",
    "        \n",
    "        melody = torch.tensor(song.iloc[0].values.reshape(-1, 1), dtype=torch.float32).unsqueeze(0).reshape(1, song.shape[1], 1)\n",
    "        harmonies = torch.tensor(song.iloc[1:].values.T, dtype=torch.float32).unsqueeze(0)\n",
    "        harmonies_with_zero = torch.zeros(1, song.shape[1], 3)\n",
    "        melody_with_empty_harmonies = torch.cat((melody, harmonies_with_zero), dim = -1)\n",
    "        harmonies_for_loss = harmonies_to_class(harmonies)\n",
    "       \n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            ratio = .9 - (.9 - .1) * (epoch / num_epochs)\n",
    "            ratio = max(.1, ratio)\n",
    "            output = model(x=melody_with_empty_harmonies, target=harmonies, teacher_forcing=ratio)\n",
    "            output = output.reshape(-1, 128)\n",
    "            harmonies_for_loss = harmonies_for_loss.reshape(-1)\n",
    "#             with torch.no_grad():\n",
    "#                 print(f\"Targets    : {harmonies_for_loss[:50]}\")\n",
    "#                 print(f\"Predictions: {output[:50].argmax(dim=1)}\")\n",
    "            loss = criterion(output, harmonies_for_loss)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Song {song_index + 1}, Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "                    \n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        \n",
    "\n",
    "        \n",
    "        # validation songs\n",
    "        with torch.no_grad():\n",
    "            for val_song in validation:\n",
    "                val_melody = torch.tensor(val_song.iloc[0].values.reshape(-1, 1), dtype=torch.float32).unsqueeze(0).reshape(1, val_song.shape[1], 1)\n",
    "                val_harmonies = torch.tensor(val_song.iloc[1:].values.T, dtype=torch.float32).unsqueeze(0)\n",
    "                val_harmonies = harmonies_to_class(val_harmonies)\n",
    "                val_harmonies_with_zero = torch.zeros(1, val_song.shape[1], 3)\n",
    "                val_melody_with_empty_harmonies = torch.cat((val_melody, val_harmonies_with_zero), dim=-1)\n",
    "                \n",
    "                val_output = model(val_melody_with_empty_harmonies)\n",
    "                val_output = val_output.reshape(-1, 128)\n",
    "                val_harmonies = val_harmonies.reshape(-1)\n",
    "                \n",
    "                val_loss = criterion(val_output, val_harmonies)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        average_val_loss = total_val_loss / len(validation)\n",
    "        print(f\"Validation Loss after song {song_index + 1}: {average_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on song 1\n",
      "Song 1, Epoch 10/200, Loss: 4.826527118682861\n",
      "Song 1, Epoch 20/200, Loss: 4.806944847106934\n",
      "Song 1, Epoch 30/200, Loss: 4.763866901397705\n",
      "Song 1, Epoch 40/200, Loss: 4.711582660675049\n",
      "Song 1, Epoch 50/200, Loss: 4.601804733276367\n",
      "Song 1, Epoch 60/200, Loss: 4.397435665130615\n",
      "Song 1, Epoch 70/200, Loss: 4.112029552459717\n",
      "Song 1, Epoch 80/200, Loss: 3.750270128250122\n",
      "Song 1, Epoch 90/200, Loss: 3.4394004344940186\n",
      "Song 1, Epoch 100/200, Loss: 3.171048879623413\n",
      "Song 1, Epoch 110/200, Loss: 2.909698486328125\n",
      "Song 1, Epoch 120/200, Loss: 2.715970993041992\n",
      "Song 1, Epoch 130/200, Loss: 2.5552196502685547\n",
      "Song 1, Epoch 140/200, Loss: 2.4439637660980225\n",
      "Song 1, Epoch 150/200, Loss: 2.3771116733551025\n",
      "Song 1, Epoch 160/200, Loss: 2.277440309524536\n",
      "Song 1, Epoch 170/200, Loss: 2.2265398502349854\n",
      "Song 1, Epoch 180/200, Loss: 2.1913485527038574\n",
      "Song 1, Epoch 190/200, Loss: 2.177070140838623\n",
      "Song 1, Epoch 200/200, Loss: 2.149001121520996\n",
      "Validation Loss after song 1: 4.198215680244641\n",
      "Training on song 2\n",
      "Song 2, Epoch 10/200, Loss: 4.898775100708008\n",
      "Song 2, Epoch 20/200, Loss: 4.629065036773682\n",
      "Song 2, Epoch 30/200, Loss: 4.355052471160889\n",
      "Song 2, Epoch 40/200, Loss: 4.1173481941223145\n",
      "Song 2, Epoch 50/200, Loss: 3.9013631343841553\n",
      "Song 2, Epoch 60/200, Loss: 3.7099249362945557\n",
      "Song 2, Epoch 70/200, Loss: 3.534708023071289\n",
      "Song 2, Epoch 80/200, Loss: 3.3885254859924316\n",
      "Song 2, Epoch 90/200, Loss: 3.2465507984161377\n",
      "Song 2, Epoch 100/200, Loss: 3.106740951538086\n",
      "Song 2, Epoch 110/200, Loss: 2.9849841594696045\n",
      "Song 2, Epoch 120/200, Loss: 2.8723020553588867\n",
      "Song 2, Epoch 130/200, Loss: 2.768329381942749\n",
      "Song 2, Epoch 140/200, Loss: 2.6742866039276123\n",
      "Song 2, Epoch 150/200, Loss: 2.593519926071167\n",
      "Song 2, Epoch 160/200, Loss: 2.5046772956848145\n",
      "Song 2, Epoch 170/200, Loss: 2.435318946838379\n",
      "Song 2, Epoch 180/200, Loss: 2.376126766204834\n",
      "Song 2, Epoch 190/200, Loss: 2.3265974521636963\n",
      "Song 2, Epoch 200/200, Loss: 2.2858147621154785\n",
      "Validation Loss after song 2: 3.7089692445901723\n",
      "Training on song 3\n",
      "Song 3, Epoch 10/200, Loss: 4.145141124725342\n",
      "Song 3, Epoch 20/200, Loss: 3.947995185852051\n",
      "Song 3, Epoch 30/200, Loss: 3.7334229946136475\n",
      "Song 3, Epoch 40/200, Loss: 3.4864046573638916\n",
      "Song 3, Epoch 50/200, Loss: 3.3792810440063477\n",
      "Song 3, Epoch 60/200, Loss: 3.1820545196533203\n",
      "Song 3, Epoch 70/200, Loss: 3.035942554473877\n",
      "Song 3, Epoch 80/200, Loss: 2.909909725189209\n",
      "Song 3, Epoch 90/200, Loss: 2.779003620147705\n",
      "Song 3, Epoch 100/200, Loss: 2.7191548347473145\n",
      "Song 3, Epoch 110/200, Loss: 2.6218252182006836\n",
      "Song 3, Epoch 120/200, Loss: 2.5438334941864014\n",
      "Song 3, Epoch 130/200, Loss: 2.5459160804748535\n",
      "Song 3, Epoch 140/200, Loss: 2.4564385414123535\n",
      "Song 3, Epoch 150/200, Loss: 2.425654888153076\n",
      "Song 3, Epoch 160/200, Loss: 2.406378746032715\n",
      "Song 3, Epoch 170/200, Loss: 2.379647970199585\n",
      "Song 3, Epoch 180/200, Loss: 2.362565279006958\n",
      "Song 3, Epoch 190/200, Loss: 2.350611925125122\n",
      "Song 3, Epoch 200/200, Loss: 2.3305869102478027\n",
      "Validation Loss after song 3: 3.9838370420993905\n",
      "Training on song 4\n",
      "Song 4, Epoch 10/200, Loss: 2.6858808994293213\n",
      "Song 4, Epoch 20/200, Loss: 2.5529894828796387\n",
      "Song 4, Epoch 30/200, Loss: 2.493036985397339\n",
      "Song 4, Epoch 40/200, Loss: 2.4635238647460938\n",
      "Song 4, Epoch 50/200, Loss: 2.4070355892181396\n",
      "Song 4, Epoch 60/200, Loss: 2.3856749534606934\n",
      "Song 4, Epoch 70/200, Loss: 2.3749938011169434\n",
      "Song 4, Epoch 80/200, Loss: 2.375425100326538\n",
      "Song 4, Epoch 90/200, Loss: 2.3424699306488037\n",
      "Song 4, Epoch 100/200, Loss: 2.3318917751312256\n",
      "Song 4, Epoch 110/200, Loss: 2.324378490447998\n",
      "Song 4, Epoch 120/200, Loss: 2.3336844444274902\n",
      "Song 4, Epoch 130/200, Loss: 2.312664031982422\n",
      "Song 4, Epoch 140/200, Loss: 2.3143179416656494\n",
      "Song 4, Epoch 150/200, Loss: 2.3028674125671387\n",
      "Song 4, Epoch 160/200, Loss: 2.307046413421631\n",
      "Song 4, Epoch 170/200, Loss: 2.2941741943359375\n",
      "Song 4, Epoch 180/200, Loss: 2.2899842262268066\n",
      "Song 4, Epoch 190/200, Loss: 2.280438184738159\n",
      "Song 4, Epoch 200/200, Loss: 2.2703757286071777\n",
      "Validation Loss after song 4: 4.458969299609844\n",
      "Training on song 5\n",
      "Song 5, Epoch 10/200, Loss: 3.6634867191314697\n",
      "Song 5, Epoch 20/200, Loss: 3.3369321823120117\n",
      "Song 5, Epoch 30/200, Loss: 3.099806547164917\n",
      "Song 5, Epoch 40/200, Loss: 2.8592803478240967\n",
      "Song 5, Epoch 50/200, Loss: 2.720527410507202\n",
      "Song 5, Epoch 60/200, Loss: 2.5455527305603027\n",
      "Song 5, Epoch 70/200, Loss: 2.437976360321045\n",
      "Song 5, Epoch 80/200, Loss: 2.3662617206573486\n",
      "Song 5, Epoch 90/200, Loss: 2.2775754928588867\n",
      "Song 5, Epoch 100/200, Loss: 2.2221996784210205\n",
      "Song 5, Epoch 110/200, Loss: 2.175924777984619\n",
      "Song 5, Epoch 120/200, Loss: 2.1409120559692383\n",
      "Song 5, Epoch 130/200, Loss: 2.139061212539673\n",
      "Song 5, Epoch 140/200, Loss: 2.0862791538238525\n",
      "Song 5, Epoch 150/200, Loss: 2.082766056060791\n",
      "Song 5, Epoch 160/200, Loss: 2.0487582683563232\n",
      "Song 5, Epoch 170/200, Loss: 2.066375970840454\n",
      "Song 5, Epoch 180/200, Loss: 2.022672176361084\n",
      "Song 5, Epoch 190/200, Loss: 2.0126194953918457\n",
      "Song 5, Epoch 200/200, Loss: 2.0039021968841553\n",
      "Validation Loss after song 5: 3.8860824536054563\n",
      "Training on song 6\n",
      "Song 6, Epoch 10/200, Loss: 3.215407133102417\n",
      "Song 6, Epoch 20/200, Loss: 3.0471975803375244\n",
      "Song 6, Epoch 30/200, Loss: 2.8877177238464355\n",
      "Song 6, Epoch 40/200, Loss: 2.743579387664795\n",
      "Song 6, Epoch 50/200, Loss: 2.596815824508667\n",
      "Song 6, Epoch 60/200, Loss: 2.484525680541992\n",
      "Song 6, Epoch 70/200, Loss: 2.373767852783203\n",
      "Song 6, Epoch 80/200, Loss: 2.286052703857422\n",
      "Song 6, Epoch 90/200, Loss: 2.221362590789795\n",
      "Song 6, Epoch 100/200, Loss: 2.1755034923553467\n",
      "Song 6, Epoch 110/200, Loss: 2.14817476272583\n",
      "Song 6, Epoch 120/200, Loss: 2.1197292804718018\n",
      "Song 6, Epoch 130/200, Loss: 2.102534294128418\n",
      "Song 6, Epoch 140/200, Loss: 2.0903351306915283\n",
      "Song 6, Epoch 150/200, Loss: 2.0893867015838623\n",
      "Song 6, Epoch 160/200, Loss: 2.0718226432800293\n",
      "Song 6, Epoch 170/200, Loss: 2.0655579566955566\n",
      "Song 6, Epoch 180/200, Loss: 2.060417890548706\n",
      "Song 6, Epoch 190/200, Loss: 2.056837797164917\n",
      "Song 6, Epoch 200/200, Loss: 2.058021306991577\n",
      "Validation Loss after song 6: 3.8934991971040382\n",
      "Training on song 7\n",
      "Song 7, Epoch 10/200, Loss: 3.2907397747039795\n",
      "Song 7, Epoch 20/200, Loss: 3.1026601791381836\n",
      "Song 7, Epoch 30/200, Loss: 2.910172462463379\n",
      "Song 7, Epoch 40/200, Loss: 2.7262864112854004\n",
      "Song 7, Epoch 50/200, Loss: 2.611497402191162\n",
      "Song 7, Epoch 60/200, Loss: 2.4999804496765137\n",
      "Song 7, Epoch 70/200, Loss: 2.4110665321350098\n",
      "Song 7, Epoch 80/200, Loss: 2.3549768924713135\n",
      "Song 7, Epoch 90/200, Loss: 2.3166286945343018\n",
      "Song 7, Epoch 100/200, Loss: 2.2843565940856934\n",
      "Song 7, Epoch 110/200, Loss: 2.253911256790161\n",
      "Song 7, Epoch 120/200, Loss: 2.2387521266937256\n",
      "Song 7, Epoch 130/200, Loss: 2.2241640090942383\n",
      "Song 7, Epoch 140/200, Loss: 2.213061571121216\n",
      "Song 7, Epoch 150/200, Loss: 2.2047698497772217\n",
      "Song 7, Epoch 160/200, Loss: 2.204507350921631\n",
      "Song 7, Epoch 170/200, Loss: 2.1960928440093994\n",
      "Song 7, Epoch 180/200, Loss: 2.1912825107574463\n",
      "Song 7, Epoch 190/200, Loss: 2.181417465209961\n",
      "Song 7, Epoch 200/200, Loss: 2.177598476409912\n",
      "Validation Loss after song 7: 3.993817390539707\n",
      "Training on song 8\n",
      "Song 8, Epoch 10/200, Loss: 4.377810955047607\n",
      "Song 8, Epoch 20/200, Loss: 4.078766822814941\n",
      "Song 8, Epoch 30/200, Loss: 3.778442144393921\n",
      "Song 8, Epoch 40/200, Loss: 3.525951385498047\n",
      "Song 8, Epoch 50/200, Loss: 3.3066749572753906\n",
      "Song 8, Epoch 60/200, Loss: 3.10101580619812\n",
      "Song 8, Epoch 70/200, Loss: 2.9427649974823\n",
      "Song 8, Epoch 80/200, Loss: 2.825364828109741\n",
      "Song 8, Epoch 90/200, Loss: 2.7529847621917725\n",
      "Song 8, Epoch 100/200, Loss: 2.6635615825653076\n",
      "Song 8, Epoch 110/200, Loss: 2.6001179218292236\n",
      "Song 8, Epoch 120/200, Loss: 2.553281545639038\n",
      "Song 8, Epoch 130/200, Loss: 2.5204179286956787\n",
      "Song 8, Epoch 140/200, Loss: 2.4887726306915283\n",
      "Song 8, Epoch 150/200, Loss: 2.460739850997925\n",
      "Song 8, Epoch 160/200, Loss: 2.4369301795959473\n",
      "Song 8, Epoch 170/200, Loss: 2.4220638275146484\n",
      "Song 8, Epoch 180/200, Loss: 2.3990519046783447\n",
      "Song 8, Epoch 190/200, Loss: 2.3902463912963867\n",
      "Song 8, Epoch 200/200, Loss: 2.381253957748413\n",
      "Validation Loss after song 8: 3.527331297214215\n",
      "Training on song 9\n",
      "Song 9, Epoch 10/200, Loss: 3.1116549968719482\n",
      "Song 9, Epoch 20/200, Loss: 2.9577524662017822\n",
      "Song 9, Epoch 30/200, Loss: 2.774991989135742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 9, Epoch 40/200, Loss: 2.623589038848877\n",
      "Song 9, Epoch 50/200, Loss: 2.5097668170928955\n",
      "Song 9, Epoch 60/200, Loss: 2.381617784500122\n",
      "Song 9, Epoch 70/200, Loss: 2.2789435386657715\n",
      "Song 9, Epoch 80/200, Loss: 2.2323780059814453\n",
      "Song 9, Epoch 90/200, Loss: 2.184739828109741\n",
      "Song 9, Epoch 100/200, Loss: 2.153258800506592\n",
      "Song 9, Epoch 110/200, Loss: 2.1351966857910156\n",
      "Song 9, Epoch 120/200, Loss: 2.116194486618042\n",
      "Song 9, Epoch 130/200, Loss: 2.0920557975769043\n",
      "Song 9, Epoch 140/200, Loss: 2.0908734798431396\n",
      "Song 9, Epoch 150/200, Loss: 2.086055278778076\n",
      "Song 9, Epoch 160/200, Loss: 2.0667037963867188\n",
      "Song 9, Epoch 170/200, Loss: 2.055654525756836\n",
      "Song 9, Epoch 180/200, Loss: 2.0593760013580322\n",
      "Song 9, Epoch 190/200, Loss: 2.046806573867798\n",
      "Song 9, Epoch 200/200, Loss: 2.043516159057617\n",
      "Validation Loss after song 9: 3.7065905729929605\n",
      "Training on song 10\n",
      "Song 10, Epoch 10/200, Loss: 2.2363474369049072\n",
      "Song 10, Epoch 20/200, Loss: 2.154874324798584\n",
      "Song 10, Epoch 30/200, Loss: 2.1041877269744873\n",
      "Song 10, Epoch 40/200, Loss: 2.081369400024414\n",
      "Song 10, Epoch 50/200, Loss: 2.0544867515563965\n",
      "Song 10, Epoch 60/200, Loss: 2.0295889377593994\n",
      "Song 10, Epoch 70/200, Loss: 2.0156753063201904\n",
      "Song 10, Epoch 80/200, Loss: 2.0077033042907715\n",
      "Song 10, Epoch 90/200, Loss: 1.9970930814743042\n",
      "Song 10, Epoch 100/200, Loss: 1.9953328371047974\n",
      "Song 10, Epoch 110/200, Loss: 1.9847149848937988\n",
      "Song 10, Epoch 120/200, Loss: 1.9799187183380127\n",
      "Song 10, Epoch 130/200, Loss: 1.9738966226577759\n",
      "Song 10, Epoch 140/200, Loss: 1.969994306564331\n",
      "Song 10, Epoch 150/200, Loss: 1.975928544998169\n",
      "Song 10, Epoch 160/200, Loss: 1.9708112478256226\n",
      "Song 10, Epoch 170/200, Loss: 1.9688749313354492\n",
      "Song 10, Epoch 180/200, Loss: 1.9586293697357178\n",
      "Song 10, Epoch 190/200, Loss: 1.95710289478302\n",
      "Song 10, Epoch 200/200, Loss: 1.9549338817596436\n",
      "Validation Loss after song 10: 3.8179975228431897\n",
      "Training on song 11\n",
      "Song 11, Epoch 10/200, Loss: 2.9046308994293213\n",
      "Song 11, Epoch 20/200, Loss: 2.7866978645324707\n",
      "Song 11, Epoch 30/200, Loss: 2.6606667041778564\n",
      "Song 11, Epoch 40/200, Loss: 2.544153928756714\n",
      "Song 11, Epoch 50/200, Loss: 2.434089183807373\n",
      "Song 11, Epoch 60/200, Loss: 2.376708507537842\n",
      "Song 11, Epoch 70/200, Loss: 2.2985806465148926\n",
      "Song 11, Epoch 80/200, Loss: 2.2466177940368652\n",
      "Song 11, Epoch 90/200, Loss: 2.2183997631073\n",
      "Song 11, Epoch 100/200, Loss: 2.1765196323394775\n",
      "Song 11, Epoch 110/200, Loss: 2.166883945465088\n",
      "Song 11, Epoch 120/200, Loss: 2.1342735290527344\n",
      "Song 11, Epoch 130/200, Loss: 2.123289108276367\n",
      "Song 11, Epoch 140/200, Loss: 2.1132595539093018\n",
      "Song 11, Epoch 150/200, Loss: 2.1024951934814453\n",
      "Song 11, Epoch 160/200, Loss: 2.093965530395508\n",
      "Song 11, Epoch 170/200, Loss: 2.0867366790771484\n",
      "Song 11, Epoch 180/200, Loss: 2.0798192024230957\n",
      "Song 11, Epoch 190/200, Loss: 2.084202289581299\n",
      "Song 11, Epoch 200/200, Loss: 2.0695059299468994\n",
      "Validation Loss after song 11: 3.6800687374212804\n",
      "Training on song 12\n",
      "Song 12, Epoch 10/200, Loss: 4.332366943359375\n",
      "Song 12, Epoch 20/200, Loss: 3.9287970066070557\n",
      "Song 12, Epoch 30/200, Loss: 3.5766475200653076\n",
      "Song 12, Epoch 40/200, Loss: 3.3025219440460205\n",
      "Song 12, Epoch 50/200, Loss: 3.1335177421569824\n",
      "Song 12, Epoch 60/200, Loss: 3.0008018016815186\n",
      "Song 12, Epoch 70/200, Loss: 2.891838550567627\n",
      "Song 12, Epoch 80/200, Loss: 2.802504062652588\n",
      "Song 12, Epoch 90/200, Loss: 2.7371256351470947\n",
      "Song 12, Epoch 100/200, Loss: 2.6783506870269775\n",
      "Song 12, Epoch 110/200, Loss: 2.6294496059417725\n",
      "Song 12, Epoch 120/200, Loss: 2.587162733078003\n",
      "Song 12, Epoch 130/200, Loss: 2.5467123985290527\n",
      "Song 12, Epoch 140/200, Loss: 2.5130722522735596\n",
      "Song 12, Epoch 150/200, Loss: 2.483642578125\n",
      "Song 12, Epoch 160/200, Loss: 2.4574406147003174\n",
      "Song 12, Epoch 170/200, Loss: 2.4329967498779297\n",
      "Song 12, Epoch 180/200, Loss: 2.428729772567749\n",
      "Song 12, Epoch 190/200, Loss: 2.4118595123291016\n",
      "Song 12, Epoch 200/200, Loss: 2.4044172763824463\n",
      "Validation Loss after song 12: 3.61703417240045\n",
      "Training on song 13\n",
      "Song 13, Epoch 10/200, Loss: 4.1957244873046875\n",
      "Song 13, Epoch 20/200, Loss: 3.925732374191284\n",
      "Song 13, Epoch 30/200, Loss: 3.661752700805664\n",
      "Song 13, Epoch 40/200, Loss: 3.4258549213409424\n",
      "Song 13, Epoch 50/200, Loss: 3.208153247833252\n",
      "Song 13, Epoch 60/200, Loss: 3.0353429317474365\n",
      "Song 13, Epoch 70/200, Loss: 2.884065628051758\n",
      "Song 13, Epoch 80/200, Loss: 2.748558759689331\n",
      "Song 13, Epoch 90/200, Loss: 2.646284580230713\n",
      "Song 13, Epoch 100/200, Loss: 2.56834077835083\n",
      "Song 13, Epoch 110/200, Loss: 2.5031964778900146\n",
      "Song 13, Epoch 120/200, Loss: 2.455622434616089\n",
      "Song 13, Epoch 130/200, Loss: 2.421830654144287\n",
      "Song 13, Epoch 140/200, Loss: 2.397049903869629\n",
      "Song 13, Epoch 150/200, Loss: 2.3726251125335693\n",
      "Song 13, Epoch 160/200, Loss: 2.3589229583740234\n",
      "Song 13, Epoch 170/200, Loss: 2.3423409461975098\n",
      "Song 13, Epoch 180/200, Loss: 2.3336281776428223\n",
      "Song 13, Epoch 190/200, Loss: 2.3242735862731934\n",
      "Song 13, Epoch 200/200, Loss: 2.3178091049194336\n",
      "Validation Loss after song 13: 3.58918869189727\n",
      "Training on song 14\n",
      "Song 14, Epoch 10/200, Loss: 3.900158405303955\n",
      "Song 14, Epoch 20/200, Loss: 3.6428873538970947\n",
      "Song 14, Epoch 30/200, Loss: 3.3574600219726562\n",
      "Song 14, Epoch 40/200, Loss: 3.157557725906372\n",
      "Song 14, Epoch 50/200, Loss: 2.9887447357177734\n",
      "Song 14, Epoch 60/200, Loss: 2.8308849334716797\n",
      "Song 14, Epoch 70/200, Loss: 2.7010414600372314\n",
      "Song 14, Epoch 80/200, Loss: 2.584526538848877\n",
      "Song 14, Epoch 90/200, Loss: 2.494706153869629\n",
      "Song 14, Epoch 100/200, Loss: 2.4182827472686768\n",
      "Song 14, Epoch 110/200, Loss: 2.360567331314087\n",
      "Song 14, Epoch 120/200, Loss: 2.3194336891174316\n",
      "Song 14, Epoch 130/200, Loss: 2.287254571914673\n",
      "Song 14, Epoch 140/200, Loss: 2.2674388885498047\n",
      "Song 14, Epoch 150/200, Loss: 2.2417469024658203\n",
      "Song 14, Epoch 160/200, Loss: 2.224097490310669\n",
      "Song 14, Epoch 170/200, Loss: 2.211688280105591\n",
      "Song 14, Epoch 180/200, Loss: 2.2042076587677\n",
      "Song 14, Epoch 190/200, Loss: 2.1852779388427734\n",
      "Song 14, Epoch 200/200, Loss: 2.1748945713043213\n",
      "Validation Loss after song 14: 3.583948954557761\n",
      "Training on song 15\n",
      "Song 15, Epoch 10/200, Loss: 3.1342387199401855\n",
      "Song 15, Epoch 20/200, Loss: 2.9834394454956055\n",
      "Song 15, Epoch 30/200, Loss: 2.8288443088531494\n",
      "Song 15, Epoch 40/200, Loss: 2.699528455734253\n",
      "Song 15, Epoch 50/200, Loss: 2.592585325241089\n",
      "Song 15, Epoch 60/200, Loss: 2.5049757957458496\n",
      "Song 15, Epoch 70/200, Loss: 2.449840545654297\n",
      "Song 15, Epoch 80/200, Loss: 2.3957247734069824\n",
      "Song 15, Epoch 90/200, Loss: 2.3587417602539062\n",
      "Song 15, Epoch 100/200, Loss: 2.341850996017456\n",
      "Song 15, Epoch 110/200, Loss: 2.3083698749542236\n",
      "Song 15, Epoch 120/200, Loss: 2.306241989135742\n",
      "Song 15, Epoch 130/200, Loss: 2.2884254455566406\n",
      "Song 15, Epoch 140/200, Loss: 2.2824435234069824\n",
      "Song 15, Epoch 150/200, Loss: 2.275423049926758\n",
      "Song 15, Epoch 160/200, Loss: 2.2720274925231934\n",
      "Song 15, Epoch 170/200, Loss: 2.2659029960632324\n",
      "Song 15, Epoch 180/200, Loss: 2.2625792026519775\n",
      "Song 15, Epoch 190/200, Loss: 2.2618634700775146\n",
      "Song 15, Epoch 200/200, Loss: 2.2586252689361572\n",
      "Validation Loss after song 15: 3.4115707752032156\n",
      "Training on song 16\n",
      "Song 16, Epoch 10/200, Loss: 2.7194340229034424\n",
      "Song 16, Epoch 20/200, Loss: 2.6275782585144043\n",
      "Song 16, Epoch 30/200, Loss: 2.5320637226104736\n",
      "Song 16, Epoch 40/200, Loss: 2.4610464572906494\n",
      "Song 16, Epoch 50/200, Loss: 2.4030778408050537\n",
      "Song 16, Epoch 60/200, Loss: 2.3662805557250977\n",
      "Song 16, Epoch 70/200, Loss: 2.3307089805603027\n",
      "Song 16, Epoch 80/200, Loss: 2.3165740966796875\n",
      "Song 16, Epoch 90/200, Loss: 2.291905164718628\n",
      "Song 16, Epoch 100/200, Loss: 2.278562068939209\n",
      "Song 16, Epoch 110/200, Loss: 2.2669990062713623\n",
      "Song 16, Epoch 120/200, Loss: 2.2516725063323975\n",
      "Song 16, Epoch 130/200, Loss: 2.244478702545166\n",
      "Song 16, Epoch 140/200, Loss: 2.236522912979126\n",
      "Song 16, Epoch 150/200, Loss: 2.232495069503784\n",
      "Song 16, Epoch 160/200, Loss: 2.234790086746216\n",
      "Song 16, Epoch 170/200, Loss: 2.2244679927825928\n",
      "Song 16, Epoch 180/200, Loss: 2.218404531478882\n",
      "Song 16, Epoch 190/200, Loss: 2.213261365890503\n",
      "Song 16, Epoch 200/200, Loss: 2.2155251502990723\n",
      "Validation Loss after song 16: 3.4776094937935853\n",
      "Training on song 17\n",
      "Song 17, Epoch 10/200, Loss: 4.255592346191406\n",
      "Song 17, Epoch 20/200, Loss: 3.9458682537078857\n",
      "Song 17, Epoch 30/200, Loss: 3.628593683242798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 17, Epoch 40/200, Loss: 3.3692872524261475\n",
      "Song 17, Epoch 50/200, Loss: 3.1634950637817383\n",
      "Song 17, Epoch 60/200, Loss: 2.9883310794830322\n",
      "Song 17, Epoch 70/200, Loss: 2.853451728820801\n",
      "Song 17, Epoch 80/200, Loss: 2.72556734085083\n",
      "Song 17, Epoch 90/200, Loss: 2.6358566284179688\n",
      "Song 17, Epoch 100/200, Loss: 2.5418763160705566\n",
      "Song 17, Epoch 110/200, Loss: 2.4636263847351074\n",
      "Song 17, Epoch 120/200, Loss: 2.4103949069976807\n",
      "Song 17, Epoch 130/200, Loss: 2.367213487625122\n",
      "Song 17, Epoch 140/200, Loss: 2.3330421447753906\n",
      "Song 17, Epoch 150/200, Loss: 2.308600902557373\n",
      "Song 17, Epoch 160/200, Loss: 2.2889838218688965\n",
      "Song 17, Epoch 170/200, Loss: 2.275946855545044\n",
      "Song 17, Epoch 180/200, Loss: 2.2669782638549805\n",
      "Song 17, Epoch 190/200, Loss: 2.2564806938171387\n",
      "Song 17, Epoch 200/200, Loss: 2.244575023651123\n",
      "Validation Loss after song 17: 3.9908623817639475\n",
      "Training on song 18\n",
      "Song 18, Epoch 10/200, Loss: 3.5836379528045654\n",
      "Song 18, Epoch 20/200, Loss: 3.3697292804718018\n",
      "Song 18, Epoch 30/200, Loss: 3.1142492294311523\n",
      "Song 18, Epoch 40/200, Loss: 2.9238250255584717\n",
      "Song 18, Epoch 50/200, Loss: 2.7789175510406494\n",
      "Song 18, Epoch 60/200, Loss: 2.6386077404022217\n",
      "Song 18, Epoch 70/200, Loss: 2.5184762477874756\n",
      "Song 18, Epoch 80/200, Loss: 2.449983596801758\n",
      "Song 18, Epoch 90/200, Loss: 2.412612199783325\n",
      "Song 18, Epoch 100/200, Loss: 2.362971305847168\n",
      "Song 18, Epoch 110/200, Loss: 2.347093105316162\n",
      "Song 18, Epoch 120/200, Loss: 2.3156321048736572\n",
      "Song 18, Epoch 130/200, Loss: 2.2978925704956055\n",
      "Song 18, Epoch 140/200, Loss: 2.2820000648498535\n",
      "Song 18, Epoch 150/200, Loss: 2.2692933082580566\n",
      "Song 18, Epoch 160/200, Loss: 2.2609121799468994\n",
      "Song 18, Epoch 170/200, Loss: 2.253657817840576\n",
      "Song 18, Epoch 180/200, Loss: 2.2478749752044678\n",
      "Song 18, Epoch 190/200, Loss: 2.238328218460083\n",
      "Song 18, Epoch 200/200, Loss: 2.2324681282043457\n",
      "Validation Loss after song 18: 3.4424205315418734\n",
      "Training on song 19\n",
      "Song 19, Epoch 10/200, Loss: 2.37608003616333\n",
      "Song 19, Epoch 20/200, Loss: 2.2875115871429443\n",
      "Song 19, Epoch 30/200, Loss: 2.2104289531707764\n",
      "Song 19, Epoch 40/200, Loss: 2.1539106369018555\n",
      "Song 19, Epoch 50/200, Loss: 2.123243570327759\n",
      "Song 19, Epoch 60/200, Loss: 2.1038031578063965\n",
      "Song 19, Epoch 70/200, Loss: 2.0918326377868652\n",
      "Song 19, Epoch 80/200, Loss: 2.080090284347534\n",
      "Song 19, Epoch 90/200, Loss: 2.063798666000366\n",
      "Song 19, Epoch 100/200, Loss: 2.0538361072540283\n",
      "Song 19, Epoch 110/200, Loss: 2.052889823913574\n",
      "Song 19, Epoch 120/200, Loss: 2.042414903640747\n",
      "Song 19, Epoch 130/200, Loss: 2.037224054336548\n",
      "Song 19, Epoch 140/200, Loss: 2.030087471008301\n",
      "Song 19, Epoch 150/200, Loss: 2.0249879360198975\n",
      "Song 19, Epoch 160/200, Loss: 2.0272579193115234\n",
      "Song 19, Epoch 170/200, Loss: 2.0164358615875244\n",
      "Song 19, Epoch 180/200, Loss: 2.01204776763916\n",
      "Song 19, Epoch 190/200, Loss: 2.0058176517486572\n",
      "Song 19, Epoch 200/200, Loss: 2.006587505340576\n",
      "Validation Loss after song 19: 3.7878030018928723\n",
      "Training on song 20\n",
      "Song 20, Epoch 10/200, Loss: 4.7358479499816895\n",
      "Song 20, Epoch 20/200, Loss: 4.313360691070557\n",
      "Song 20, Epoch 30/200, Loss: 3.9364261627197266\n",
      "Song 20, Epoch 40/200, Loss: 3.552867889404297\n",
      "Song 20, Epoch 50/200, Loss: 3.271007537841797\n",
      "Song 20, Epoch 60/200, Loss: 3.0891122817993164\n",
      "Song 20, Epoch 70/200, Loss: 2.9710299968719482\n",
      "Song 20, Epoch 80/200, Loss: 2.826690196990967\n",
      "Song 20, Epoch 90/200, Loss: 2.7131025791168213\n",
      "Song 20, Epoch 100/200, Loss: 2.6239566802978516\n",
      "Song 20, Epoch 110/200, Loss: 2.561523914337158\n",
      "Song 20, Epoch 120/200, Loss: 2.505554676055908\n",
      "Song 20, Epoch 130/200, Loss: 2.4740755558013916\n",
      "Song 20, Epoch 140/200, Loss: 2.4362008571624756\n",
      "Song 20, Epoch 150/200, Loss: 2.399472951889038\n",
      "Song 20, Epoch 160/200, Loss: 2.363241672515869\n",
      "Song 20, Epoch 170/200, Loss: 2.349170446395874\n",
      "Song 20, Epoch 180/200, Loss: 2.335503101348877\n",
      "Song 20, Epoch 190/200, Loss: 2.3287813663482666\n",
      "Song 20, Epoch 200/200, Loss: 2.3389739990234375\n",
      "Validation Loss after song 20: 3.832907254879291\n",
      "Training on song 21\n",
      "Song 21, Epoch 10/200, Loss: 4.053555011749268\n",
      "Song 21, Epoch 20/200, Loss: 3.6323273181915283\n",
      "Song 21, Epoch 30/200, Loss: 3.417961597442627\n",
      "Song 21, Epoch 40/200, Loss: 3.1967670917510986\n",
      "Song 21, Epoch 50/200, Loss: 3.019237756729126\n",
      "Song 21, Epoch 60/200, Loss: 2.8257906436920166\n",
      "Song 21, Epoch 70/200, Loss: 2.671964168548584\n",
      "Song 21, Epoch 80/200, Loss: 2.5058157444000244\n",
      "Song 21, Epoch 90/200, Loss: 2.386117696762085\n",
      "Song 21, Epoch 100/200, Loss: 2.3242409229278564\n",
      "Song 21, Epoch 110/200, Loss: 2.274639129638672\n",
      "Song 21, Epoch 120/200, Loss: 2.2475547790527344\n",
      "Song 21, Epoch 130/200, Loss: 2.22505521774292\n",
      "Song 21, Epoch 140/200, Loss: 2.20908522605896\n",
      "Song 21, Epoch 150/200, Loss: 2.201690673828125\n",
      "Song 21, Epoch 160/200, Loss: 2.181929111480713\n",
      "Song 21, Epoch 170/200, Loss: 2.176111936569214\n",
      "Song 21, Epoch 180/200, Loss: 2.1973989009857178\n",
      "Song 21, Epoch 190/200, Loss: 2.1771552562713623\n",
      "Song 21, Epoch 200/200, Loss: 2.1777195930480957\n",
      "Validation Loss after song 21: 3.7005814283322067\n",
      "Training on song 22\n",
      "Song 22, Epoch 10/200, Loss: 3.363604784011841\n",
      "Song 22, Epoch 20/200, Loss: 3.069709300994873\n",
      "Song 22, Epoch 30/200, Loss: 2.780932664871216\n",
      "Song 22, Epoch 40/200, Loss: 2.5676429271698\n",
      "Song 22, Epoch 50/200, Loss: 2.401536464691162\n",
      "Song 22, Epoch 60/200, Loss: 2.3174140453338623\n",
      "Song 22, Epoch 70/200, Loss: 2.2654330730438232\n",
      "Song 22, Epoch 80/200, Loss: 2.2395009994506836\n",
      "Song 22, Epoch 90/200, Loss: 2.212614059448242\n",
      "Song 22, Epoch 100/200, Loss: 2.2042996883392334\n",
      "Song 22, Epoch 110/200, Loss: 2.1882901191711426\n",
      "Song 22, Epoch 120/200, Loss: 2.1744675636291504\n",
      "Song 22, Epoch 130/200, Loss: 2.164475679397583\n",
      "Song 22, Epoch 140/200, Loss: 2.1583123207092285\n",
      "Song 22, Epoch 150/200, Loss: 2.157686948776245\n",
      "Song 22, Epoch 160/200, Loss: 2.14990496635437\n",
      "Song 22, Epoch 170/200, Loss: 2.1433475017547607\n",
      "Song 22, Epoch 180/200, Loss: 2.1454153060913086\n",
      "Song 22, Epoch 190/200, Loss: 2.1400721073150635\n",
      "Song 22, Epoch 200/200, Loss: 2.1387407779693604\n",
      "Validation Loss after song 22: 4.695401148918347\n",
      "Training on song 23\n",
      "Song 23, Epoch 10/200, Loss: 5.948640823364258\n",
      "Song 23, Epoch 20/200, Loss: 5.077266216278076\n",
      "Song 23, Epoch 30/200, Loss: 4.30852746963501\n",
      "Song 23, Epoch 40/200, Loss: 3.7559220790863037\n",
      "Song 23, Epoch 50/200, Loss: 3.309154987335205\n",
      "Song 23, Epoch 60/200, Loss: 2.932996988296509\n",
      "Song 23, Epoch 70/200, Loss: 2.635324239730835\n",
      "Song 23, Epoch 80/200, Loss: 2.4482994079589844\n",
      "Song 23, Epoch 90/200, Loss: 2.330068349838257\n",
      "Song 23, Epoch 100/200, Loss: 2.245471239089966\n",
      "Song 23, Epoch 110/200, Loss: 2.201829195022583\n",
      "Song 23, Epoch 120/200, Loss: 2.1711347103118896\n",
      "Song 23, Epoch 130/200, Loss: 2.1461172103881836\n",
      "Song 23, Epoch 140/200, Loss: 2.1426572799682617\n",
      "Song 23, Epoch 150/200, Loss: 2.1182312965393066\n",
      "Song 23, Epoch 160/200, Loss: 2.107353687286377\n",
      "Song 23, Epoch 170/200, Loss: 2.103370189666748\n",
      "Song 23, Epoch 180/200, Loss: 2.0919158458709717\n",
      "Song 23, Epoch 190/200, Loss: 2.084212303161621\n",
      "Song 23, Epoch 200/200, Loss: 2.087387800216675\n",
      "Validation Loss after song 23: 4.357463689950796\n",
      "Training on song 24\n",
      "Song 24, Epoch 10/200, Loss: 3.277838706970215\n",
      "Song 24, Epoch 20/200, Loss: 3.046584129333496\n",
      "Song 24, Epoch 30/200, Loss: 2.76875901222229\n",
      "Song 24, Epoch 40/200, Loss: 2.6430068016052246\n",
      "Song 24, Epoch 50/200, Loss: 2.5411460399627686\n",
      "Song 24, Epoch 60/200, Loss: 2.4510302543640137\n",
      "Song 24, Epoch 70/200, Loss: 2.4022719860076904\n",
      "Song 24, Epoch 80/200, Loss: 2.3844568729400635\n",
      "Song 24, Epoch 90/200, Loss: 2.3508241176605225\n",
      "Song 24, Epoch 100/200, Loss: 2.339468240737915\n",
      "Song 24, Epoch 110/200, Loss: 2.3168022632598877\n",
      "Song 24, Epoch 120/200, Loss: 2.3090035915374756\n",
      "Song 24, Epoch 130/200, Loss: 2.294896125793457\n",
      "Song 24, Epoch 140/200, Loss: 2.280975580215454\n",
      "Song 24, Epoch 150/200, Loss: 2.266254425048828\n",
      "Song 24, Epoch 160/200, Loss: 2.2608983516693115\n",
      "Song 24, Epoch 170/200, Loss: 2.2565226554870605\n",
      "Song 24, Epoch 180/200, Loss: 2.246464729309082\n",
      "Song 24, Epoch 190/200, Loss: 2.237764358520508\n",
      "Song 24, Epoch 200/200, Loss: 2.2417569160461426\n",
      "Validation Loss after song 24: 3.671735849135961\n",
      "Training on song 25\n",
      "Song 25, Epoch 10/200, Loss: 2.7077953815460205\n",
      "Song 25, Epoch 20/200, Loss: 2.553196668624878\n",
      "Song 25, Epoch 30/200, Loss: 2.3860280513763428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 25, Epoch 40/200, Loss: 2.291566848754883\n",
      "Song 25, Epoch 50/200, Loss: 2.226774215698242\n",
      "Song 25, Epoch 60/200, Loss: 2.194234848022461\n",
      "Song 25, Epoch 70/200, Loss: 2.168586015701294\n",
      "Song 25, Epoch 80/200, Loss: 2.1530163288116455\n",
      "Song 25, Epoch 90/200, Loss: 2.13523530960083\n",
      "Song 25, Epoch 100/200, Loss: 2.121950149536133\n",
      "Song 25, Epoch 110/200, Loss: 2.1156392097473145\n",
      "Song 25, Epoch 120/200, Loss: 2.1084704399108887\n",
      "Song 25, Epoch 130/200, Loss: 2.105189085006714\n",
      "Song 25, Epoch 140/200, Loss: 2.1019062995910645\n",
      "Song 25, Epoch 150/200, Loss: 2.0896739959716797\n",
      "Song 25, Epoch 160/200, Loss: 2.086453914642334\n",
      "Song 25, Epoch 170/200, Loss: 2.0949783325195312\n",
      "Song 25, Epoch 180/200, Loss: 2.097369432449341\n",
      "Song 25, Epoch 190/200, Loss: 2.0895848274230957\n",
      "Song 25, Epoch 200/200, Loss: 2.0840823650360107\n",
      "Validation Loss after song 25: 3.77374224173717\n",
      "Training on song 26\n",
      "Song 26, Epoch 10/200, Loss: 2.638803243637085\n",
      "Song 26, Epoch 20/200, Loss: 2.4735803604125977\n",
      "Song 26, Epoch 30/200, Loss: 2.3316075801849365\n",
      "Song 26, Epoch 40/200, Loss: 2.2338271141052246\n",
      "Song 26, Epoch 50/200, Loss: 2.1713321208953857\n",
      "Song 26, Epoch 60/200, Loss: 2.1212596893310547\n",
      "Song 26, Epoch 70/200, Loss: 2.095315456390381\n",
      "Song 26, Epoch 80/200, Loss: 2.094663381576538\n",
      "Song 26, Epoch 90/200, Loss: 2.06380558013916\n",
      "Song 26, Epoch 100/200, Loss: 2.0521974563598633\n",
      "Song 26, Epoch 110/200, Loss: 2.0454928874969482\n",
      "Song 26, Epoch 120/200, Loss: 2.0672683715820312\n",
      "Song 26, Epoch 130/200, Loss: 2.0506720542907715\n",
      "Song 26, Epoch 140/200, Loss: 2.0039846897125244\n",
      "Song 26, Epoch 150/200, Loss: 2.0072877407073975\n",
      "Song 26, Epoch 160/200, Loss: 1.9998377561569214\n",
      "Song 26, Epoch 170/200, Loss: 1.9936379194259644\n",
      "Song 26, Epoch 180/200, Loss: 1.9945921897888184\n",
      "Song 26, Epoch 190/200, Loss: 1.9881761074066162\n",
      "Song 26, Epoch 200/200, Loss: 1.9708364009857178\n",
      "Validation Loss after song 26: 3.8311265982114353\n",
      "Training on song 27\n",
      "Song 27, Epoch 10/200, Loss: 2.9377551078796387\n",
      "Song 27, Epoch 20/200, Loss: 2.7868685722351074\n",
      "Song 27, Epoch 30/200, Loss: 2.675595760345459\n",
      "Song 27, Epoch 40/200, Loss: 2.554347515106201\n",
      "Song 27, Epoch 50/200, Loss: 2.500016689300537\n",
      "Song 27, Epoch 60/200, Loss: 2.468012571334839\n",
      "Song 27, Epoch 70/200, Loss: 2.3995444774627686\n",
      "Song 27, Epoch 80/200, Loss: 2.379918098449707\n",
      "Song 27, Epoch 90/200, Loss: 2.356966257095337\n",
      "Song 27, Epoch 100/200, Loss: 2.3205347061157227\n",
      "Song 27, Epoch 110/200, Loss: 2.2919907569885254\n",
      "Song 27, Epoch 120/200, Loss: 2.290987968444824\n",
      "Song 27, Epoch 130/200, Loss: 2.2740960121154785\n",
      "Song 27, Epoch 140/200, Loss: 2.263228178024292\n",
      "Song 27, Epoch 150/200, Loss: 2.2589571475982666\n",
      "Song 27, Epoch 160/200, Loss: 2.2735629081726074\n",
      "Song 27, Epoch 170/200, Loss: 2.30391001701355\n",
      "Song 27, Epoch 180/200, Loss: 2.277003526687622\n",
      "Song 27, Epoch 190/200, Loss: 2.317572593688965\n",
      "Song 27, Epoch 200/200, Loss: 2.25771164894104\n",
      "Validation Loss after song 27: 3.5505205667935886\n",
      "Training on song 28\n",
      "Song 28, Epoch 10/200, Loss: 2.409048557281494\n",
      "Song 28, Epoch 20/200, Loss: 2.2654120922088623\n",
      "Song 28, Epoch 30/200, Loss: 2.155205488204956\n",
      "Song 28, Epoch 40/200, Loss: 2.0872414112091064\n",
      "Song 28, Epoch 50/200, Loss: 2.0233936309814453\n",
      "Song 28, Epoch 60/200, Loss: 2.003145456314087\n",
      "Song 28, Epoch 70/200, Loss: 1.9839402437210083\n",
      "Song 28, Epoch 80/200, Loss: 1.9528480768203735\n",
      "Song 28, Epoch 90/200, Loss: 1.9348732233047485\n",
      "Song 28, Epoch 100/200, Loss: 1.924109697341919\n",
      "Song 28, Epoch 110/200, Loss: 1.9136990308761597\n",
      "Song 28, Epoch 120/200, Loss: 1.9049392938613892\n",
      "Song 28, Epoch 130/200, Loss: 1.8994091749191284\n",
      "Song 28, Epoch 140/200, Loss: 1.896586537361145\n",
      "Song 28, Epoch 150/200, Loss: 1.8925899267196655\n",
      "Song 28, Epoch 160/200, Loss: 1.8927900791168213\n",
      "Song 28, Epoch 170/200, Loss: 1.8803386688232422\n",
      "Song 28, Epoch 180/200, Loss: 1.8743152618408203\n",
      "Song 28, Epoch 190/200, Loss: 1.861481785774231\n",
      "Song 28, Epoch 200/200, Loss: 1.878537893295288\n",
      "Validation Loss after song 28: 3.807572242541191\n",
      "Training on song 29\n",
      "Song 29, Epoch 10/200, Loss: 2.779181957244873\n",
      "Song 29, Epoch 20/200, Loss: 2.5725550651550293\n",
      "Song 29, Epoch 30/200, Loss: 2.4270577430725098\n",
      "Song 29, Epoch 40/200, Loss: 2.3318018913269043\n",
      "Song 29, Epoch 50/200, Loss: 2.289970874786377\n",
      "Song 29, Epoch 60/200, Loss: 2.246382474899292\n",
      "Song 29, Epoch 70/200, Loss: 2.2349607944488525\n",
      "Song 29, Epoch 80/200, Loss: 2.2167279720306396\n",
      "Song 29, Epoch 90/200, Loss: 2.1998345851898193\n",
      "Song 29, Epoch 100/200, Loss: 2.183791160583496\n",
      "Song 29, Epoch 110/200, Loss: 2.1898410320281982\n",
      "Song 29, Epoch 120/200, Loss: 2.164503335952759\n",
      "Song 29, Epoch 130/200, Loss: 2.169377088546753\n",
      "Song 29, Epoch 140/200, Loss: 2.163132429122925\n",
      "Song 29, Epoch 150/200, Loss: 2.1509850025177\n",
      "Song 29, Epoch 160/200, Loss: 2.1463518142700195\n",
      "Song 29, Epoch 170/200, Loss: 2.141200065612793\n",
      "Song 29, Epoch 180/200, Loss: 2.132215738296509\n",
      "Song 29, Epoch 190/200, Loss: 2.1304209232330322\n",
      "Song 29, Epoch 200/200, Loss: 2.122213363647461\n",
      "Validation Loss after song 29: 3.8548754147994213\n",
      "Training on song 30\n",
      "Song 30, Epoch 10/200, Loss: 2.3000872135162354\n",
      "Song 30, Epoch 20/200, Loss: 2.21928334236145\n",
      "Song 30, Epoch 30/200, Loss: 2.1479811668395996\n",
      "Song 30, Epoch 40/200, Loss: 2.1049888134002686\n",
      "Song 30, Epoch 50/200, Loss: 2.0817551612854004\n",
      "Song 30, Epoch 60/200, Loss: 2.046409845352173\n",
      "Song 30, Epoch 70/200, Loss: 2.0228378772735596\n",
      "Song 30, Epoch 80/200, Loss: 2.0152111053466797\n",
      "Song 30, Epoch 90/200, Loss: 1.985582947731018\n",
      "Song 30, Epoch 100/200, Loss: 1.9876054525375366\n",
      "Song 30, Epoch 110/200, Loss: 1.9762022495269775\n",
      "Song 30, Epoch 120/200, Loss: 1.9407685995101929\n",
      "Song 30, Epoch 130/200, Loss: 1.9312632083892822\n",
      "Song 30, Epoch 140/200, Loss: 1.9257967472076416\n",
      "Song 30, Epoch 150/200, Loss: 1.9266088008880615\n",
      "Song 30, Epoch 160/200, Loss: 1.9292261600494385\n",
      "Song 30, Epoch 170/200, Loss: 1.887829303741455\n",
      "Song 30, Epoch 180/200, Loss: 1.8822163343429565\n",
      "Song 30, Epoch 190/200, Loss: 1.888293743133545\n",
      "Song 30, Epoch 200/200, Loss: 1.901398777961731\n",
      "Validation Loss after song 30: 3.9248733887305627\n",
      "Training on song 31\n",
      "Song 31, Epoch 10/200, Loss: 2.6350884437561035\n",
      "Song 31, Epoch 20/200, Loss: 2.4861481189727783\n",
      "Song 31, Epoch 30/200, Loss: 2.362654685974121\n",
      "Song 31, Epoch 40/200, Loss: 2.2696480751037598\n",
      "Song 31, Epoch 50/200, Loss: 2.20731258392334\n",
      "Song 31, Epoch 60/200, Loss: 2.15596079826355\n",
      "Song 31, Epoch 70/200, Loss: 2.124189615249634\n",
      "Song 31, Epoch 80/200, Loss: 2.1144278049468994\n",
      "Song 31, Epoch 90/200, Loss: 2.0733816623687744\n",
      "Song 31, Epoch 100/200, Loss: 2.0737838745117188\n",
      "Song 31, Epoch 110/200, Loss: 2.043518543243408\n",
      "Song 31, Epoch 120/200, Loss: 2.0370230674743652\n",
      "Song 31, Epoch 130/200, Loss: 2.0245230197906494\n",
      "Song 31, Epoch 140/200, Loss: 2.032423973083496\n",
      "Song 31, Epoch 150/200, Loss: 2.019731044769287\n",
      "Song 31, Epoch 160/200, Loss: 2.0133464336395264\n",
      "Song 31, Epoch 170/200, Loss: 2.0358996391296387\n",
      "Song 31, Epoch 180/200, Loss: 2.008152484893799\n",
      "Song 31, Epoch 190/200, Loss: 1.992751955986023\n",
      "Song 31, Epoch 200/200, Loss: 2.079601287841797\n",
      "Validation Loss after song 31: 4.015661685894697\n",
      "Training on song 32\n",
      "Song 32, Epoch 10/200, Loss: 2.139798641204834\n",
      "Song 32, Epoch 20/200, Loss: 2.096503496170044\n",
      "Song 32, Epoch 30/200, Loss: 2.065528154373169\n",
      "Song 32, Epoch 40/200, Loss: 2.0453007221221924\n",
      "Song 32, Epoch 50/200, Loss: 2.0343892574310303\n",
      "Song 32, Epoch 60/200, Loss: 2.017580270767212\n",
      "Song 32, Epoch 70/200, Loss: 2.010819435119629\n",
      "Song 32, Epoch 80/200, Loss: 2.0000343322753906\n",
      "Song 32, Epoch 90/200, Loss: 1.9914896488189697\n",
      "Song 32, Epoch 100/200, Loss: 1.9851850271224976\n",
      "Song 32, Epoch 110/200, Loss: 1.9758198261260986\n",
      "Song 32, Epoch 120/200, Loss: 1.973130702972412\n",
      "Song 32, Epoch 130/200, Loss: 1.9665557146072388\n",
      "Song 32, Epoch 140/200, Loss: 1.9631462097167969\n",
      "Song 32, Epoch 150/200, Loss: 1.9590237140655518\n",
      "Song 32, Epoch 160/200, Loss: 1.95524263381958\n",
      "Song 32, Epoch 170/200, Loss: 1.9509068727493286\n",
      "Song 32, Epoch 180/200, Loss: 1.9497376680374146\n",
      "Song 32, Epoch 190/200, Loss: 1.9452890157699585\n",
      "Song 32, Epoch 200/200, Loss: 1.9423738718032837\n",
      "Validation Loss after song 32: 4.111695460784129\n",
      "Training on song 33\n",
      "Song 33, Epoch 10/200, Loss: 2.9273533821105957\n",
      "Song 33, Epoch 20/200, Loss: 2.7422969341278076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 33, Epoch 30/200, Loss: 2.5470468997955322\n",
      "Song 33, Epoch 40/200, Loss: 2.3948047161102295\n",
      "Song 33, Epoch 50/200, Loss: 2.243260383605957\n",
      "Song 33, Epoch 60/200, Loss: 2.168640375137329\n",
      "Song 33, Epoch 70/200, Loss: 2.125826835632324\n",
      "Song 33, Epoch 80/200, Loss: 2.0666584968566895\n",
      "Song 33, Epoch 90/200, Loss: 2.045847177505493\n",
      "Song 33, Epoch 100/200, Loss: 2.0207386016845703\n",
      "Song 33, Epoch 110/200, Loss: 2.0069022178649902\n",
      "Song 33, Epoch 120/200, Loss: 1.9908298254013062\n",
      "Song 33, Epoch 130/200, Loss: 1.9825571775436401\n",
      "Song 33, Epoch 140/200, Loss: 1.9723107814788818\n",
      "Song 33, Epoch 150/200, Loss: 1.9701025485992432\n",
      "Song 33, Epoch 160/200, Loss: 1.9617831707000732\n",
      "Song 33, Epoch 170/200, Loss: 1.9570281505584717\n",
      "Song 33, Epoch 180/200, Loss: 1.949556827545166\n",
      "Song 33, Epoch 190/200, Loss: 1.9446098804473877\n",
      "Song 33, Epoch 200/200, Loss: 1.9563541412353516\n",
      "Validation Loss after song 33: 3.935076872507731\n",
      "Training on song 34\n",
      "Song 34, Epoch 10/200, Loss: 4.0492963790893555\n",
      "Song 34, Epoch 20/200, Loss: 3.4140307903289795\n",
      "Song 34, Epoch 30/200, Loss: 3.013880491256714\n",
      "Song 34, Epoch 40/200, Loss: 2.7224674224853516\n",
      "Song 34, Epoch 50/200, Loss: 2.5165293216705322\n",
      "Song 34, Epoch 60/200, Loss: 2.4086172580718994\n",
      "Song 34, Epoch 70/200, Loss: 2.320977210998535\n",
      "Song 34, Epoch 80/200, Loss: 2.2738444805145264\n",
      "Song 34, Epoch 90/200, Loss: 2.2459492683410645\n",
      "Song 34, Epoch 100/200, Loss: 2.2108535766601562\n",
      "Song 34, Epoch 110/200, Loss: 2.187588930130005\n",
      "Song 34, Epoch 120/200, Loss: 2.1639556884765625\n",
      "Song 34, Epoch 130/200, Loss: 2.1679675579071045\n",
      "Song 34, Epoch 140/200, Loss: 2.1309616565704346\n",
      "Song 34, Epoch 150/200, Loss: 2.129700183868408\n",
      "Song 34, Epoch 160/200, Loss: 2.111062526702881\n",
      "Song 34, Epoch 170/200, Loss: 2.1104068756103516\n",
      "Song 34, Epoch 180/200, Loss: 2.0962367057800293\n",
      "Song 34, Epoch 190/200, Loss: 2.1247103214263916\n",
      "Song 34, Epoch 200/200, Loss: 2.1016969680786133\n",
      "Validation Loss after song 34: 4.5417064642294855\n",
      "Training on song 35\n",
      "Song 35, Epoch 10/200, Loss: 4.142385482788086\n",
      "Song 35, Epoch 20/200, Loss: 3.5892300605773926\n",
      "Song 35, Epoch 30/200, Loss: 3.1010990142822266\n",
      "Song 35, Epoch 40/200, Loss: 2.7927756309509277\n",
      "Song 35, Epoch 50/200, Loss: 2.5750749111175537\n",
      "Song 35, Epoch 60/200, Loss: 2.4563405513763428\n",
      "Song 35, Epoch 70/200, Loss: 2.3630270957946777\n",
      "Song 35, Epoch 80/200, Loss: 2.3064534664154053\n",
      "Song 35, Epoch 90/200, Loss: 2.266906499862671\n",
      "Song 35, Epoch 100/200, Loss: 2.2426350116729736\n",
      "Song 35, Epoch 110/200, Loss: 2.229200601577759\n",
      "Song 35, Epoch 120/200, Loss: 2.211571216583252\n",
      "Song 35, Epoch 130/200, Loss: 2.1995816230773926\n",
      "Song 35, Epoch 140/200, Loss: 2.187241554260254\n",
      "Song 35, Epoch 150/200, Loss: 2.177485466003418\n",
      "Song 35, Epoch 160/200, Loss: 2.172565221786499\n",
      "Song 35, Epoch 170/200, Loss: 2.1735129356384277\n",
      "Song 35, Epoch 180/200, Loss: 2.15762996673584\n",
      "Song 35, Epoch 190/200, Loss: 2.167372226715088\n",
      "Song 35, Epoch 200/200, Loss: 2.1345157623291016\n",
      "Validation Loss after song 35: 3.499923663261609\n",
      "Training on song 36\n",
      "Song 36, Epoch 10/200, Loss: 3.1116340160369873\n",
      "Song 36, Epoch 20/200, Loss: 2.921755075454712\n",
      "Song 36, Epoch 30/200, Loss: 2.7752323150634766\n",
      "Song 36, Epoch 40/200, Loss: 2.6685774326324463\n",
      "Song 36, Epoch 50/200, Loss: 2.58670973777771\n",
      "Song 36, Epoch 60/200, Loss: 2.5297915935516357\n",
      "Song 36, Epoch 70/200, Loss: 2.4782509803771973\n",
      "Song 36, Epoch 80/200, Loss: 2.441253900527954\n",
      "Song 36, Epoch 90/200, Loss: 2.404463768005371\n",
      "Song 36, Epoch 100/200, Loss: 2.375061273574829\n",
      "Song 36, Epoch 110/200, Loss: 2.3461129665374756\n",
      "Song 36, Epoch 120/200, Loss: 2.3206300735473633\n",
      "Song 36, Epoch 130/200, Loss: 2.299065113067627\n",
      "Song 36, Epoch 140/200, Loss: 2.2821033000946045\n",
      "Song 36, Epoch 150/200, Loss: 2.2724075317382812\n",
      "Song 36, Epoch 160/200, Loss: 2.2602531909942627\n",
      "Song 36, Epoch 170/200, Loss: 2.253051996231079\n",
      "Song 36, Epoch 180/200, Loss: 2.245962381362915\n",
      "Song 36, Epoch 190/200, Loss: 2.2406091690063477\n",
      "Song 36, Epoch 200/200, Loss: 2.2356653213500977\n",
      "Validation Loss after song 36: 3.542448483980619\n",
      "Training on song 37\n",
      "Song 37, Epoch 10/200, Loss: 2.7054920196533203\n",
      "Song 37, Epoch 20/200, Loss: 2.601454973220825\n",
      "Song 37, Epoch 30/200, Loss: 2.5057783126831055\n",
      "Song 37, Epoch 40/200, Loss: 2.417297124862671\n",
      "Song 37, Epoch 50/200, Loss: 2.3543734550476074\n",
      "Song 37, Epoch 60/200, Loss: 2.3046019077301025\n",
      "Song 37, Epoch 70/200, Loss: 2.2736024856567383\n",
      "Song 37, Epoch 80/200, Loss: 2.2498748302459717\n",
      "Song 37, Epoch 90/200, Loss: 2.2303225994110107\n",
      "Song 37, Epoch 100/200, Loss: 2.2062675952911377\n",
      "Song 37, Epoch 110/200, Loss: 2.190537691116333\n",
      "Song 37, Epoch 120/200, Loss: 2.1825385093688965\n",
      "Song 37, Epoch 130/200, Loss: 2.170145034790039\n",
      "Song 37, Epoch 140/200, Loss: 2.1674156188964844\n",
      "Song 37, Epoch 150/200, Loss: 2.1649770736694336\n",
      "Song 37, Epoch 160/200, Loss: 2.153839349746704\n",
      "Song 37, Epoch 170/200, Loss: 2.1499249935150146\n",
      "Song 37, Epoch 180/200, Loss: 2.136094570159912\n",
      "Song 37, Epoch 190/200, Loss: 2.1559433937072754\n",
      "Song 37, Epoch 200/200, Loss: 2.1211414337158203\n",
      "Validation Loss after song 37: 3.8305034881983047\n",
      "Training on song 38\n",
      "Song 38, Epoch 10/200, Loss: 2.291159152984619\n",
      "Song 38, Epoch 20/200, Loss: 2.2343037128448486\n",
      "Song 38, Epoch 30/200, Loss: 2.1867494583129883\n",
      "Song 38, Epoch 40/200, Loss: 2.1546854972839355\n",
      "Song 38, Epoch 50/200, Loss: 2.1312968730926514\n",
      "Song 38, Epoch 60/200, Loss: 2.115535020828247\n",
      "Song 38, Epoch 70/200, Loss: 2.1014554500579834\n",
      "Song 38, Epoch 80/200, Loss: 2.088040828704834\n",
      "Song 38, Epoch 90/200, Loss: 2.0763676166534424\n",
      "Song 38, Epoch 100/200, Loss: 2.0749764442443848\n",
      "Song 38, Epoch 110/200, Loss: 2.065237283706665\n",
      "Song 38, Epoch 120/200, Loss: 2.058042526245117\n",
      "Song 38, Epoch 130/200, Loss: 2.0525434017181396\n",
      "Song 38, Epoch 140/200, Loss: 2.047149658203125\n",
      "Song 38, Epoch 150/200, Loss: 2.040937900543213\n",
      "Song 38, Epoch 160/200, Loss: 2.0367157459259033\n",
      "Song 38, Epoch 170/200, Loss: 2.0324196815490723\n",
      "Song 38, Epoch 180/200, Loss: 2.018810987472534\n",
      "Song 38, Epoch 190/200, Loss: 2.0128977298736572\n",
      "Song 38, Epoch 200/200, Loss: 2.0119075775146484\n",
      "Validation Loss after song 38: 3.972755334316156\n",
      "Training on song 39\n",
      "Song 39, Epoch 10/200, Loss: 4.5706706047058105\n",
      "Song 39, Epoch 20/200, Loss: 4.186135768890381\n",
      "Song 39, Epoch 30/200, Loss: 3.8096678256988525\n",
      "Song 39, Epoch 40/200, Loss: 3.498826026916504\n",
      "Song 39, Epoch 50/200, Loss: 3.1899056434631348\n",
      "Song 39, Epoch 60/200, Loss: 3.0372657775878906\n",
      "Song 39, Epoch 70/200, Loss: 2.8654990196228027\n",
      "Song 39, Epoch 80/200, Loss: 2.7358345985412598\n",
      "Song 39, Epoch 90/200, Loss: 2.6177635192871094\n",
      "Song 39, Epoch 100/200, Loss: 2.455390691757202\n",
      "Song 39, Epoch 110/200, Loss: 2.327017307281494\n",
      "Song 39, Epoch 120/200, Loss: 2.2476823329925537\n",
      "Song 39, Epoch 130/200, Loss: 2.1841177940368652\n",
      "Song 39, Epoch 140/200, Loss: 2.1548848152160645\n",
      "Song 39, Epoch 150/200, Loss: 2.131028890609741\n",
      "Song 39, Epoch 160/200, Loss: 2.1196515560150146\n",
      "Song 39, Epoch 170/200, Loss: 2.104402542114258\n",
      "Song 39, Epoch 180/200, Loss: 2.098853826522827\n",
      "Song 39, Epoch 190/200, Loss: 2.0946741104125977\n",
      "Song 39, Epoch 200/200, Loss: 2.1071395874023438\n",
      "Validation Loss after song 39: 4.175036674890762\n",
      "Training on song 40\n",
      "Song 40, Epoch 10/200, Loss: 3.0181102752685547\n",
      "Song 40, Epoch 20/200, Loss: 2.849820852279663\n",
      "Song 40, Epoch 30/200, Loss: 2.7326416969299316\n",
      "Song 40, Epoch 40/200, Loss: 2.652569532394409\n",
      "Song 40, Epoch 50/200, Loss: 2.5925652980804443\n",
      "Song 40, Epoch 60/200, Loss: 2.545295238494873\n",
      "Song 40, Epoch 70/200, Loss: 2.5114424228668213\n",
      "Song 40, Epoch 80/200, Loss: 2.461263656616211\n",
      "Song 40, Epoch 90/200, Loss: 2.4399807453155518\n",
      "Song 40, Epoch 100/200, Loss: 2.4153554439544678\n",
      "Song 40, Epoch 110/200, Loss: 2.4004158973693848\n",
      "Song 40, Epoch 120/200, Loss: 2.3766353130340576\n",
      "Song 40, Epoch 130/200, Loss: 2.3521528244018555\n",
      "Song 40, Epoch 140/200, Loss: 2.3443217277526855\n",
      "Song 40, Epoch 150/200, Loss: 2.327268362045288\n",
      "Song 40, Epoch 160/200, Loss: 2.321335554122925\n",
      "Song 40, Epoch 170/200, Loss: 2.3035786151885986\n",
      "Song 40, Epoch 180/200, Loss: 2.2881019115448\n",
      "Song 40, Epoch 190/200, Loss: 2.306044578552246\n",
      "Song 40, Epoch 200/200, Loss: 2.2874197959899902\n",
      "Validation Loss after song 40: 3.6412589183220496\n",
      "Training on song 41\n",
      "Song 41, Epoch 10/200, Loss: 2.735846757888794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 41, Epoch 20/200, Loss: 2.6538851261138916\n",
      "Song 41, Epoch 30/200, Loss: 2.57242488861084\n",
      "Song 41, Epoch 40/200, Loss: 2.4994864463806152\n",
      "Song 41, Epoch 50/200, Loss: 2.4305999279022217\n",
      "Song 41, Epoch 60/200, Loss: 2.377156972885132\n",
      "Song 41, Epoch 70/200, Loss: 2.335822105407715\n",
      "Song 41, Epoch 80/200, Loss: 2.293043375015259\n",
      "Song 41, Epoch 90/200, Loss: 2.2481942176818848\n",
      "Song 41, Epoch 100/200, Loss: 2.22186017036438\n",
      "Song 41, Epoch 110/200, Loss: 2.1973659992218018\n",
      "Song 41, Epoch 120/200, Loss: 2.169771671295166\n",
      "Song 41, Epoch 130/200, Loss: 2.164177656173706\n",
      "Song 41, Epoch 140/200, Loss: 2.1425271034240723\n",
      "Song 41, Epoch 150/200, Loss: 2.1272289752960205\n",
      "Song 41, Epoch 160/200, Loss: 2.1174094676971436\n",
      "Song 41, Epoch 170/200, Loss: 2.1052908897399902\n",
      "Song 41, Epoch 180/200, Loss: 2.0966429710388184\n",
      "Song 41, Epoch 190/200, Loss: 2.202662706375122\n",
      "Song 41, Epoch 200/200, Loss: 2.077652931213379\n",
      "Validation Loss after song 41: 3.98932399505224\n",
      "Training on song 42\n",
      "Song 42, Epoch 10/200, Loss: 3.344644784927368\n",
      "Song 42, Epoch 20/200, Loss: 3.116710662841797\n",
      "Song 42, Epoch 30/200, Loss: 2.9165804386138916\n",
      "Song 42, Epoch 40/200, Loss: 2.7401368618011475\n",
      "Song 42, Epoch 50/200, Loss: 2.5959982872009277\n",
      "Song 42, Epoch 60/200, Loss: 2.5090091228485107\n",
      "Song 42, Epoch 70/200, Loss: 2.429826259613037\n",
      "Song 42, Epoch 80/200, Loss: 2.3893141746520996\n",
      "Song 42, Epoch 90/200, Loss: 2.3241283893585205\n",
      "Song 42, Epoch 100/200, Loss: 2.2850780487060547\n",
      "Song 42, Epoch 110/200, Loss: 2.258601188659668\n",
      "Song 42, Epoch 120/200, Loss: 2.214857339859009\n",
      "Song 42, Epoch 130/200, Loss: 2.197664976119995\n",
      "Song 42, Epoch 140/200, Loss: 2.1642675399780273\n",
      "Song 42, Epoch 150/200, Loss: 2.1610195636749268\n",
      "Song 42, Epoch 160/200, Loss: 2.1345624923706055\n",
      "Song 42, Epoch 170/200, Loss: 2.1229586601257324\n",
      "Song 42, Epoch 180/200, Loss: 2.109739303588867\n",
      "Song 42, Epoch 190/200, Loss: 2.0972001552581787\n",
      "Song 42, Epoch 200/200, Loss: 2.0783090591430664\n",
      "Validation Loss after song 42: 4.280775174116477\n",
      "Training on song 43\n",
      "Song 43, Epoch 10/200, Loss: 2.5645370483398438\n",
      "Song 43, Epoch 20/200, Loss: 2.4786877632141113\n",
      "Song 43, Epoch 30/200, Loss: 2.407193660736084\n",
      "Song 43, Epoch 40/200, Loss: 2.3677048683166504\n",
      "Song 43, Epoch 50/200, Loss: 2.3268163204193115\n",
      "Song 43, Epoch 60/200, Loss: 2.2889723777770996\n",
      "Song 43, Epoch 70/200, Loss: 2.247731924057007\n",
      "Song 43, Epoch 80/200, Loss: 2.245979070663452\n",
      "Song 43, Epoch 90/200, Loss: 2.198082447052002\n",
      "Song 43, Epoch 100/200, Loss: 2.1759321689605713\n",
      "Song 43, Epoch 110/200, Loss: 2.164605140686035\n",
      "Song 43, Epoch 120/200, Loss: 2.145319700241089\n",
      "Song 43, Epoch 130/200, Loss: 2.127579689025879\n",
      "Song 43, Epoch 140/200, Loss: 2.0878453254699707\n",
      "Song 43, Epoch 150/200, Loss: 2.0783987045288086\n",
      "Song 43, Epoch 160/200, Loss: 2.045424461364746\n",
      "Song 43, Epoch 170/200, Loss: 2.0783588886260986\n",
      "Song 43, Epoch 180/200, Loss: 2.0584611892700195\n",
      "Song 43, Epoch 190/200, Loss: 2.025932788848877\n",
      "Song 43, Epoch 200/200, Loss: 2.005474090576172\n",
      "Validation Loss after song 43: 4.0717477309398165\n",
      "Training on song 44\n",
      "Song 44, Epoch 10/200, Loss: 2.615560293197632\n",
      "Song 44, Epoch 20/200, Loss: 2.4762582778930664\n",
      "Song 44, Epoch 30/200, Loss: 2.334455728530884\n",
      "Song 44, Epoch 40/200, Loss: 2.2335400581359863\n",
      "Song 44, Epoch 50/200, Loss: 2.155754566192627\n",
      "Song 44, Epoch 60/200, Loss: 2.104318141937256\n",
      "Song 44, Epoch 70/200, Loss: 2.0571985244750977\n",
      "Song 44, Epoch 80/200, Loss: 2.021981716156006\n",
      "Song 44, Epoch 90/200, Loss: 2.0306344032287598\n",
      "Song 44, Epoch 100/200, Loss: 1.9517347812652588\n",
      "Song 44, Epoch 110/200, Loss: 1.9456231594085693\n",
      "Song 44, Epoch 120/200, Loss: 1.9157687425613403\n",
      "Song 44, Epoch 130/200, Loss: 1.905621886253357\n",
      "Song 44, Epoch 140/200, Loss: 1.8880407810211182\n",
      "Song 44, Epoch 150/200, Loss: 1.875119686126709\n",
      "Song 44, Epoch 160/200, Loss: 1.8669401407241821\n",
      "Song 44, Epoch 170/200, Loss: 1.8685520887374878\n",
      "Song 44, Epoch 180/200, Loss: 1.8485968112945557\n",
      "Song 44, Epoch 190/200, Loss: 1.8479701280593872\n",
      "Song 44, Epoch 200/200, Loss: 1.8375020027160645\n",
      "Validation Loss after song 44: 3.9305165975521774\n",
      "Training on song 45\n",
      "Song 45, Epoch 10/200, Loss: 4.463911056518555\n",
      "Song 45, Epoch 20/200, Loss: 3.8808722496032715\n",
      "Song 45, Epoch 30/200, Loss: 3.386246919631958\n",
      "Song 45, Epoch 40/200, Loss: 2.940089225769043\n",
      "Song 45, Epoch 50/200, Loss: 2.671534776687622\n",
      "Song 45, Epoch 60/200, Loss: 2.4672770500183105\n",
      "Song 45, Epoch 70/200, Loss: 2.359975576400757\n",
      "Song 45, Epoch 80/200, Loss: 2.2904818058013916\n",
      "Song 45, Epoch 90/200, Loss: 2.2650680541992188\n",
      "Song 45, Epoch 100/200, Loss: 2.212102174758911\n",
      "Song 45, Epoch 110/200, Loss: 2.203664779663086\n",
      "Song 45, Epoch 120/200, Loss: 2.17927885055542\n",
      "Song 45, Epoch 130/200, Loss: 2.1626200675964355\n",
      "Song 45, Epoch 140/200, Loss: 2.1449763774871826\n",
      "Song 45, Epoch 150/200, Loss: 2.1355528831481934\n",
      "Song 45, Epoch 160/200, Loss: 2.1215455532073975\n",
      "Song 45, Epoch 170/200, Loss: 2.113999128341675\n",
      "Song 45, Epoch 180/200, Loss: 2.1119775772094727\n",
      "Song 45, Epoch 190/200, Loss: 2.12662935256958\n",
      "Song 45, Epoch 200/200, Loss: 2.097857713699341\n",
      "Validation Loss after song 45: 4.054991923845732\n",
      "Training on song 46\n",
      "Song 46, Epoch 10/200, Loss: 3.6812832355499268\n",
      "Song 46, Epoch 20/200, Loss: 3.3286097049713135\n",
      "Song 46, Epoch 30/200, Loss: 2.965031147003174\n",
      "Song 46, Epoch 40/200, Loss: 2.7921838760375977\n",
      "Song 46, Epoch 50/200, Loss: 2.6291439533233643\n",
      "Song 46, Epoch 60/200, Loss: 2.543072462081909\n",
      "Song 46, Epoch 70/200, Loss: 2.4494776725769043\n",
      "Song 46, Epoch 80/200, Loss: 2.397677183151245\n",
      "Song 46, Epoch 90/200, Loss: 2.370760679244995\n",
      "Song 46, Epoch 100/200, Loss: 2.34093976020813\n",
      "Song 46, Epoch 110/200, Loss: 2.3153271675109863\n",
      "Song 46, Epoch 120/200, Loss: 2.2817957401275635\n",
      "Song 46, Epoch 130/200, Loss: 2.26001238822937\n",
      "Song 46, Epoch 140/200, Loss: 2.2529406547546387\n",
      "Song 46, Epoch 150/200, Loss: 2.2363808155059814\n",
      "Song 46, Epoch 160/200, Loss: 2.22812819480896\n",
      "Song 46, Epoch 170/200, Loss: 2.2264645099639893\n",
      "Song 46, Epoch 180/200, Loss: 2.2339224815368652\n",
      "Song 46, Epoch 190/200, Loss: 2.2141270637512207\n",
      "Song 46, Epoch 200/200, Loss: 2.2312707901000977\n",
      "Validation Loss after song 46: 3.8046135474474\n",
      "Training on song 47\n",
      "Song 47, Epoch 10/200, Loss: 2.6106581687927246\n",
      "Song 47, Epoch 20/200, Loss: 2.4673006534576416\n",
      "Song 47, Epoch 30/200, Loss: 2.354945659637451\n",
      "Song 47, Epoch 40/200, Loss: 2.2535200119018555\n",
      "Song 47, Epoch 50/200, Loss: 2.168156385421753\n",
      "Song 47, Epoch 60/200, Loss: 2.1136834621429443\n",
      "Song 47, Epoch 70/200, Loss: 2.0462446212768555\n",
      "Song 47, Epoch 80/200, Loss: 1.9884774684906006\n",
      "Song 47, Epoch 90/200, Loss: 1.9636828899383545\n",
      "Song 47, Epoch 100/200, Loss: 1.9469120502471924\n",
      "Song 47, Epoch 110/200, Loss: 1.9496183395385742\n",
      "Song 47, Epoch 120/200, Loss: 1.8944296836853027\n",
      "Song 47, Epoch 130/200, Loss: 1.8812679052352905\n",
      "Song 47, Epoch 140/200, Loss: 1.8574535846710205\n",
      "Song 47, Epoch 150/200, Loss: 1.8414503335952759\n",
      "Song 47, Epoch 160/200, Loss: 1.8385416269302368\n",
      "Song 47, Epoch 170/200, Loss: 1.8226872682571411\n",
      "Song 47, Epoch 180/200, Loss: 1.809698224067688\n",
      "Song 47, Epoch 190/200, Loss: 1.8553022146224976\n",
      "Song 47, Epoch 200/200, Loss: 1.8277361392974854\n",
      "Validation Loss after song 47: 3.7427419882554274\n",
      "Training on song 48\n",
      "Song 48, Epoch 10/200, Loss: 3.1543831825256348\n",
      "Song 48, Epoch 20/200, Loss: 2.9846484661102295\n",
      "Song 48, Epoch 30/200, Loss: 2.7950587272644043\n",
      "Song 48, Epoch 40/200, Loss: 2.687223196029663\n",
      "Song 48, Epoch 50/200, Loss: 2.610163450241089\n",
      "Song 48, Epoch 60/200, Loss: 2.536956787109375\n",
      "Song 48, Epoch 70/200, Loss: 2.4580039978027344\n",
      "Song 48, Epoch 80/200, Loss: 2.4403653144836426\n",
      "Song 48, Epoch 90/200, Loss: 2.393580436706543\n",
      "Song 48, Epoch 100/200, Loss: 2.3434805870056152\n",
      "Song 48, Epoch 110/200, Loss: 2.3110570907592773\n",
      "Song 48, Epoch 120/200, Loss: 2.2838118076324463\n",
      "Song 48, Epoch 130/200, Loss: 2.235262393951416\n",
      "Song 48, Epoch 140/200, Loss: 2.224151134490967\n",
      "Song 48, Epoch 150/200, Loss: 2.1951942443847656\n",
      "Song 48, Epoch 160/200, Loss: 2.1658432483673096\n",
      "Song 48, Epoch 170/200, Loss: 2.1565637588500977\n",
      "Song 48, Epoch 180/200, Loss: 2.2375195026397705\n",
      "Song 48, Epoch 190/200, Loss: 2.1734635829925537\n",
      "Song 48, Epoch 200/200, Loss: 2.158393144607544\n",
      "Validation Loss after song 48: 3.7451825753236427\n",
      "Training on song 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 49, Epoch 10/200, Loss: 2.603864908218384\n",
      "Song 49, Epoch 20/200, Loss: 2.496540069580078\n",
      "Song 49, Epoch 30/200, Loss: 2.407636880874634\n",
      "Song 49, Epoch 40/200, Loss: 2.3412463665008545\n",
      "Song 49, Epoch 50/200, Loss: 2.2823119163513184\n",
      "Song 49, Epoch 60/200, Loss: 2.23673939704895\n",
      "Song 49, Epoch 70/200, Loss: 2.204530715942383\n",
      "Song 49, Epoch 80/200, Loss: 2.1632094383239746\n",
      "Song 49, Epoch 90/200, Loss: 2.138995885848999\n",
      "Song 49, Epoch 100/200, Loss: 2.119131565093994\n",
      "Song 49, Epoch 110/200, Loss: 2.126384735107422\n",
      "Song 49, Epoch 120/200, Loss: 2.114025592803955\n",
      "Song 49, Epoch 130/200, Loss: 2.068538188934326\n",
      "Song 49, Epoch 140/200, Loss: 2.0594027042388916\n",
      "Song 49, Epoch 150/200, Loss: 2.053783655166626\n",
      "Song 49, Epoch 160/200, Loss: 2.0493686199188232\n",
      "Song 49, Epoch 170/200, Loss: 2.0406222343444824\n",
      "Song 49, Epoch 180/200, Loss: 2.0369656085968018\n",
      "Song 49, Epoch 190/200, Loss: 2.030867099761963\n",
      "Song 49, Epoch 200/200, Loss: 2.013341188430786\n",
      "Validation Loss after song 49: 3.6905514032412796\n",
      "Training on song 50\n",
      "Song 50, Epoch 10/200, Loss: 2.3796703815460205\n",
      "Song 50, Epoch 20/200, Loss: 2.319979667663574\n",
      "Song 50, Epoch 30/200, Loss: 2.238764762878418\n",
      "Song 50, Epoch 40/200, Loss: 2.224123477935791\n",
      "Song 50, Epoch 50/200, Loss: 2.196009397506714\n",
      "Song 50, Epoch 60/200, Loss: 2.1463420391082764\n",
      "Song 50, Epoch 70/200, Loss: 2.1454362869262695\n",
      "Song 50, Epoch 80/200, Loss: 2.10262131690979\n",
      "Song 50, Epoch 90/200, Loss: 2.0734126567840576\n",
      "Song 50, Epoch 100/200, Loss: 2.05411958694458\n",
      "Song 50, Epoch 110/200, Loss: 2.0472612380981445\n",
      "Song 50, Epoch 120/200, Loss: 2.0490894317626953\n",
      "Song 50, Epoch 130/200, Loss: 2.0054407119750977\n",
      "Song 50, Epoch 140/200, Loss: 1.9973676204681396\n",
      "Song 50, Epoch 150/200, Loss: 1.990509271621704\n",
      "Song 50, Epoch 160/200, Loss: 1.978376865386963\n",
      "Song 50, Epoch 170/200, Loss: 1.9715919494628906\n",
      "Song 50, Epoch 180/200, Loss: 1.9633032083511353\n",
      "Song 50, Epoch 190/200, Loss: 1.960427165031433\n",
      "Song 50, Epoch 200/200, Loss: 1.9532723426818848\n",
      "Validation Loss after song 50: 3.856759175276145\n",
      "Training on song 51\n",
      "Song 51, Epoch 10/200, Loss: 2.8922336101531982\n",
      "Song 51, Epoch 20/200, Loss: 2.739898204803467\n",
      "Song 51, Epoch 30/200, Loss: 2.6156554222106934\n",
      "Song 51, Epoch 40/200, Loss: 2.523207664489746\n",
      "Song 51, Epoch 50/200, Loss: 2.436744451522827\n",
      "Song 51, Epoch 60/200, Loss: 2.376826524734497\n",
      "Song 51, Epoch 70/200, Loss: 2.336456775665283\n",
      "Song 51, Epoch 80/200, Loss: 2.294053077697754\n",
      "Song 51, Epoch 90/200, Loss: 2.264662265777588\n",
      "Song 51, Epoch 100/200, Loss: 2.227905035018921\n",
      "Song 51, Epoch 110/200, Loss: 2.211805820465088\n",
      "Song 51, Epoch 120/200, Loss: 2.2001473903656006\n",
      "Song 51, Epoch 130/200, Loss: 2.1863508224487305\n",
      "Song 51, Epoch 140/200, Loss: 2.179234743118286\n",
      "Song 51, Epoch 150/200, Loss: 2.155381679534912\n",
      "Song 51, Epoch 160/200, Loss: 2.156996011734009\n",
      "Song 51, Epoch 170/200, Loss: 2.1505439281463623\n",
      "Song 51, Epoch 180/200, Loss: 2.1430068016052246\n",
      "Song 51, Epoch 190/200, Loss: 2.144644021987915\n",
      "Song 51, Epoch 200/200, Loss: 2.14886474609375\n",
      "Validation Loss after song 51: 3.7195028158334584\n",
      "Training on song 52\n",
      "Song 52, Epoch 10/200, Loss: 2.627775192260742\n",
      "Song 52, Epoch 20/200, Loss: 2.5132150650024414\n",
      "Song 52, Epoch 30/200, Loss: 2.42248797416687\n",
      "Song 52, Epoch 40/200, Loss: 2.4252638816833496\n",
      "Song 52, Epoch 50/200, Loss: 2.307753562927246\n",
      "Song 52, Epoch 60/200, Loss: 2.257962226867676\n",
      "Song 52, Epoch 70/200, Loss: 2.21297025680542\n",
      "Song 52, Epoch 80/200, Loss: 2.1586246490478516\n",
      "Song 52, Epoch 90/200, Loss: 2.144209623336792\n",
      "Song 52, Epoch 100/200, Loss: 2.106534957885742\n",
      "Song 52, Epoch 110/200, Loss: 2.074504852294922\n",
      "Song 52, Epoch 120/200, Loss: 2.068765163421631\n",
      "Song 52, Epoch 130/200, Loss: 2.0472278594970703\n",
      "Song 52, Epoch 140/200, Loss: 2.0606603622436523\n",
      "Song 52, Epoch 150/200, Loss: 2.0376720428466797\n",
      "Song 52, Epoch 160/200, Loss: 2.031660795211792\n",
      "Song 52, Epoch 170/200, Loss: 2.022068738937378\n",
      "Song 52, Epoch 180/200, Loss: 2.035961151123047\n",
      "Song 52, Epoch 190/200, Loss: 2.082644462585449\n",
      "Song 52, Epoch 200/200, Loss: 2.0214591026306152\n",
      "Validation Loss after song 52: 3.8067087638072477\n",
      "Training on song 53\n",
      "Song 53, Epoch 10/200, Loss: 2.742332696914673\n",
      "Song 53, Epoch 20/200, Loss: 2.6203696727752686\n",
      "Song 53, Epoch 30/200, Loss: 2.502924680709839\n",
      "Song 53, Epoch 40/200, Loss: 2.406059503555298\n",
      "Song 53, Epoch 50/200, Loss: 2.341718912124634\n",
      "Song 53, Epoch 60/200, Loss: 2.297132730484009\n",
      "Song 53, Epoch 70/200, Loss: 2.2616944313049316\n",
      "Song 53, Epoch 80/200, Loss: 2.228358030319214\n",
      "Song 53, Epoch 90/200, Loss: 2.222959518432617\n",
      "Song 53, Epoch 100/200, Loss: 2.1701040267944336\n",
      "Song 53, Epoch 110/200, Loss: 2.141011953353882\n",
      "Song 53, Epoch 120/200, Loss: 2.1423182487487793\n",
      "Song 53, Epoch 130/200, Loss: 2.1155447959899902\n",
      "Song 53, Epoch 140/200, Loss: 2.1064789295196533\n",
      "Song 53, Epoch 150/200, Loss: 2.099346160888672\n",
      "Song 53, Epoch 160/200, Loss: 2.0887410640716553\n",
      "Song 53, Epoch 170/200, Loss: 2.074786901473999\n",
      "Song 53, Epoch 180/200, Loss: 2.080044984817505\n",
      "Song 53, Epoch 190/200, Loss: 2.0751495361328125\n",
      "Song 53, Epoch 200/200, Loss: 2.0691425800323486\n",
      "Validation Loss after song 53: 3.94962870157682\n",
      "Training on song 54\n",
      "Song 54, Epoch 10/200, Loss: 2.6893444061279297\n",
      "Song 54, Epoch 20/200, Loss: 2.5006866455078125\n",
      "Song 54, Epoch 30/200, Loss: 2.3946189880371094\n",
      "Song 54, Epoch 40/200, Loss: 2.271764039993286\n",
      "Song 54, Epoch 50/200, Loss: 2.196819543838501\n",
      "Song 54, Epoch 60/200, Loss: 2.1330857276916504\n",
      "Song 54, Epoch 70/200, Loss: 2.087924003601074\n",
      "Song 54, Epoch 80/200, Loss: 2.053525447845459\n",
      "Song 54, Epoch 90/200, Loss: 2.0261123180389404\n",
      "Song 54, Epoch 100/200, Loss: 2.0129497051239014\n",
      "Song 54, Epoch 110/200, Loss: 2.004307746887207\n",
      "Song 54, Epoch 120/200, Loss: 1.9930789470672607\n",
      "Song 54, Epoch 130/200, Loss: 1.9855190515518188\n",
      "Song 54, Epoch 140/200, Loss: 1.9794319868087769\n",
      "Song 54, Epoch 150/200, Loss: 1.9740650653839111\n",
      "Song 54, Epoch 160/200, Loss: 1.9699610471725464\n",
      "Song 54, Epoch 170/200, Loss: 1.962291955947876\n",
      "Song 54, Epoch 180/200, Loss: 1.958831787109375\n",
      "Song 54, Epoch 190/200, Loss: 1.9536705017089844\n",
      "Song 54, Epoch 200/200, Loss: 1.9506220817565918\n",
      "Validation Loss after song 54: 4.073146887314626\n",
      "Training on song 55\n",
      "Song 55, Epoch 10/200, Loss: 2.224393606185913\n",
      "Song 55, Epoch 20/200, Loss: 2.1248505115509033\n",
      "Song 55, Epoch 30/200, Loss: 2.0875120162963867\n",
      "Song 55, Epoch 40/200, Loss: 2.0406343936920166\n",
      "Song 55, Epoch 50/200, Loss: 2.016226053237915\n",
      "Song 55, Epoch 60/200, Loss: 2.001310348510742\n",
      "Song 55, Epoch 70/200, Loss: 1.9932044744491577\n",
      "Song 55, Epoch 80/200, Loss: 1.9537354707717896\n",
      "Song 55, Epoch 90/200, Loss: 1.9454442262649536\n",
      "Song 55, Epoch 100/200, Loss: 1.936248779296875\n",
      "Song 55, Epoch 110/200, Loss: 1.9228447675704956\n",
      "Song 55, Epoch 120/200, Loss: 1.9110509157180786\n",
      "Song 55, Epoch 130/200, Loss: 1.8995224237442017\n",
      "Song 55, Epoch 140/200, Loss: 1.8899693489074707\n",
      "Song 55, Epoch 150/200, Loss: 1.8860373497009277\n",
      "Song 55, Epoch 160/200, Loss: 1.8845348358154297\n",
      "Song 55, Epoch 170/200, Loss: 1.8686002492904663\n",
      "Song 55, Epoch 180/200, Loss: 1.873789668083191\n",
      "Song 55, Epoch 190/200, Loss: 1.8559889793395996\n",
      "Song 55, Epoch 200/200, Loss: 1.8530635833740234\n",
      "Validation Loss after song 55: 4.030585600779607\n",
      "Training on song 56\n",
      "Song 56, Epoch 10/200, Loss: 2.3842387199401855\n",
      "Song 56, Epoch 20/200, Loss: 2.3409626483917236\n",
      "Song 56, Epoch 30/200, Loss: 2.269341230392456\n",
      "Song 56, Epoch 40/200, Loss: 2.234445333480835\n",
      "Song 56, Epoch 50/200, Loss: 2.219878673553467\n",
      "Song 56, Epoch 60/200, Loss: 2.186859130859375\n",
      "Song 56, Epoch 70/200, Loss: 2.1871960163116455\n",
      "Song 56, Epoch 80/200, Loss: 2.1740124225616455\n",
      "Song 56, Epoch 90/200, Loss: 2.1433541774749756\n",
      "Song 56, Epoch 100/200, Loss: 2.130314588546753\n",
      "Song 56, Epoch 110/200, Loss: 2.1280956268310547\n",
      "Song 56, Epoch 120/200, Loss: 2.101670503616333\n",
      "Song 56, Epoch 130/200, Loss: 2.0924439430236816\n",
      "Song 56, Epoch 140/200, Loss: 2.078434944152832\n",
      "Song 56, Epoch 150/200, Loss: 2.0706820487976074\n",
      "Song 56, Epoch 160/200, Loss: 2.061647653579712\n",
      "Song 56, Epoch 170/200, Loss: 2.0520756244659424\n",
      "Song 56, Epoch 180/200, Loss: 2.0482466220855713\n",
      "Song 56, Epoch 190/200, Loss: 2.0465126037597656\n",
      "Song 56, Epoch 200/200, Loss: 2.045367956161499\n",
      "Validation Loss after song 56: 3.807511818714631\n",
      "Training on song 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 57, Epoch 10/200, Loss: 2.2391223907470703\n",
      "Song 57, Epoch 20/200, Loss: 2.1304378509521484\n",
      "Song 57, Epoch 30/200, Loss: 2.0476105213165283\n",
      "Song 57, Epoch 40/200, Loss: 1.985488772392273\n",
      "Song 57, Epoch 50/200, Loss: 1.9451733827590942\n",
      "Song 57, Epoch 60/200, Loss: 1.9087289571762085\n",
      "Song 57, Epoch 70/200, Loss: 1.9319206476211548\n",
      "Song 57, Epoch 80/200, Loss: 1.871155023574829\n",
      "Song 57, Epoch 90/200, Loss: 1.8454772233963013\n",
      "Song 57, Epoch 100/200, Loss: 1.8259931802749634\n",
      "Song 57, Epoch 110/200, Loss: 1.8137584924697876\n",
      "Song 57, Epoch 120/200, Loss: 1.8020962476730347\n",
      "Song 57, Epoch 130/200, Loss: 1.784666895866394\n",
      "Song 57, Epoch 140/200, Loss: 1.7785100936889648\n",
      "Song 57, Epoch 150/200, Loss: 1.7698370218276978\n",
      "Song 57, Epoch 160/200, Loss: 1.7724766731262207\n",
      "Song 57, Epoch 170/200, Loss: 1.759413719177246\n",
      "Song 57, Epoch 180/200, Loss: 1.7536929845809937\n",
      "Song 57, Epoch 190/200, Loss: 1.745039701461792\n",
      "Song 57, Epoch 200/200, Loss: 1.7504255771636963\n",
      "Validation Loss after song 57: 3.7882335430536513\n",
      "Training on song 58\n",
      "Song 58, Epoch 10/200, Loss: 2.176668643951416\n",
      "Song 58, Epoch 20/200, Loss: 2.1221351623535156\n",
      "Song 58, Epoch 30/200, Loss: 2.0615291595458984\n",
      "Song 58, Epoch 40/200, Loss: 2.0285356044769287\n",
      "Song 58, Epoch 50/200, Loss: 1.9946894645690918\n",
      "Song 58, Epoch 60/200, Loss: 1.975285530090332\n",
      "Song 58, Epoch 70/200, Loss: 1.9501469135284424\n",
      "Song 58, Epoch 80/200, Loss: 1.9320957660675049\n",
      "Song 58, Epoch 90/200, Loss: 1.9337018728256226\n",
      "Song 58, Epoch 100/200, Loss: 1.9056792259216309\n",
      "Song 58, Epoch 110/200, Loss: 1.8969018459320068\n",
      "Song 58, Epoch 120/200, Loss: 1.8908536434173584\n",
      "Song 58, Epoch 130/200, Loss: 1.8679752349853516\n",
      "Song 58, Epoch 140/200, Loss: 1.8558330535888672\n",
      "Song 58, Epoch 150/200, Loss: 1.8512585163116455\n",
      "Song 58, Epoch 160/200, Loss: 1.8434745073318481\n",
      "Song 58, Epoch 170/200, Loss: 1.8349730968475342\n",
      "Song 58, Epoch 180/200, Loss: 1.8507249355316162\n",
      "Song 58, Epoch 190/200, Loss: 1.8355920314788818\n",
      "Song 58, Epoch 200/200, Loss: 1.8433537483215332\n",
      "Validation Loss after song 58: 4.154293115322407\n",
      "Training on song 59\n",
      "Song 59, Epoch 10/200, Loss: 4.426563262939453\n",
      "Song 59, Epoch 20/200, Loss: 3.789261817932129\n",
      "Song 59, Epoch 30/200, Loss: 3.342771530151367\n",
      "Song 59, Epoch 40/200, Loss: 3.0325417518615723\n",
      "Song 59, Epoch 50/200, Loss: 2.8078629970550537\n",
      "Song 59, Epoch 60/200, Loss: 2.528245687484741\n",
      "Song 59, Epoch 70/200, Loss: 2.400157928466797\n",
      "Song 59, Epoch 80/200, Loss: 2.321701765060425\n",
      "Song 59, Epoch 90/200, Loss: 2.2641797065734863\n",
      "Song 59, Epoch 100/200, Loss: 2.2110774517059326\n",
      "Song 59, Epoch 110/200, Loss: 2.1850621700286865\n",
      "Song 59, Epoch 120/200, Loss: 2.1594011783599854\n",
      "Song 59, Epoch 130/200, Loss: 2.144073486328125\n",
      "Song 59, Epoch 140/200, Loss: 2.131129503250122\n",
      "Song 59, Epoch 150/200, Loss: 2.126110792160034\n",
      "Song 59, Epoch 160/200, Loss: 2.1223392486572266\n",
      "Song 59, Epoch 170/200, Loss: 2.1104073524475098\n",
      "Song 59, Epoch 180/200, Loss: 2.1142666339874268\n",
      "Song 59, Epoch 190/200, Loss: 2.1018171310424805\n",
      "Song 59, Epoch 200/200, Loss: 2.1034255027770996\n",
      "Validation Loss after song 59: 4.3231979211171465\n",
      "Training on song 60\n",
      "Song 60, Epoch 10/200, Loss: 5.024815559387207\n",
      "Song 60, Epoch 20/200, Loss: 4.552911758422852\n",
      "Song 60, Epoch 30/200, Loss: 4.094294548034668\n",
      "Song 60, Epoch 40/200, Loss: 3.9291210174560547\n",
      "Song 60, Epoch 50/200, Loss: 3.5993244647979736\n",
      "Song 60, Epoch 60/200, Loss: 3.3894944190979004\n",
      "Song 60, Epoch 70/200, Loss: 3.2058804035186768\n",
      "Song 60, Epoch 80/200, Loss: 2.892177104949951\n",
      "Song 60, Epoch 90/200, Loss: 2.650235176086426\n",
      "Song 60, Epoch 100/200, Loss: 2.465515613555908\n",
      "Song 60, Epoch 110/200, Loss: 2.2956881523132324\n",
      "Song 60, Epoch 120/200, Loss: 2.229625701904297\n",
      "Song 60, Epoch 130/200, Loss: 2.1955807209014893\n",
      "Song 60, Epoch 140/200, Loss: 2.1640641689300537\n",
      "Song 60, Epoch 150/200, Loss: 2.1303935050964355\n",
      "Song 60, Epoch 160/200, Loss: 2.1061205863952637\n",
      "Song 60, Epoch 170/200, Loss: 2.0876991748809814\n",
      "Song 60, Epoch 180/200, Loss: 2.0773465633392334\n",
      "Song 60, Epoch 190/200, Loss: 2.064345359802246\n",
      "Song 60, Epoch 200/200, Loss: 2.0600051879882812\n",
      "Validation Loss after song 60: 4.591691659047053\n",
      "Training on song 61\n",
      "Song 61, Epoch 10/200, Loss: 2.8874239921569824\n",
      "Song 61, Epoch 20/200, Loss: 2.626370429992676\n",
      "Song 61, Epoch 30/200, Loss: 2.445221424102783\n",
      "Song 61, Epoch 40/200, Loss: 2.3169586658477783\n",
      "Song 61, Epoch 50/200, Loss: 2.2292654514312744\n",
      "Song 61, Epoch 60/200, Loss: 2.106914758682251\n",
      "Song 61, Epoch 70/200, Loss: 2.047990083694458\n",
      "Song 61, Epoch 80/200, Loss: 1.9919906854629517\n",
      "Song 61, Epoch 90/200, Loss: 1.938126564025879\n",
      "Song 61, Epoch 100/200, Loss: 1.910365343093872\n",
      "Song 61, Epoch 110/200, Loss: 1.8940579891204834\n",
      "Song 61, Epoch 120/200, Loss: 1.8760168552398682\n",
      "Song 61, Epoch 130/200, Loss: 1.8662593364715576\n",
      "Song 61, Epoch 140/200, Loss: 1.8547226190567017\n",
      "Song 61, Epoch 150/200, Loss: 1.839086651802063\n",
      "Song 61, Epoch 160/200, Loss: 1.828312873840332\n",
      "Song 61, Epoch 170/200, Loss: 1.8219099044799805\n",
      "Song 61, Epoch 180/200, Loss: 1.8406583070755005\n",
      "Song 61, Epoch 190/200, Loss: 1.809398889541626\n",
      "Song 61, Epoch 200/200, Loss: 1.8058024644851685\n",
      "Validation Loss after song 61: 3.8634052826808047\n",
      "Training on song 62\n",
      "Song 62, Epoch 10/200, Loss: 2.502577781677246\n",
      "Song 62, Epoch 20/200, Loss: 2.333310842514038\n",
      "Song 62, Epoch 30/200, Loss: 2.234557628631592\n",
      "Song 62, Epoch 40/200, Loss: 2.117678165435791\n",
      "Song 62, Epoch 50/200, Loss: 2.0190932750701904\n",
      "Song 62, Epoch 60/200, Loss: 1.9412871599197388\n",
      "Song 62, Epoch 70/200, Loss: 1.918131709098816\n",
      "Song 62, Epoch 80/200, Loss: 1.871720552444458\n",
      "Song 62, Epoch 90/200, Loss: 1.7965965270996094\n",
      "Song 62, Epoch 100/200, Loss: 1.763601303100586\n",
      "Song 62, Epoch 110/200, Loss: 1.7279925346374512\n",
      "Song 62, Epoch 120/200, Loss: 1.82142972946167\n",
      "Song 62, Epoch 130/200, Loss: 1.6563632488250732\n",
      "Song 62, Epoch 140/200, Loss: 1.6579433679580688\n",
      "Song 62, Epoch 150/200, Loss: 1.6417771577835083\n",
      "Song 62, Epoch 160/200, Loss: 1.702890157699585\n",
      "Song 62, Epoch 170/200, Loss: 1.6244370937347412\n",
      "Song 62, Epoch 180/200, Loss: 1.6103006601333618\n",
      "Song 62, Epoch 190/200, Loss: 1.6342564821243286\n",
      "Song 62, Epoch 200/200, Loss: 1.6361463069915771\n",
      "Validation Loss after song 62: 4.2654134921538525\n",
      "Training on song 63\n",
      "Song 63, Epoch 10/200, Loss: 2.301983118057251\n",
      "Song 63, Epoch 20/200, Loss: 2.2307634353637695\n",
      "Song 63, Epoch 30/200, Loss: 2.1898374557495117\n",
      "Song 63, Epoch 40/200, Loss: 2.1603517532348633\n",
      "Song 63, Epoch 50/200, Loss: 2.119117259979248\n",
      "Song 63, Epoch 60/200, Loss: 2.0967588424682617\n",
      "Song 63, Epoch 70/200, Loss: 2.0657756328582764\n",
      "Song 63, Epoch 80/200, Loss: 2.0598127841949463\n",
      "Song 63, Epoch 90/200, Loss: 2.0614914894104004\n",
      "Song 63, Epoch 100/200, Loss: 2.0222978591918945\n",
      "Song 63, Epoch 110/200, Loss: 2.007286548614502\n",
      "Song 63, Epoch 120/200, Loss: 1.983614206314087\n",
      "Song 63, Epoch 130/200, Loss: 1.967336654663086\n",
      "Song 63, Epoch 140/200, Loss: 1.9447046518325806\n",
      "Song 63, Epoch 150/200, Loss: 1.9324826002120972\n",
      "Song 63, Epoch 160/200, Loss: 1.959794521331787\n",
      "Song 63, Epoch 170/200, Loss: 1.9926886558532715\n",
      "Song 63, Epoch 180/200, Loss: 1.9333062171936035\n",
      "Song 63, Epoch 190/200, Loss: 1.9452531337738037\n",
      "Song 63, Epoch 200/200, Loss: 1.9338942766189575\n",
      "Validation Loss after song 63: 4.327687721986037\n",
      "Training on song 64\n",
      "Song 64, Epoch 10/200, Loss: 2.9220387935638428\n",
      "Song 64, Epoch 20/200, Loss: 2.7866852283477783\n",
      "Song 64, Epoch 30/200, Loss: 2.6422300338745117\n",
      "Song 64, Epoch 40/200, Loss: 2.5197103023529053\n",
      "Song 64, Epoch 50/200, Loss: 2.4499521255493164\n",
      "Song 64, Epoch 60/200, Loss: 2.3980302810668945\n",
      "Song 64, Epoch 70/200, Loss: 2.3358898162841797\n",
      "Song 64, Epoch 80/200, Loss: 2.2520501613616943\n",
      "Song 64, Epoch 90/200, Loss: 2.1916801929473877\n",
      "Song 64, Epoch 100/200, Loss: 2.1542413234710693\n",
      "Song 64, Epoch 110/200, Loss: 2.114748954772949\n",
      "Song 64, Epoch 120/200, Loss: 2.07835054397583\n",
      "Song 64, Epoch 130/200, Loss: 2.0505526065826416\n",
      "Song 64, Epoch 140/200, Loss: 2.026298761367798\n",
      "Song 64, Epoch 150/200, Loss: 2.0134596824645996\n",
      "Song 64, Epoch 160/200, Loss: 2.0129292011260986\n",
      "Song 64, Epoch 170/200, Loss: 2.0027658939361572\n",
      "Song 64, Epoch 180/200, Loss: 2.002899646759033\n",
      "Song 64, Epoch 190/200, Loss: 1.9902434349060059\n",
      "Song 64, Epoch 200/200, Loss: 2.0104196071624756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after song 64: 4.0192559865804816\n",
      "Training on song 65\n",
      "Song 65, Epoch 10/200, Loss: 2.894002676010132\n",
      "Song 65, Epoch 20/200, Loss: 2.650926351547241\n",
      "Song 65, Epoch 30/200, Loss: 2.494150161743164\n",
      "Song 65, Epoch 40/200, Loss: 2.373318910598755\n",
      "Song 65, Epoch 50/200, Loss: 2.288414239883423\n",
      "Song 65, Epoch 60/200, Loss: 2.2343990802764893\n",
      "Song 65, Epoch 70/200, Loss: 2.152393102645874\n",
      "Song 65, Epoch 80/200, Loss: 2.090623140335083\n",
      "Song 65, Epoch 90/200, Loss: 1.9767307043075562\n",
      "Song 65, Epoch 100/200, Loss: 1.9045401811599731\n",
      "Song 65, Epoch 110/200, Loss: 1.8646742105484009\n",
      "Song 65, Epoch 120/200, Loss: 1.8332200050354004\n",
      "Song 65, Epoch 130/200, Loss: 1.7841547727584839\n",
      "Song 65, Epoch 140/200, Loss: 1.7707700729370117\n",
      "Song 65, Epoch 150/200, Loss: 1.7625147104263306\n",
      "Song 65, Epoch 160/200, Loss: 1.7425315380096436\n",
      "Song 65, Epoch 170/200, Loss: 1.7310576438903809\n",
      "Song 65, Epoch 180/200, Loss: 1.7276076078414917\n",
      "Song 65, Epoch 190/200, Loss: 1.7359960079193115\n",
      "Song 65, Epoch 200/200, Loss: 1.706007719039917\n",
      "Validation Loss after song 65: 3.8403181662926307\n",
      "Training on song 66\n",
      "Song 66, Epoch 10/200, Loss: 2.3886027336120605\n",
      "Song 66, Epoch 20/200, Loss: 2.3672728538513184\n",
      "Song 66, Epoch 30/200, Loss: 2.3028371334075928\n",
      "Song 66, Epoch 40/200, Loss: 2.2684178352355957\n",
      "Song 66, Epoch 50/200, Loss: 2.2252769470214844\n",
      "Song 66, Epoch 60/200, Loss: 2.2424397468566895\n",
      "Song 66, Epoch 70/200, Loss: 2.1633918285369873\n",
      "Song 66, Epoch 80/200, Loss: 2.132826805114746\n",
      "Song 66, Epoch 90/200, Loss: 2.1050984859466553\n",
      "Song 66, Epoch 100/200, Loss: 2.077007532119751\n",
      "Song 66, Epoch 110/200, Loss: 2.068065643310547\n",
      "Song 66, Epoch 120/200, Loss: 2.0379512310028076\n",
      "Song 66, Epoch 130/200, Loss: 2.0305283069610596\n",
      "Song 66, Epoch 140/200, Loss: 2.0000126361846924\n",
      "Song 66, Epoch 150/200, Loss: 1.9836854934692383\n",
      "Song 66, Epoch 160/200, Loss: 1.9658147096633911\n",
      "Song 66, Epoch 170/200, Loss: 1.9511446952819824\n",
      "Song 66, Epoch 180/200, Loss: 1.9429682493209839\n",
      "Song 66, Epoch 190/200, Loss: 1.93694007396698\n",
      "Song 66, Epoch 200/200, Loss: 1.9249505996704102\n",
      "Validation Loss after song 66: 3.7378276066902356\n",
      "Training on song 67\n",
      "Song 67, Epoch 10/200, Loss: 2.332943916320801\n",
      "Song 67, Epoch 20/200, Loss: 2.226074695587158\n",
      "Song 67, Epoch 30/200, Loss: 2.131040573120117\n",
      "Song 67, Epoch 40/200, Loss: 2.0461761951446533\n",
      "Song 67, Epoch 50/200, Loss: 2.0074210166931152\n",
      "Song 67, Epoch 60/200, Loss: 1.9505833387374878\n",
      "Song 67, Epoch 70/200, Loss: 1.9345324039459229\n",
      "Song 67, Epoch 80/200, Loss: 1.8470641374588013\n",
      "Song 67, Epoch 90/200, Loss: 1.821047306060791\n",
      "Song 67, Epoch 100/200, Loss: 1.7962703704833984\n",
      "Song 67, Epoch 110/200, Loss: 1.775349736213684\n",
      "Song 67, Epoch 120/200, Loss: 1.7643893957138062\n",
      "Song 67, Epoch 130/200, Loss: 1.7627829313278198\n",
      "Song 67, Epoch 140/200, Loss: 1.7498940229415894\n",
      "Song 67, Epoch 150/200, Loss: 1.7349985837936401\n",
      "Song 67, Epoch 160/200, Loss: 1.7276115417480469\n",
      "Song 67, Epoch 170/200, Loss: 1.722030758857727\n",
      "Song 67, Epoch 180/200, Loss: 1.7153955698013306\n",
      "Song 67, Epoch 190/200, Loss: 1.759515643119812\n",
      "Song 67, Epoch 200/200, Loss: 1.7121565341949463\n",
      "Validation Loss after song 67: 4.530627605242607\n",
      "Training on song 68\n",
      "Song 68, Epoch 10/200, Loss: 5.263919353485107\n",
      "Song 68, Epoch 20/200, Loss: 5.002710819244385\n",
      "Song 68, Epoch 30/200, Loss: 4.315057277679443\n",
      "Song 68, Epoch 40/200, Loss: 3.9429895877838135\n",
      "Song 68, Epoch 50/200, Loss: 3.5815646648406982\n",
      "Song 68, Epoch 60/200, Loss: 3.606126546859741\n",
      "Song 68, Epoch 70/200, Loss: 3.295985221862793\n",
      "Song 68, Epoch 80/200, Loss: 3.115140199661255\n",
      "Song 68, Epoch 90/200, Loss: 2.890427350997925\n",
      "Song 68, Epoch 100/200, Loss: 2.709235429763794\n",
      "Song 68, Epoch 110/200, Loss: 2.515296220779419\n",
      "Song 68, Epoch 120/200, Loss: 2.3930788040161133\n",
      "Song 68, Epoch 130/200, Loss: 2.279189348220825\n",
      "Song 68, Epoch 140/200, Loss: 2.2000732421875\n",
      "Song 68, Epoch 150/200, Loss: 2.1536688804626465\n",
      "Song 68, Epoch 160/200, Loss: 2.107618808746338\n",
      "Song 68, Epoch 170/200, Loss: 2.0811305046081543\n",
      "Song 68, Epoch 180/200, Loss: 2.055233955383301\n",
      "Song 68, Epoch 190/200, Loss: 2.0337088108062744\n",
      "Song 68, Epoch 200/200, Loss: 2.0198488235473633\n",
      "Validation Loss after song 68: 4.113840940671089\n",
      "Training on song 69\n",
      "Song 69, Epoch 10/200, Loss: 3.2642133235931396\n",
      "Song 69, Epoch 20/200, Loss: 3.1401541233062744\n",
      "Song 69, Epoch 30/200, Loss: 3.031125545501709\n",
      "Song 69, Epoch 40/200, Loss: 2.9174842834472656\n",
      "Song 69, Epoch 50/200, Loss: 2.8273682594299316\n",
      "Song 69, Epoch 60/200, Loss: 2.716465950012207\n",
      "Song 69, Epoch 70/200, Loss: 2.5996997356414795\n",
      "Song 69, Epoch 80/200, Loss: 2.44807767868042\n",
      "Song 69, Epoch 90/200, Loss: 2.3478798866271973\n",
      "Song 69, Epoch 100/200, Loss: 2.216891050338745\n",
      "Song 69, Epoch 110/200, Loss: 2.1668004989624023\n",
      "Song 69, Epoch 120/200, Loss: 2.1384737491607666\n",
      "Song 69, Epoch 130/200, Loss: 2.112405300140381\n",
      "Song 69, Epoch 140/200, Loss: 2.0810937881469727\n",
      "Song 69, Epoch 150/200, Loss: 2.0747060775756836\n",
      "Song 69, Epoch 160/200, Loss: 2.066535234451294\n",
      "Song 69, Epoch 170/200, Loss: 2.055870294570923\n",
      "Song 69, Epoch 180/200, Loss: 2.0412349700927734\n",
      "Song 69, Epoch 190/200, Loss: 2.0605030059814453\n",
      "Song 69, Epoch 200/200, Loss: 2.0254135131835938\n",
      "Validation Loss after song 69: 4.3191261536035785\n",
      "Training on song 70\n",
      "Song 70, Epoch 10/200, Loss: 2.988363027572632\n",
      "Song 70, Epoch 20/200, Loss: 2.8476150035858154\n",
      "Song 70, Epoch 30/200, Loss: 2.7275004386901855\n",
      "Song 70, Epoch 40/200, Loss: 2.6044869422912598\n",
      "Song 70, Epoch 50/200, Loss: 2.5119237899780273\n",
      "Song 70, Epoch 60/200, Loss: 2.4213130474090576\n",
      "Song 70, Epoch 70/200, Loss: 2.51345157623291\n",
      "Song 70, Epoch 80/200, Loss: 2.437978506088257\n",
      "Song 70, Epoch 90/200, Loss: 2.1931827068328857\n",
      "Song 70, Epoch 100/200, Loss: 2.092113494873047\n",
      "Song 70, Epoch 110/200, Loss: 2.0038936138153076\n",
      "Song 70, Epoch 120/200, Loss: 1.9687682390213013\n",
      "Song 70, Epoch 130/200, Loss: 1.9451550245285034\n",
      "Song 70, Epoch 140/200, Loss: 1.9331332445144653\n",
      "Song 70, Epoch 150/200, Loss: 1.9199398756027222\n",
      "Song 70, Epoch 160/200, Loss: 1.9257193803787231\n",
      "Song 70, Epoch 170/200, Loss: 1.902193546295166\n",
      "Song 70, Epoch 180/200, Loss: 1.899341106414795\n",
      "Song 70, Epoch 190/200, Loss: 1.8903906345367432\n",
      "Song 70, Epoch 200/200, Loss: 1.8925375938415527\n",
      "Validation Loss after song 70: 4.125920167336097\n",
      "Training on song 71\n",
      "Song 71, Epoch 10/200, Loss: 2.706089496612549\n",
      "Song 71, Epoch 20/200, Loss: 2.652731418609619\n",
      "Song 71, Epoch 30/200, Loss: 2.611825466156006\n",
      "Song 71, Epoch 40/200, Loss: 2.5979156494140625\n",
      "Song 71, Epoch 50/200, Loss: 2.5507731437683105\n",
      "Song 71, Epoch 60/200, Loss: 2.54146671295166\n",
      "Song 71, Epoch 70/200, Loss: 2.5098159313201904\n",
      "Song 71, Epoch 80/200, Loss: 2.614044427871704\n",
      "Song 71, Epoch 90/200, Loss: 2.485706090927124\n",
      "Song 71, Epoch 100/200, Loss: 2.434516429901123\n",
      "Song 71, Epoch 110/200, Loss: 2.3905413150787354\n",
      "Song 71, Epoch 120/200, Loss: 2.32558274269104\n",
      "Song 71, Epoch 130/200, Loss: 2.300584554672241\n",
      "Song 71, Epoch 140/200, Loss: 2.283781051635742\n",
      "Song 71, Epoch 150/200, Loss: 2.258387327194214\n",
      "Song 71, Epoch 160/200, Loss: 2.227569818496704\n",
      "Song 71, Epoch 170/200, Loss: 2.258918523788452\n",
      "Song 71, Epoch 180/200, Loss: 2.232799768447876\n",
      "Song 71, Epoch 190/200, Loss: 2.2534494400024414\n",
      "Song 71, Epoch 200/200, Loss: 2.204392671585083\n",
      "Validation Loss after song 71: 3.8654075280213966\n",
      "Training on song 72\n",
      "Song 72, Epoch 10/200, Loss: 3.2151124477386475\n",
      "Song 72, Epoch 20/200, Loss: 3.080091953277588\n",
      "Song 72, Epoch 30/200, Loss: 2.978070020675659\n",
      "Song 72, Epoch 40/200, Loss: 2.905625820159912\n",
      "Song 72, Epoch 50/200, Loss: 2.8114559650421143\n",
      "Song 72, Epoch 60/200, Loss: 2.7386209964752197\n",
      "Song 72, Epoch 70/200, Loss: 2.635047197341919\n",
      "Song 72, Epoch 80/200, Loss: 2.5469160079956055\n",
      "Song 72, Epoch 90/200, Loss: 2.4870004653930664\n",
      "Song 72, Epoch 100/200, Loss: 2.4097254276275635\n",
      "Song 72, Epoch 110/200, Loss: 2.3627068996429443\n",
      "Song 72, Epoch 120/200, Loss: 2.3511054515838623\n",
      "Song 72, Epoch 130/200, Loss: 2.315703868865967\n",
      "Song 72, Epoch 140/200, Loss: 2.295537233352661\n",
      "Song 72, Epoch 150/200, Loss: 2.279998302459717\n",
      "Song 72, Epoch 160/200, Loss: 2.296826124191284\n",
      "Song 72, Epoch 170/200, Loss: 2.2410449981689453\n",
      "Song 72, Epoch 180/200, Loss: 2.236837387084961\n",
      "Song 72, Epoch 190/200, Loss: 2.2411673069000244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 72, Epoch 200/200, Loss: 2.2868330478668213\n",
      "Validation Loss after song 72: 4.267060237053113\n",
      "Training on song 73\n",
      "Song 73, Epoch 10/200, Loss: 2.7836363315582275\n",
      "Song 73, Epoch 20/200, Loss: 2.694728136062622\n",
      "Song 73, Epoch 30/200, Loss: 2.692486047744751\n",
      "Song 73, Epoch 40/200, Loss: 2.49710750579834\n",
      "Song 73, Epoch 50/200, Loss: 2.4026029109954834\n",
      "Song 73, Epoch 60/200, Loss: 2.3677501678466797\n",
      "Song 73, Epoch 70/200, Loss: 2.3535423278808594\n",
      "Song 73, Epoch 80/200, Loss: 2.171616315841675\n",
      "Song 73, Epoch 90/200, Loss: 2.2736146450042725\n",
      "Song 73, Epoch 100/200, Loss: 2.131622076034546\n",
      "Song 73, Epoch 110/200, Loss: 2.0532519817352295\n",
      "Song 73, Epoch 120/200, Loss: 2.0298566818237305\n",
      "Song 73, Epoch 130/200, Loss: 2.057633399963379\n",
      "Song 73, Epoch 140/200, Loss: 1.9777584075927734\n",
      "Song 73, Epoch 150/200, Loss: 1.9810917377471924\n",
      "Song 73, Epoch 160/200, Loss: 1.9366474151611328\n",
      "Song 73, Epoch 170/200, Loss: 1.9486347436904907\n",
      "Song 73, Epoch 180/200, Loss: 1.909778118133545\n",
      "Song 73, Epoch 190/200, Loss: 1.8614753484725952\n",
      "Song 73, Epoch 200/200, Loss: 1.8975836038589478\n",
      "Validation Loss after song 73: 3.573294621247512\n",
      "Training on song 74\n",
      "Song 74, Epoch 10/200, Loss: 2.4608960151672363\n",
      "Song 74, Epoch 20/200, Loss: 2.4038021564483643\n",
      "Song 74, Epoch 30/200, Loss: 2.2992265224456787\n",
      "Song 74, Epoch 40/200, Loss: 2.2484097480773926\n",
      "Song 74, Epoch 50/200, Loss: 2.259744644165039\n",
      "Song 74, Epoch 60/200, Loss: 2.152503490447998\n",
      "Song 74, Epoch 70/200, Loss: 2.2186028957366943\n",
      "Song 74, Epoch 80/200, Loss: 1.969118356704712\n",
      "Song 74, Epoch 90/200, Loss: 1.9133362770080566\n",
      "Song 74, Epoch 100/200, Loss: 1.8909173011779785\n",
      "Song 74, Epoch 110/200, Loss: 1.8954658508300781\n",
      "Song 74, Epoch 120/200, Loss: 1.864836573600769\n",
      "Song 74, Epoch 130/200, Loss: 1.8613795042037964\n",
      "Song 74, Epoch 140/200, Loss: 1.8493306636810303\n",
      "Song 74, Epoch 150/200, Loss: 1.8276036977767944\n",
      "Song 74, Epoch 160/200, Loss: 1.8208930492401123\n",
      "Song 74, Epoch 170/200, Loss: 1.8145679235458374\n",
      "Song 74, Epoch 180/200, Loss: 1.815355658531189\n",
      "Song 74, Epoch 190/200, Loss: 1.8111166954040527\n",
      "Song 74, Epoch 200/200, Loss: 1.8223317861557007\n",
      "Validation Loss after song 74: 3.798128525416056\n",
      "Training on song 75\n",
      "Song 75, Epoch 10/200, Loss: 4.222440719604492\n",
      "Song 75, Epoch 20/200, Loss: 3.119155168533325\n",
      "Song 75, Epoch 30/200, Loss: 2.850864887237549\n",
      "Song 75, Epoch 40/200, Loss: 2.6618964672088623\n",
      "Song 75, Epoch 50/200, Loss: 2.5447607040405273\n",
      "Song 75, Epoch 60/200, Loss: 2.4608161449432373\n",
      "Song 75, Epoch 70/200, Loss: 2.462040662765503\n",
      "Song 75, Epoch 80/200, Loss: 2.409053325653076\n",
      "Song 75, Epoch 90/200, Loss: 2.398636817932129\n",
      "Song 75, Epoch 100/200, Loss: 2.384636163711548\n",
      "Song 75, Epoch 110/200, Loss: 2.294952869415283\n",
      "Song 75, Epoch 120/200, Loss: 2.248812675476074\n",
      "Song 75, Epoch 130/200, Loss: 2.2263453006744385\n",
      "Song 75, Epoch 140/200, Loss: 2.194692373275757\n",
      "Song 75, Epoch 150/200, Loss: 2.296816349029541\n",
      "Song 75, Epoch 160/200, Loss: 2.187960147857666\n",
      "Song 75, Epoch 170/200, Loss: 2.1310973167419434\n",
      "Song 75, Epoch 180/200, Loss: 2.1039884090423584\n",
      "Song 75, Epoch 190/200, Loss: 2.0895140171051025\n",
      "Song 75, Epoch 200/200, Loss: 2.1287782192230225\n",
      "Validation Loss after song 75: 4.136941500199147\n",
      "Training on song 76\n",
      "Song 76, Epoch 10/200, Loss: 4.156975746154785\n",
      "Song 76, Epoch 20/200, Loss: 3.421211004257202\n",
      "Song 76, Epoch 30/200, Loss: 2.5877277851104736\n",
      "Song 76, Epoch 40/200, Loss: 2.299363613128662\n",
      "Song 76, Epoch 50/200, Loss: 2.0802667140960693\n",
      "Song 76, Epoch 60/200, Loss: 2.0112292766571045\n",
      "Song 76, Epoch 70/200, Loss: 1.9579310417175293\n",
      "Song 76, Epoch 80/200, Loss: 1.9343525171279907\n",
      "Song 76, Epoch 90/200, Loss: 1.9143142700195312\n",
      "Song 76, Epoch 100/200, Loss: 1.9024837017059326\n",
      "Song 76, Epoch 110/200, Loss: 1.890419840812683\n",
      "Song 76, Epoch 120/200, Loss: 1.8776780366897583\n",
      "Song 76, Epoch 130/200, Loss: 1.8624560832977295\n",
      "Song 76, Epoch 140/200, Loss: 1.8739354610443115\n",
      "Song 76, Epoch 150/200, Loss: 1.8606951236724854\n",
      "Song 76, Epoch 160/200, Loss: 1.8551154136657715\n",
      "Song 76, Epoch 170/200, Loss: 1.8417302370071411\n",
      "Song 76, Epoch 180/200, Loss: 1.8353800773620605\n",
      "Song 76, Epoch 190/200, Loss: 1.8273205757141113\n",
      "Song 76, Epoch 200/200, Loss: 1.830245852470398\n",
      "Validation Loss after song 76: 3.906291466492873\n",
      "Training on song 77\n",
      "Song 77, Epoch 10/200, Loss: 2.1050634384155273\n",
      "Song 77, Epoch 20/200, Loss: 1.9752438068389893\n",
      "Song 77, Epoch 30/200, Loss: 1.9016526937484741\n",
      "Song 77, Epoch 40/200, Loss: 1.865421175956726\n",
      "Song 77, Epoch 50/200, Loss: 1.8410180807113647\n",
      "Song 77, Epoch 60/200, Loss: 1.8283305168151855\n",
      "Song 77, Epoch 70/200, Loss: 1.8153421878814697\n",
      "Song 77, Epoch 80/200, Loss: 1.8013782501220703\n",
      "Song 77, Epoch 90/200, Loss: 1.79475998878479\n",
      "Song 77, Epoch 100/200, Loss: 1.7890706062316895\n",
      "Song 77, Epoch 110/200, Loss: 1.7806533575057983\n",
      "Song 77, Epoch 120/200, Loss: 1.777510643005371\n",
      "Song 77, Epoch 130/200, Loss: 1.7703487873077393\n",
      "Song 77, Epoch 140/200, Loss: 1.761491298675537\n",
      "Song 77, Epoch 150/200, Loss: 1.75466787815094\n",
      "Song 77, Epoch 160/200, Loss: 1.7515922784805298\n",
      "Song 77, Epoch 170/200, Loss: 1.7486801147460938\n",
      "Song 77, Epoch 180/200, Loss: 1.7452068328857422\n",
      "Song 77, Epoch 190/200, Loss: 1.7408760786056519\n",
      "Song 77, Epoch 200/200, Loss: 1.7379703521728516\n",
      "Validation Loss after song 77: 4.165302044306046\n",
      "Training on song 78\n",
      "Song 78, Epoch 10/200, Loss: 3.806654214859009\n",
      "Song 78, Epoch 20/200, Loss: 3.1679813861846924\n",
      "Song 78, Epoch 30/200, Loss: 2.684856414794922\n",
      "Song 78, Epoch 40/200, Loss: 2.436795711517334\n",
      "Song 78, Epoch 50/200, Loss: 2.311675786972046\n",
      "Song 78, Epoch 60/200, Loss: 2.25064754486084\n",
      "Song 78, Epoch 70/200, Loss: 2.215609312057495\n",
      "Song 78, Epoch 80/200, Loss: 2.195734977722168\n",
      "Song 78, Epoch 90/200, Loss: 2.1727564334869385\n",
      "Song 78, Epoch 100/200, Loss: 2.173086166381836\n",
      "Song 78, Epoch 110/200, Loss: 2.1608123779296875\n",
      "Song 78, Epoch 120/200, Loss: 2.1465024948120117\n",
      "Song 78, Epoch 130/200, Loss: 2.1414196491241455\n",
      "Song 78, Epoch 140/200, Loss: 2.1338181495666504\n",
      "Song 78, Epoch 150/200, Loss: 2.130770444869995\n",
      "Song 78, Epoch 160/200, Loss: 2.1256821155548096\n",
      "Song 78, Epoch 170/200, Loss: 2.1230669021606445\n",
      "Song 78, Epoch 180/200, Loss: 2.120450973510742\n",
      "Song 78, Epoch 190/200, Loss: 2.121436595916748\n",
      "Song 78, Epoch 200/200, Loss: 2.1148009300231934\n",
      "Validation Loss after song 78: 4.154272537965041\n",
      "Training on song 79\n",
      "Song 79, Epoch 10/200, Loss: 3.1416633129119873\n",
      "Song 79, Epoch 20/200, Loss: 2.7689743041992188\n",
      "Song 79, Epoch 30/200, Loss: 2.503986120223999\n",
      "Song 79, Epoch 40/200, Loss: 2.284335136413574\n",
      "Song 79, Epoch 50/200, Loss: 2.1472721099853516\n",
      "Song 79, Epoch 60/200, Loss: 2.0558881759643555\n",
      "Song 79, Epoch 70/200, Loss: 2.001209259033203\n",
      "Song 79, Epoch 80/200, Loss: 1.9749741554260254\n",
      "Song 79, Epoch 90/200, Loss: 1.9548497200012207\n",
      "Song 79, Epoch 100/200, Loss: 1.9400640726089478\n",
      "Song 79, Epoch 110/200, Loss: 1.9253772497177124\n",
      "Song 79, Epoch 120/200, Loss: 1.9165539741516113\n",
      "Song 79, Epoch 130/200, Loss: 1.913314938545227\n",
      "Song 79, Epoch 140/200, Loss: 1.9068561792373657\n",
      "Song 79, Epoch 150/200, Loss: 1.9043573141098022\n",
      "Song 79, Epoch 160/200, Loss: 1.8995604515075684\n",
      "Song 79, Epoch 170/200, Loss: 1.8941764831542969\n",
      "Song 79, Epoch 180/200, Loss: 1.8868355751037598\n",
      "Song 79, Epoch 190/200, Loss: 1.8842154741287231\n",
      "Song 79, Epoch 200/200, Loss: 1.8974676132202148\n",
      "Validation Loss after song 79: 4.2221454962705955\n",
      "Training on song 80\n",
      "Song 80, Epoch 10/200, Loss: 6.1081862449646\n",
      "Song 80, Epoch 20/200, Loss: 4.968715190887451\n",
      "Song 80, Epoch 30/200, Loss: 3.9825870990753174\n",
      "Song 80, Epoch 40/200, Loss: 3.2516698837280273\n",
      "Song 80, Epoch 50/200, Loss: 2.8976049423217773\n",
      "Song 80, Epoch 60/200, Loss: 2.672769546508789\n",
      "Song 80, Epoch 70/200, Loss: 2.480727434158325\n",
      "Song 80, Epoch 80/200, Loss: 2.358144521713257\n",
      "Song 80, Epoch 90/200, Loss: 2.2854154109954834\n",
      "Song 80, Epoch 100/200, Loss: 2.242941379547119\n",
      "Song 80, Epoch 110/200, Loss: 2.21577525138855\n",
      "Song 80, Epoch 120/200, Loss: 2.1912639141082764\n",
      "Song 80, Epoch 130/200, Loss: 2.17145037651062\n",
      "Song 80, Epoch 140/200, Loss: 2.152930974960327\n",
      "Song 80, Epoch 150/200, Loss: 2.1444201469421387\n",
      "Song 80, Epoch 160/200, Loss: 2.122826337814331\n",
      "Song 80, Epoch 170/200, Loss: 2.1091670989990234\n",
      "Song 80, Epoch 180/200, Loss: 2.1016697883605957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 80, Epoch 190/200, Loss: 2.091078281402588\n",
      "Song 80, Epoch 200/200, Loss: 2.104550838470459\n",
      "Validation Loss after song 80: 4.0289973601316795\n",
      "Training on song 81\n",
      "Song 81, Epoch 10/200, Loss: 2.4955663681030273\n",
      "Song 81, Epoch 20/200, Loss: 2.3126351833343506\n",
      "Song 81, Epoch 30/200, Loss: 2.1751694679260254\n",
      "Song 81, Epoch 40/200, Loss: 2.0919086933135986\n",
      "Song 81, Epoch 50/200, Loss: 2.045772075653076\n",
      "Song 81, Epoch 60/200, Loss: 2.019686698913574\n",
      "Song 81, Epoch 70/200, Loss: 2.001042127609253\n",
      "Song 81, Epoch 80/200, Loss: 1.9776257276535034\n",
      "Song 81, Epoch 90/200, Loss: 1.978487253189087\n",
      "Song 81, Epoch 100/200, Loss: 1.9647663831710815\n",
      "Song 81, Epoch 110/200, Loss: 1.9405276775360107\n",
      "Song 81, Epoch 120/200, Loss: 1.9516757726669312\n",
      "Song 81, Epoch 130/200, Loss: 1.947992205619812\n",
      "Song 81, Epoch 140/200, Loss: 1.9400615692138672\n",
      "Song 81, Epoch 150/200, Loss: 1.9335591793060303\n",
      "Song 81, Epoch 160/200, Loss: 1.93316650390625\n",
      "Song 81, Epoch 170/200, Loss: 1.9405183792114258\n",
      "Song 81, Epoch 180/200, Loss: 1.9358546733856201\n",
      "Song 81, Epoch 190/200, Loss: 1.928260087966919\n",
      "Song 81, Epoch 200/200, Loss: 1.9263776540756226\n",
      "Validation Loss after song 81: 5.506716349186042\n",
      "Training on song 82\n",
      "Song 82, Epoch 10/200, Loss: 5.366966247558594\n",
      "Song 82, Epoch 20/200, Loss: 4.277981281280518\n",
      "Song 82, Epoch 30/200, Loss: 3.4239437580108643\n",
      "Song 82, Epoch 40/200, Loss: 2.817082166671753\n",
      "Song 82, Epoch 50/200, Loss: 2.4333505630493164\n",
      "Song 82, Epoch 60/200, Loss: 2.1975038051605225\n",
      "Song 82, Epoch 70/200, Loss: 2.0444893836975098\n",
      "Song 82, Epoch 80/200, Loss: 1.934584617614746\n",
      "Song 82, Epoch 90/200, Loss: 1.8701847791671753\n",
      "Song 82, Epoch 100/200, Loss: 1.84190034866333\n",
      "Song 82, Epoch 110/200, Loss: 1.821867823600769\n",
      "Song 82, Epoch 120/200, Loss: 1.8079129457473755\n",
      "Song 82, Epoch 130/200, Loss: 1.798551321029663\n",
      "Song 82, Epoch 140/200, Loss: 1.7857646942138672\n",
      "Song 82, Epoch 150/200, Loss: 1.775291085243225\n",
      "Song 82, Epoch 160/200, Loss: 1.765793800354004\n",
      "Song 82, Epoch 170/200, Loss: 1.7603116035461426\n",
      "Song 82, Epoch 180/200, Loss: 1.7519465684890747\n",
      "Song 82, Epoch 190/200, Loss: 1.752732276916504\n",
      "Song 82, Epoch 200/200, Loss: 1.7501723766326904\n",
      "Validation Loss after song 82: 3.9430501736127415\n",
      "Training on song 83\n",
      "Song 83, Epoch 10/200, Loss: 3.7560155391693115\n",
      "Song 83, Epoch 20/200, Loss: 3.1896541118621826\n",
      "Song 83, Epoch 30/200, Loss: 2.9019033908843994\n",
      "Song 83, Epoch 40/200, Loss: 2.727518320083618\n",
      "Song 83, Epoch 50/200, Loss: 2.6037631034851074\n",
      "Song 83, Epoch 60/200, Loss: 2.524672746658325\n",
      "Song 83, Epoch 70/200, Loss: 2.4892737865448\n",
      "Song 83, Epoch 80/200, Loss: 2.475335121154785\n",
      "Song 83, Epoch 90/200, Loss: 2.4431769847869873\n",
      "Song 83, Epoch 100/200, Loss: 2.430975914001465\n",
      "Song 83, Epoch 110/200, Loss: 2.416221857070923\n",
      "Song 83, Epoch 120/200, Loss: 2.407543659210205\n",
      "Song 83, Epoch 130/200, Loss: 2.3992512226104736\n",
      "Song 83, Epoch 140/200, Loss: 2.390814781188965\n",
      "Song 83, Epoch 150/200, Loss: 2.3904364109039307\n",
      "Song 83, Epoch 160/200, Loss: 2.3872902393341064\n",
      "Song 83, Epoch 170/200, Loss: 2.380647897720337\n",
      "Song 83, Epoch 180/200, Loss: 2.3782122135162354\n",
      "Song 83, Epoch 190/200, Loss: 2.369117259979248\n",
      "Song 83, Epoch 200/200, Loss: 2.3699748516082764\n",
      "Validation Loss after song 83: 4.154824207990598\n",
      "Training on song 84\n",
      "Song 84, Epoch 10/200, Loss: 2.795055866241455\n",
      "Song 84, Epoch 20/200, Loss: 2.4979946613311768\n",
      "Song 84, Epoch 30/200, Loss: 2.3170628547668457\n",
      "Song 84, Epoch 40/200, Loss: 2.230531930923462\n",
      "Song 84, Epoch 50/200, Loss: 2.174515724182129\n",
      "Song 84, Epoch 60/200, Loss: 2.131343126296997\n",
      "Song 84, Epoch 70/200, Loss: 2.108475685119629\n",
      "Song 84, Epoch 80/200, Loss: 2.11138653755188\n",
      "Song 84, Epoch 90/200, Loss: 2.0959725379943848\n",
      "Song 84, Epoch 100/200, Loss: 2.0798304080963135\n",
      "Song 84, Epoch 110/200, Loss: 2.072625160217285\n",
      "Song 84, Epoch 120/200, Loss: 2.0668694972991943\n",
      "Song 84, Epoch 130/200, Loss: 2.069589138031006\n",
      "Song 84, Epoch 140/200, Loss: 2.0664892196655273\n",
      "Song 84, Epoch 150/200, Loss: 2.0622000694274902\n",
      "Song 84, Epoch 160/200, Loss: 2.0497868061065674\n",
      "Song 84, Epoch 170/200, Loss: 2.0484633445739746\n",
      "Song 84, Epoch 180/200, Loss: 2.045351028442383\n",
      "Song 84, Epoch 190/200, Loss: 2.042882204055786\n",
      "Song 84, Epoch 200/200, Loss: 2.0345518589019775\n",
      "Validation Loss after song 84: 4.221709966659546\n",
      "Training on song 85\n",
      "Song 85, Epoch 10/200, Loss: 3.3559398651123047\n",
      "Song 85, Epoch 20/200, Loss: 2.6893043518066406\n",
      "Song 85, Epoch 30/200, Loss: 2.349898338317871\n",
      "Song 85, Epoch 40/200, Loss: 2.1083226203918457\n",
      "Song 85, Epoch 50/200, Loss: 1.9303994178771973\n",
      "Song 85, Epoch 60/200, Loss: 1.7904417514801025\n",
      "Song 85, Epoch 70/200, Loss: 1.6897395849227905\n",
      "Song 85, Epoch 80/200, Loss: 1.631559133529663\n",
      "Song 85, Epoch 90/200, Loss: 1.5767581462860107\n",
      "Song 85, Epoch 100/200, Loss: 1.5403889417648315\n",
      "Song 85, Epoch 110/200, Loss: 1.536568284034729\n",
      "Song 85, Epoch 120/200, Loss: 1.5070172548294067\n",
      "Song 85, Epoch 130/200, Loss: 1.4798519611358643\n",
      "Song 85, Epoch 140/200, Loss: 1.511677861213684\n",
      "Song 85, Epoch 150/200, Loss: 1.4562138319015503\n",
      "Song 85, Epoch 160/200, Loss: 1.5069366693496704\n",
      "Song 85, Epoch 170/200, Loss: 1.4848895072937012\n",
      "Song 85, Epoch 180/200, Loss: 1.4435477256774902\n",
      "Song 85, Epoch 190/200, Loss: 1.489443063735962\n",
      "Song 85, Epoch 200/200, Loss: 1.4634957313537598\n",
      "Validation Loss after song 85: 3.903020883217836\n",
      "Training on song 86\n",
      "Song 86, Epoch 10/200, Loss: 2.5879807472229004\n",
      "Song 86, Epoch 20/200, Loss: 2.273996114730835\n",
      "Song 86, Epoch 30/200, Loss: 2.310009717941284\n",
      "Song 86, Epoch 40/200, Loss: 2.1874516010284424\n",
      "Song 86, Epoch 50/200, Loss: 2.1343700885772705\n",
      "Song 86, Epoch 60/200, Loss: 2.1076550483703613\n",
      "Song 86, Epoch 70/200, Loss: 2.0672008991241455\n",
      "Song 86, Epoch 80/200, Loss: 2.0308539867401123\n",
      "Song 86, Epoch 90/200, Loss: 2.001485586166382\n",
      "Song 86, Epoch 100/200, Loss: 2.011258602142334\n",
      "Song 86, Epoch 110/200, Loss: 1.992559790611267\n",
      "Song 86, Epoch 120/200, Loss: 1.9791628122329712\n",
      "Song 86, Epoch 130/200, Loss: 1.9550180435180664\n",
      "Song 86, Epoch 140/200, Loss: 1.9619166851043701\n",
      "Song 86, Epoch 150/200, Loss: 1.9355747699737549\n",
      "Song 86, Epoch 160/200, Loss: 1.9306929111480713\n",
      "Song 86, Epoch 170/200, Loss: 1.9317870140075684\n",
      "Song 86, Epoch 180/200, Loss: 1.9251437187194824\n",
      "Song 86, Epoch 190/200, Loss: 1.9111895561218262\n",
      "Song 86, Epoch 200/200, Loss: 1.9174197912216187\n",
      "Validation Loss after song 86: 4.012990248508943\n",
      "Training on song 87\n",
      "Song 87, Epoch 10/200, Loss: 2.5072364807128906\n",
      "Song 87, Epoch 20/200, Loss: 2.4910898208618164\n",
      "Song 87, Epoch 30/200, Loss: 2.4525973796844482\n",
      "Song 87, Epoch 40/200, Loss: 2.3432071208953857\n",
      "Song 87, Epoch 50/200, Loss: 2.3134262561798096\n",
      "Song 87, Epoch 60/200, Loss: 2.386023759841919\n",
      "Song 87, Epoch 70/200, Loss: 2.243082046508789\n",
      "Song 87, Epoch 80/200, Loss: 2.202012538909912\n",
      "Song 87, Epoch 90/200, Loss: 2.1614768505096436\n",
      "Song 87, Epoch 100/200, Loss: 2.1230876445770264\n",
      "Song 87, Epoch 110/200, Loss: 2.091465473175049\n",
      "Song 87, Epoch 120/200, Loss: 2.06516170501709\n",
      "Song 87, Epoch 130/200, Loss: 2.0526413917541504\n",
      "Song 87, Epoch 140/200, Loss: 2.0402557849884033\n",
      "Song 87, Epoch 150/200, Loss: 2.0300405025482178\n",
      "Song 87, Epoch 160/200, Loss: 2.0208957195281982\n",
      "Song 87, Epoch 170/200, Loss: 2.0127527713775635\n",
      "Song 87, Epoch 180/200, Loss: 2.0047354698181152\n",
      "Song 87, Epoch 190/200, Loss: 2.043149471282959\n",
      "Song 87, Epoch 200/200, Loss: 1.9974678754806519\n",
      "Validation Loss after song 87: 3.97649560830532\n",
      "Training on song 88\n",
      "Song 88, Epoch 10/200, Loss: 2.612626791000366\n",
      "Song 88, Epoch 20/200, Loss: 2.4921483993530273\n",
      "Song 88, Epoch 30/200, Loss: 2.376633644104004\n",
      "Song 88, Epoch 40/200, Loss: 2.2914960384368896\n",
      "Song 88, Epoch 50/200, Loss: 2.2075817584991455\n",
      "Song 88, Epoch 60/200, Loss: 2.157090187072754\n",
      "Song 88, Epoch 70/200, Loss: 2.081918239593506\n",
      "Song 88, Epoch 80/200, Loss: 2.0086374282836914\n",
      "Song 88, Epoch 90/200, Loss: 1.9546560049057007\n",
      "Song 88, Epoch 100/200, Loss: 1.8924946784973145\n",
      "Song 88, Epoch 110/200, Loss: 1.8552311658859253\n",
      "Song 88, Epoch 120/200, Loss: 1.761379361152649\n",
      "Song 88, Epoch 130/200, Loss: 1.6992522478103638\n",
      "Song 88, Epoch 140/200, Loss: 1.6613175868988037\n",
      "Song 88, Epoch 150/200, Loss: 1.624138593673706\n",
      "Song 88, Epoch 160/200, Loss: 1.5853828191757202\n",
      "Song 88, Epoch 170/200, Loss: 1.5685138702392578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 88, Epoch 180/200, Loss: 1.5500725507736206\n",
      "Song 88, Epoch 190/200, Loss: 1.5354492664337158\n",
      "Song 88, Epoch 200/200, Loss: 1.5201953649520874\n",
      "Validation Loss after song 88: 3.9015744160383177\n",
      "Training on song 89\n",
      "Song 89, Epoch 10/200, Loss: 2.370335578918457\n",
      "Song 89, Epoch 20/200, Loss: 2.3252992630004883\n",
      "Song 89, Epoch 30/200, Loss: 2.2610843181610107\n",
      "Song 89, Epoch 40/200, Loss: 2.217198133468628\n",
      "Song 89, Epoch 50/200, Loss: 2.169635534286499\n",
      "Song 89, Epoch 60/200, Loss: 2.1327409744262695\n",
      "Song 89, Epoch 70/200, Loss: 2.094726324081421\n",
      "Song 89, Epoch 80/200, Loss: 2.0783705711364746\n",
      "Song 89, Epoch 90/200, Loss: 2.029768705368042\n",
      "Song 89, Epoch 100/200, Loss: 1.9850338697433472\n",
      "Song 89, Epoch 110/200, Loss: 1.9208990335464478\n",
      "Song 89, Epoch 120/200, Loss: 1.9091943502426147\n",
      "Song 89, Epoch 130/200, Loss: 1.902743935585022\n",
      "Song 89, Epoch 140/200, Loss: 1.8767553567886353\n",
      "Song 89, Epoch 150/200, Loss: 1.9082046747207642\n",
      "Song 89, Epoch 160/200, Loss: 1.8835680484771729\n",
      "Song 89, Epoch 170/200, Loss: 1.8732225894927979\n",
      "Song 89, Epoch 180/200, Loss: 1.8609592914581299\n",
      "Song 89, Epoch 190/200, Loss: 1.8518980741500854\n",
      "Song 89, Epoch 200/200, Loss: 1.855819821357727\n",
      "Validation Loss after song 89: 3.8087182228381815\n",
      "Training on song 90\n",
      "Song 90, Epoch 10/200, Loss: 3.885779619216919\n",
      "Song 90, Epoch 20/200, Loss: 3.627100944519043\n",
      "Song 90, Epoch 30/200, Loss: 3.3689985275268555\n",
      "Song 90, Epoch 40/200, Loss: 3.1357944011688232\n",
      "Song 90, Epoch 50/200, Loss: 2.9982659816741943\n",
      "Song 90, Epoch 60/200, Loss: 2.79329252243042\n",
      "Song 90, Epoch 70/200, Loss: 2.5248496532440186\n",
      "Song 90, Epoch 80/200, Loss: 2.375140905380249\n",
      "Song 90, Epoch 90/200, Loss: 2.2293148040771484\n",
      "Song 90, Epoch 100/200, Loss: 2.1087307929992676\n",
      "Song 90, Epoch 110/200, Loss: 2.053544521331787\n",
      "Song 90, Epoch 120/200, Loss: 2.02612566947937\n",
      "Song 90, Epoch 130/200, Loss: 2.007659435272217\n",
      "Song 90, Epoch 140/200, Loss: 1.9922654628753662\n",
      "Song 90, Epoch 150/200, Loss: 1.9778183698654175\n",
      "Song 90, Epoch 160/200, Loss: 1.9692156314849854\n",
      "Song 90, Epoch 170/200, Loss: 1.9569494724273682\n",
      "Song 90, Epoch 180/200, Loss: 1.9496458768844604\n",
      "Song 90, Epoch 190/200, Loss: 1.937514066696167\n",
      "Song 90, Epoch 200/200, Loss: 1.9391895532608032\n",
      "Validation Loss after song 90: 4.467674848360893\n",
      "Training on song 91\n",
      "Song 91, Epoch 10/200, Loss: 3.406550884246826\n",
      "Song 91, Epoch 20/200, Loss: 2.969181537628174\n",
      "Song 91, Epoch 30/200, Loss: 2.783975839614868\n",
      "Song 91, Epoch 40/200, Loss: 2.649801254272461\n",
      "Song 91, Epoch 50/200, Loss: 2.537456512451172\n",
      "Song 91, Epoch 60/200, Loss: 2.454364538192749\n",
      "Song 91, Epoch 70/200, Loss: 2.3625779151916504\n",
      "Song 91, Epoch 80/200, Loss: 2.3065221309661865\n",
      "Song 91, Epoch 90/200, Loss: 2.2281484603881836\n",
      "Song 91, Epoch 100/200, Loss: 2.0776524543762207\n",
      "Song 91, Epoch 110/200, Loss: 1.9983296394348145\n",
      "Song 91, Epoch 120/200, Loss: 1.9335578680038452\n",
      "Song 91, Epoch 130/200, Loss: 1.8959053754806519\n",
      "Song 91, Epoch 140/200, Loss: 1.8705294132232666\n",
      "Song 91, Epoch 150/200, Loss: 1.855549931526184\n",
      "Song 91, Epoch 160/200, Loss: 1.8369847536087036\n",
      "Song 91, Epoch 170/200, Loss: 1.8588752746582031\n",
      "Song 91, Epoch 180/200, Loss: 1.8076660633087158\n",
      "Song 91, Epoch 190/200, Loss: 1.805730938911438\n",
      "Song 91, Epoch 200/200, Loss: 1.791879653930664\n",
      "Validation Loss after song 91: 3.8281792127169094\n",
      "Training on song 92\n",
      "Song 92, Epoch 10/200, Loss: 2.321751356124878\n",
      "Song 92, Epoch 20/200, Loss: 2.257197380065918\n",
      "Song 92, Epoch 30/200, Loss: 2.1963651180267334\n",
      "Song 92, Epoch 40/200, Loss: 2.1359400749206543\n",
      "Song 92, Epoch 50/200, Loss: 2.084696054458618\n",
      "Song 92, Epoch 60/200, Loss: 2.03956937789917\n",
      "Song 92, Epoch 70/200, Loss: 2.037447929382324\n",
      "Song 92, Epoch 80/200, Loss: 1.9798775911331177\n",
      "Song 92, Epoch 90/200, Loss: 1.9394735097885132\n",
      "Song 92, Epoch 100/200, Loss: 1.89988374710083\n",
      "Song 92, Epoch 110/200, Loss: 1.8482133150100708\n",
      "Song 92, Epoch 120/200, Loss: 1.813339114189148\n",
      "Song 92, Epoch 130/200, Loss: 1.7904915809631348\n",
      "Song 92, Epoch 140/200, Loss: 1.7531869411468506\n",
      "Song 92, Epoch 150/200, Loss: 1.7902032136917114\n",
      "Song 92, Epoch 160/200, Loss: 1.7465966939926147\n",
      "Song 92, Epoch 170/200, Loss: 1.7500396966934204\n",
      "Song 92, Epoch 180/200, Loss: 1.7379415035247803\n",
      "Song 92, Epoch 190/200, Loss: 1.747795820236206\n",
      "Song 92, Epoch 200/200, Loss: 1.7349134683609009\n",
      "Validation Loss after song 92: 4.218275883258918\n",
      "Training on song 93\n",
      "Song 93, Epoch 10/200, Loss: 3.6011908054351807\n",
      "Song 93, Epoch 20/200, Loss: 3.3676578998565674\n",
      "Song 93, Epoch 30/200, Loss: 3.553880214691162\n",
      "Song 93, Epoch 40/200, Loss: 3.064392566680908\n",
      "Song 93, Epoch 50/200, Loss: 2.9516494274139404\n",
      "Song 93, Epoch 60/200, Loss: 2.877976894378662\n",
      "Song 93, Epoch 70/200, Loss: 2.839726448059082\n",
      "Song 93, Epoch 80/200, Loss: 2.8343982696533203\n",
      "Song 93, Epoch 90/200, Loss: 2.756085157394409\n",
      "Song 93, Epoch 100/200, Loss: 2.6947762966156006\n",
      "Song 93, Epoch 110/200, Loss: 2.6248438358306885\n",
      "Song 93, Epoch 120/200, Loss: 2.562089443206787\n",
      "Song 93, Epoch 130/200, Loss: 2.4915482997894287\n",
      "Song 93, Epoch 140/200, Loss: 2.4120378494262695\n",
      "Song 93, Epoch 150/200, Loss: 2.3653459548950195\n",
      "Song 93, Epoch 160/200, Loss: 2.310750722885132\n",
      "Song 93, Epoch 170/200, Loss: 2.265777111053467\n",
      "Song 93, Epoch 180/200, Loss: 2.2284393310546875\n",
      "Song 93, Epoch 190/200, Loss: 2.2083890438079834\n",
      "Song 93, Epoch 200/200, Loss: 2.178481101989746\n",
      "Validation Loss after song 93: 3.862413846529447\n",
      "Training on song 94\n",
      "Song 94, Epoch 10/200, Loss: 2.575232744216919\n",
      "Song 94, Epoch 20/200, Loss: 2.5409958362579346\n",
      "Song 94, Epoch 30/200, Loss: 2.504674196243286\n",
      "Song 94, Epoch 40/200, Loss: 2.471649646759033\n",
      "Song 94, Epoch 50/200, Loss: 2.447766065597534\n",
      "Song 94, Epoch 60/200, Loss: 2.4069466590881348\n",
      "Song 94, Epoch 70/200, Loss: 2.393083333969116\n",
      "Song 94, Epoch 80/200, Loss: 2.3534231185913086\n",
      "Song 94, Epoch 90/200, Loss: 2.326108455657959\n",
      "Song 94, Epoch 100/200, Loss: 2.320469856262207\n",
      "Song 94, Epoch 110/200, Loss: 2.2918710708618164\n",
      "Song 94, Epoch 120/200, Loss: 2.288931131362915\n",
      "Song 94, Epoch 130/200, Loss: 2.2743499279022217\n",
      "Song 94, Epoch 140/200, Loss: 2.2666406631469727\n",
      "Song 94, Epoch 150/200, Loss: 2.2603230476379395\n",
      "Song 94, Epoch 160/200, Loss: 2.255704641342163\n",
      "Song 94, Epoch 170/200, Loss: 2.249204397201538\n",
      "Song 94, Epoch 180/200, Loss: 2.2412784099578857\n",
      "Song 94, Epoch 190/200, Loss: 2.2364683151245117\n",
      "Song 94, Epoch 200/200, Loss: 2.2326877117156982\n",
      "Validation Loss after song 94: 4.219052724349193\n",
      "Training on song 95\n",
      "Song 95, Epoch 10/200, Loss: 2.4752161502838135\n",
      "Song 95, Epoch 20/200, Loss: 2.4413881301879883\n",
      "Song 95, Epoch 30/200, Loss: 2.395305871963501\n",
      "Song 95, Epoch 40/200, Loss: 2.3764405250549316\n",
      "Song 95, Epoch 50/200, Loss: 2.3439135551452637\n",
      "Song 95, Epoch 60/200, Loss: 2.316549062728882\n",
      "Song 95, Epoch 70/200, Loss: 2.291811943054199\n",
      "Song 95, Epoch 80/200, Loss: 2.2732136249542236\n",
      "Song 95, Epoch 90/200, Loss: 2.250117301940918\n",
      "Song 95, Epoch 100/200, Loss: 2.2458977699279785\n",
      "Song 95, Epoch 110/200, Loss: 2.22914457321167\n",
      "Song 95, Epoch 120/200, Loss: 2.2137508392333984\n",
      "Song 95, Epoch 130/200, Loss: 2.198002815246582\n",
      "Song 95, Epoch 140/200, Loss: 2.181943655014038\n",
      "Song 95, Epoch 150/200, Loss: 2.1756324768066406\n",
      "Song 95, Epoch 160/200, Loss: 2.1626334190368652\n",
      "Song 95, Epoch 170/200, Loss: 2.151641607284546\n",
      "Song 95, Epoch 180/200, Loss: 2.1378841400146484\n",
      "Song 95, Epoch 190/200, Loss: 2.126793384552002\n",
      "Song 95, Epoch 200/200, Loss: 2.1211490631103516\n",
      "Validation Loss after song 95: 4.37186119495294\n",
      "Training on song 96\n",
      "Song 96, Epoch 10/200, Loss: 2.6873996257781982\n",
      "Song 96, Epoch 20/200, Loss: 2.5394062995910645\n",
      "Song 96, Epoch 30/200, Loss: 2.455493450164795\n",
      "Song 96, Epoch 40/200, Loss: 2.399864435195923\n",
      "Song 96, Epoch 50/200, Loss: 2.3656442165374756\n",
      "Song 96, Epoch 60/200, Loss: 2.325420618057251\n",
      "Song 96, Epoch 70/200, Loss: 2.2794113159179688\n",
      "Song 96, Epoch 80/200, Loss: 2.2428767681121826\n",
      "Song 96, Epoch 90/200, Loss: 2.1868367195129395\n",
      "Song 96, Epoch 100/200, Loss: 2.1325643062591553\n",
      "Song 96, Epoch 110/200, Loss: 2.0976402759552\n",
      "Song 96, Epoch 120/200, Loss: 2.0774807929992676\n",
      "Song 96, Epoch 130/200, Loss: 2.0611624717712402\n",
      "Song 96, Epoch 140/200, Loss: 2.0359578132629395\n",
      "Song 96, Epoch 150/200, Loss: 2.0579261779785156\n",
      "Song 96, Epoch 160/200, Loss: 2.0748536586761475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 96, Epoch 170/200, Loss: 2.03524112701416\n",
      "Song 96, Epoch 180/200, Loss: 2.0244314670562744\n",
      "Song 96, Epoch 190/200, Loss: 2.013171911239624\n",
      "Song 96, Epoch 200/200, Loss: 2.003037214279175\n",
      "Validation Loss after song 96: 4.180684117170481\n",
      "Training on song 97\n",
      "Song 97, Epoch 10/200, Loss: 2.9567224979400635\n",
      "Song 97, Epoch 20/200, Loss: 2.878098726272583\n",
      "Song 97, Epoch 30/200, Loss: 2.84533953666687\n",
      "Song 97, Epoch 40/200, Loss: 2.7965328693389893\n",
      "Song 97, Epoch 50/200, Loss: 2.7421576976776123\n",
      "Song 97, Epoch 60/200, Loss: 2.706732749938965\n",
      "Song 97, Epoch 70/200, Loss: 2.6619057655334473\n",
      "Song 97, Epoch 80/200, Loss: 2.6532020568847656\n",
      "Song 97, Epoch 90/200, Loss: 2.53393292427063\n",
      "Song 97, Epoch 100/200, Loss: 2.48181414604187\n",
      "Song 97, Epoch 110/200, Loss: 2.4497644901275635\n",
      "Song 97, Epoch 120/200, Loss: 2.4182989597320557\n",
      "Song 97, Epoch 130/200, Loss: 2.3845062255859375\n",
      "Song 97, Epoch 140/200, Loss: 2.355186939239502\n",
      "Song 97, Epoch 150/200, Loss: 2.339146375656128\n",
      "Song 97, Epoch 160/200, Loss: 2.2819042205810547\n",
      "Song 97, Epoch 170/200, Loss: 2.2489824295043945\n",
      "Song 97, Epoch 180/200, Loss: 2.2082066535949707\n",
      "Song 97, Epoch 190/200, Loss: 2.209571599960327\n",
      "Song 97, Epoch 200/200, Loss: 2.2505218982696533\n",
      "Validation Loss after song 97: 4.050844742701604\n",
      "Training on song 98\n",
      "Song 98, Epoch 10/200, Loss: 2.59739351272583\n",
      "Song 98, Epoch 20/200, Loss: 2.5594706535339355\n",
      "Song 98, Epoch 30/200, Loss: 2.522097587585449\n",
      "Song 98, Epoch 40/200, Loss: 2.485546350479126\n",
      "Song 98, Epoch 50/200, Loss: 2.450279951095581\n",
      "Song 98, Epoch 60/200, Loss: 2.418950080871582\n",
      "Song 98, Epoch 70/200, Loss: 2.3872768878936768\n",
      "Song 98, Epoch 80/200, Loss: 2.37563157081604\n",
      "Song 98, Epoch 90/200, Loss: 2.36417555809021\n",
      "Song 98, Epoch 100/200, Loss: 2.301215410232544\n",
      "Song 98, Epoch 110/200, Loss: 2.2737350463867188\n",
      "Song 98, Epoch 120/200, Loss: 2.2551302909851074\n",
      "Song 98, Epoch 130/200, Loss: 2.264125108718872\n",
      "Song 98, Epoch 140/200, Loss: 2.2228455543518066\n",
      "Song 98, Epoch 150/200, Loss: 2.2106447219848633\n",
      "Song 98, Epoch 160/200, Loss: 2.178083896636963\n",
      "Song 98, Epoch 170/200, Loss: 2.19134783744812\n",
      "Song 98, Epoch 180/200, Loss: 2.217367649078369\n",
      "Song 98, Epoch 190/200, Loss: 2.2356269359588623\n",
      "Song 98, Epoch 200/200, Loss: 2.1964809894561768\n",
      "Validation Loss after song 98: 4.1822465260823565\n",
      "Training on song 99\n",
      "Song 99, Epoch 10/200, Loss: 2.461174249649048\n",
      "Song 99, Epoch 20/200, Loss: 2.3807318210601807\n",
      "Song 99, Epoch 30/200, Loss: 2.3031551837921143\n",
      "Song 99, Epoch 40/200, Loss: 2.2335360050201416\n",
      "Song 99, Epoch 50/200, Loss: 2.209184408187866\n",
      "Song 99, Epoch 60/200, Loss: 2.174192428588867\n",
      "Song 99, Epoch 70/200, Loss: 2.110891103744507\n",
      "Song 99, Epoch 80/200, Loss: 2.0589497089385986\n",
      "Song 99, Epoch 90/200, Loss: 2.0170974731445312\n",
      "Song 99, Epoch 100/200, Loss: 1.936288595199585\n",
      "Song 99, Epoch 110/200, Loss: 1.872908592224121\n",
      "Song 99, Epoch 120/200, Loss: 1.8607336282730103\n",
      "Song 99, Epoch 130/200, Loss: 1.787132978439331\n",
      "Song 99, Epoch 140/200, Loss: 1.749540090560913\n",
      "Song 99, Epoch 150/200, Loss: 1.8444139957427979\n",
      "Song 99, Epoch 160/200, Loss: 1.7201448678970337\n",
      "Song 99, Epoch 170/200, Loss: 1.7307184934616089\n",
      "Song 99, Epoch 180/200, Loss: 1.7486263513565063\n",
      "Song 99, Epoch 190/200, Loss: 1.6865724325180054\n",
      "Song 99, Epoch 200/200, Loss: 1.7180812358856201\n",
      "Validation Loss after song 99: 4.152005299543723\n",
      "Training on song 100\n",
      "Song 100, Epoch 10/200, Loss: 2.4388084411621094\n",
      "Song 100, Epoch 20/200, Loss: 2.3941256999969482\n",
      "Song 100, Epoch 30/200, Loss: 2.3571531772613525\n",
      "Song 100, Epoch 40/200, Loss: 2.318469524383545\n",
      "Song 100, Epoch 50/200, Loss: 2.281391143798828\n",
      "Song 100, Epoch 60/200, Loss: 2.2643096446990967\n",
      "Song 100, Epoch 70/200, Loss: 2.2320139408111572\n",
      "Song 100, Epoch 80/200, Loss: 2.2188000679016113\n",
      "Song 100, Epoch 90/200, Loss: 2.1901776790618896\n",
      "Song 100, Epoch 100/200, Loss: 2.191955327987671\n",
      "Song 100, Epoch 110/200, Loss: 2.164911985397339\n",
      "Song 100, Epoch 120/200, Loss: 2.1522152423858643\n",
      "Song 100, Epoch 130/200, Loss: 2.138460874557495\n",
      "Song 100, Epoch 140/200, Loss: 2.1301326751708984\n",
      "Song 100, Epoch 150/200, Loss: 2.118332624435425\n",
      "Song 100, Epoch 160/200, Loss: 2.1080596446990967\n",
      "Song 100, Epoch 170/200, Loss: 2.096790075302124\n",
      "Song 100, Epoch 180/200, Loss: 2.0867319107055664\n",
      "Song 100, Epoch 190/200, Loss: 2.0823323726654053\n",
      "Song 100, Epoch 200/200, Loss: 2.068732500076294\n",
      "Validation Loss after song 100: 4.107212531260955\n",
      "Training on song 101\n",
      "Song 101, Epoch 10/200, Loss: 2.738417387008667\n",
      "Song 101, Epoch 20/200, Loss: 2.6948328018188477\n",
      "Song 101, Epoch 30/200, Loss: 2.6438040733337402\n",
      "Song 101, Epoch 40/200, Loss: 2.597942352294922\n",
      "Song 101, Epoch 50/200, Loss: 2.5626914501190186\n",
      "Song 101, Epoch 60/200, Loss: 2.5284411907196045\n",
      "Song 101, Epoch 70/200, Loss: 2.4843971729278564\n",
      "Song 101, Epoch 80/200, Loss: 2.4385671615600586\n",
      "Song 101, Epoch 90/200, Loss: 2.364320993423462\n",
      "Song 101, Epoch 100/200, Loss: 2.340348720550537\n",
      "Song 101, Epoch 110/200, Loss: 2.300048828125\n",
      "Song 101, Epoch 120/200, Loss: 2.256690263748169\n",
      "Song 101, Epoch 130/200, Loss: 2.236083745956421\n",
      "Song 101, Epoch 140/200, Loss: 2.2211108207702637\n",
      "Song 101, Epoch 150/200, Loss: 2.1911227703094482\n",
      "Song 101, Epoch 160/200, Loss: 2.144110918045044\n",
      "Song 101, Epoch 170/200, Loss: 2.14302134513855\n",
      "Song 101, Epoch 180/200, Loss: 2.113276481628418\n",
      "Song 101, Epoch 190/200, Loss: 2.088628053665161\n",
      "Song 101, Epoch 200/200, Loss: 2.0883073806762695\n",
      "Validation Loss after song 101: 3.886988890476716\n",
      "Training on song 102\n",
      "Song 102, Epoch 10/200, Loss: 2.274608612060547\n",
      "Song 102, Epoch 20/200, Loss: 2.2284584045410156\n",
      "Song 102, Epoch 30/200, Loss: 2.168142557144165\n",
      "Song 102, Epoch 40/200, Loss: 2.1466617584228516\n",
      "Song 102, Epoch 50/200, Loss: 2.1051201820373535\n",
      "Song 102, Epoch 60/200, Loss: 2.0900161266326904\n",
      "Song 102, Epoch 70/200, Loss: 2.053771495819092\n",
      "Song 102, Epoch 80/200, Loss: 2.055250883102417\n",
      "Song 102, Epoch 90/200, Loss: 2.0606775283813477\n",
      "Song 102, Epoch 100/200, Loss: 2.0023322105407715\n",
      "Song 102, Epoch 110/200, Loss: 1.9988328218460083\n",
      "Song 102, Epoch 120/200, Loss: 1.9910937547683716\n",
      "Song 102, Epoch 130/200, Loss: 1.960202932357788\n",
      "Song 102, Epoch 140/200, Loss: 1.9495865106582642\n",
      "Song 102, Epoch 150/200, Loss: 1.9370496273040771\n",
      "Song 102, Epoch 160/200, Loss: 1.9402347803115845\n",
      "Song 102, Epoch 170/200, Loss: 1.9552452564239502\n",
      "Song 102, Epoch 180/200, Loss: 1.9249317646026611\n",
      "Song 102, Epoch 190/200, Loss: 1.948114275932312\n",
      "Song 102, Epoch 200/200, Loss: 1.981410264968872\n",
      "Validation Loss after song 102: 4.2504607286208715\n",
      "Training on song 103\n",
      "Song 103, Epoch 10/200, Loss: 3.2203657627105713\n",
      "Song 103, Epoch 20/200, Loss: 3.0150368213653564\n",
      "Song 103, Epoch 30/200, Loss: 2.8634426593780518\n",
      "Song 103, Epoch 40/200, Loss: 2.768357753753662\n",
      "Song 103, Epoch 50/200, Loss: 2.673417091369629\n",
      "Song 103, Epoch 60/200, Loss: 2.552523374557495\n",
      "Song 103, Epoch 70/200, Loss: 2.453913688659668\n",
      "Song 103, Epoch 80/200, Loss: 2.4208834171295166\n",
      "Song 103, Epoch 90/200, Loss: 2.3279354572296143\n",
      "Song 103, Epoch 100/200, Loss: 2.2921206951141357\n",
      "Song 103, Epoch 110/200, Loss: 2.250351905822754\n",
      "Song 103, Epoch 120/200, Loss: 2.229384422302246\n",
      "Song 103, Epoch 130/200, Loss: 2.2198092937469482\n",
      "Song 103, Epoch 140/200, Loss: 2.1849613189697266\n",
      "Song 103, Epoch 150/200, Loss: 2.18861722946167\n",
      "Song 103, Epoch 160/200, Loss: 2.1874425411224365\n",
      "Song 103, Epoch 170/200, Loss: 2.201383352279663\n",
      "Song 103, Epoch 180/200, Loss: 2.1949708461761475\n",
      "Song 103, Epoch 190/200, Loss: 2.21113657951355\n",
      "Song 103, Epoch 200/200, Loss: 2.1870107650756836\n",
      "Validation Loss after song 103: 4.363488423518645\n",
      "Training on song 104\n",
      "Song 104, Epoch 10/200, Loss: 2.7490928173065186\n",
      "Song 104, Epoch 20/200, Loss: 2.6159720420837402\n",
      "Song 104, Epoch 30/200, Loss: 2.4929771423339844\n",
      "Song 104, Epoch 40/200, Loss: 2.4662699699401855\n",
      "Song 104, Epoch 50/200, Loss: 2.4195199012756348\n",
      "Song 104, Epoch 60/200, Loss: 2.355053424835205\n",
      "Song 104, Epoch 70/200, Loss: 2.340693473815918\n",
      "Song 104, Epoch 80/200, Loss: 2.2824416160583496\n",
      "Song 104, Epoch 90/200, Loss: 2.2501416206359863\n",
      "Song 104, Epoch 100/200, Loss: 2.2116036415100098\n",
      "Song 104, Epoch 110/200, Loss: 2.149229049682617\n",
      "Song 104, Epoch 120/200, Loss: 2.150486469268799\n",
      "Song 104, Epoch 130/200, Loss: 2.1244406700134277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 104, Epoch 140/200, Loss: 2.0583291053771973\n",
      "Song 104, Epoch 150/200, Loss: 2.0571961402893066\n",
      "Song 104, Epoch 160/200, Loss: 2.023102045059204\n",
      "Song 104, Epoch 170/200, Loss: 2.0185463428497314\n",
      "Song 104, Epoch 180/200, Loss: 1.96644127368927\n",
      "Song 104, Epoch 190/200, Loss: 1.936616063117981\n",
      "Song 104, Epoch 200/200, Loss: 1.952702522277832\n",
      "Validation Loss after song 104: 4.051210161967155\n",
      "Training on song 105\n",
      "Song 105, Epoch 10/200, Loss: 2.62518310546875\n",
      "Song 105, Epoch 20/200, Loss: 2.5036051273345947\n",
      "Song 105, Epoch 30/200, Loss: 2.4246857166290283\n",
      "Song 105, Epoch 40/200, Loss: 2.359278678894043\n",
      "Song 105, Epoch 50/200, Loss: 2.3085711002349854\n",
      "Song 105, Epoch 60/200, Loss: 2.281064510345459\n",
      "Song 105, Epoch 70/200, Loss: 2.1984739303588867\n",
      "Song 105, Epoch 80/200, Loss: 2.1744446754455566\n"
     ]
    }
   ],
   "source": [
    "def harmonies_to_class(harmonies):\n",
    "    harmonies_classes = torch.round(harmonies * 127).long()  \n",
    "    return harmonies_classes\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "num_epochs = 200\n",
    "\n",
    "model = Model(4, 3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "train_model(model, optimizer, criterion, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234bbe1-0257-4c91-a95f-263342853d92",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1d90b-1d91-4fcc-a156-6edcb721d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = [0.01, .001]\n",
    "n_layers= [1,2,3]\n",
    "hidden_dim = [20, 40, 50]\n",
    "epochs= [5000, 10000]\n",
    "best_loss = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "for LR in learning:\n",
    "    for n_layer in n_layers:\n",
    "        for epoch in epochs:\n",
    "            for dims in hidden_dim:\n",
    "                print(f\"Training with LR={LR} and n_layers={n_layer} and epochs={epoch} and hidden_dims={dims}\")\n",
    "                model = Model(input_size=1, output_size=harmonies.shape[2], n_layers=n_layer, hidden_dim=dims)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "                train_model(model, melody, harmonies, optimizer, criterion, epoch)\n",
    "                with torch.no_grad():\n",
    "                    output = model(melody)\n",
    "                    loss = criterion(output, harmonies)\n",
    "                    print(f\"Final Loss: {loss.item()}\")        \n",
    "                # Keep track of the best model (with lowest loss)\n",
    "                if loss.item() < best_loss:\n",
    "                    best_loss = loss.item()\n",
    "                    best_params = {'learning': LR, 'n_layers': n_layer, 'epochs': epoch, 'hidden_dim': dims}\n",
    "print(\"BEST: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9f9e5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_df(df):\n",
    "    X_scaled = df * 127\n",
    "    return X_scaled\n",
    "\n",
    "def midi_to_note_melody(part):\n",
    "    result = stream.Part()\n",
    "    count = 1\n",
    "    prev = round(part[0])\n",
    "    for i in range(1, len(part)):\n",
    "        pitch = part[i]\n",
    "        curr = round(pitch)\n",
    "        if curr == prev:\n",
    "            count += 1\n",
    "        else:\n",
    "            this_note = note.Note(prev, quarterLength=count/4)\n",
    "            result.append(this_note)\n",
    "            count = 1\n",
    "        prev = curr\n",
    "    this_note = note.Note(prev, quarterLength=count/4)\n",
    "    result.append(this_note)\n",
    "    return result\n",
    "\n",
    "def midi_to_note_harmonies(part):\n",
    "    probabilities = torch.softmax(torch.tensor(part), dim=-1).numpy()\n",
    "#     print(probabilities)\n",
    "    result = stream.Part()\n",
    "    count = 1\n",
    "    predicted_notes = np.argmax(part, axis=1)\n",
    "    print(predicted_notes)\n",
    "    prev = predicted_notes[0]\n",
    "    for i in range(1, len(part)):\n",
    "        curr = predicted_notes[i]\n",
    "        if curr == prev:\n",
    "            count += 1\n",
    "        else:\n",
    "            this_note = note.Note(prev, quarterLength=count/4)\n",
    "            result.append(this_note)\n",
    "            count = 1\n",
    "        prev = curr\n",
    "    this_note = note.Note(prev, quarterLength=count/4)\n",
    "    result.append(this_note)\n",
    "    return result\n",
    "\n",
    "def output_to_sheet_music(melody, result):\n",
    "    result_numpy = result.squeeze(0).detach().numpy()\n",
    "    melody = inverse_df(melody).squeeze()\n",
    "    inversed = result_numpy.transpose(1, 0, 2) \n",
    "#     inversed = inverse_df(result_numpy.T) # for reg harmonies\n",
    "    \n",
    "    score = stream.Score()\n",
    "    melody_part = midi_to_note_melody(melody.numpy())\n",
    "    \n",
    "    alto_notes = inversed[0]\n",
    "    tenor_notes = inversed[1]\n",
    "    bass_notes = inversed[2]  \n",
    "    \n",
    "    alto_part = midi_to_note_harmonies(alto_notes)\n",
    "    tenor_part = midi_to_note_harmonies(tenor_notes)\n",
    "    bass_part = midi_to_note_harmonies(bass_notes)\n",
    "\n",
    "    score.append(melody_part)\n",
    "    score.append(alto_part)\n",
    "    score.append(tenor_part)\n",
    "    score.append(bass_part)\n",
    "    score.show('midi')\n",
    "    score.write('musicxml', 'output.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "64ca5e31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67 67 67 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72\n",
      " 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72\n",
      " 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67]\n",
      "[67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n",
      " 67 67 67 67 67 67 67 67 67 67 67 67]\n",
      "[60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n",
      " 55 55 55 55 55 55 55 55 55 55 55 55]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv150633\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv150633_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv150633\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQAFJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAAngA/wMAAOAAQM5gkEhagewggEgAAJBKWs5ggEoAAJBMWs5ggEwAAJBNWqcwgE0AAJBMWqcwgEwAAJBKWs5ggEoAAJBIWoGdQIBIAACQSlqBnUCASgAAkEVazmCARQAAkEdazmCARwAAkEhazmCASAAAkEpazmCASgAAkEhagrsAgEgAAJBKWs5ggEoAAJBMWs5ggEwAAJBNWqcwgE0AAJBMWqcwgEwAAJBKWs5ggEoAAJBIWoGdQIBIAACQSlqBnUCASgAAkEVazmCARQAAkEdazmCARwAAkEhazmCASAAAkEpazmCASgAAkEhagZ1AgEgAAJBPWoGdQIBPAACQUVrOYIBRAACQT1qnMIBPAACQTVqnMIBNAACQTFrOYIBMAACQTlrOYIBOAACQT1qCuwCATwAAkFFazmCAUQAAkE9apzCATwAAkE1apzCATQAAkExazmCATAAAkEpazmCASgAAkEhagZ1AgEgAAJBFWs5ggEUAAJBHWs5ggEcAAJBIWs5ggEgAAJBFWs5ggEUAAJBDWs5ggEMAAJBCWs5ggEIAAJBDWoGdQIBDAACQSFqBnUCASAAAkEpazmCASgAAkExazmCATAAAkE1apzCATQAAkExapzCATAAAkEpazmCASgAAkEhagZ1AgEgAAJBKWoGdQIBKAACQRVrOYIBFAACQR1rOYIBHAACQSFqnMIBIAACQR1qnMIBHAACQRVrOYIBFAACQQ1rOYIBDAACQRlrOYIBGAACQRVrOYIBFAACQQVrOYIBBAACQRVrOYIBFAACQR1rOYIBHAACQSFrOYIBIAACQSlrOYIBKAACQSFqBnUCASADOYP8vAE1UcmsAAAArAP8DAADgAEDOYJBDWrsIgEMAAJBIWorOOIBIAACQQ1qm4SCAQwDOYP8vAE1UcmsAAAAYAP8DAADgAEDOYJBDWrHqYIBDAM5g/y8ATVRyawAAACIA/wMAAOAAQM5gkDxag9hAgDwAAJA3Wq6SIIA3AM5g/y8A\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv150633_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv150633_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_song = test[3]\n",
    "melody = test_song.iloc[0]\n",
    "\n",
    "melody = torch.tensor(test_song.iloc[0].values, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "harmonies = torch.tensor(test_song.iloc[1:].values.T, dtype=torch.float32).unsqueeze(0)\n",
    "harmonies_with_zero = torch.zeros(1, test_song.shape[1], 3)\n",
    "\n",
    "model_input = torch.cat((melody, harmonies_with_zero), dim = -1)\n",
    "result = model(x=model_input)\n",
    "output_to_sheet_music(melody, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c75011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune (hyperparameters, move around test data (refer to notes), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new data + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet music + audio (musicAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new models if time permits (follow steps 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end ** if time permits\n",
    "# - Interactive sheet music\n",
    "# - musescore front end??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121de9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real one and generated compare\n",
    "# train on all songs + test on a different song\n",
    "# measure the test loss not just the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "[60, 0, 0, 0] -> [60, 70, 70, 70] -> [61, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ba97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
