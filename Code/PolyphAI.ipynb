{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d361ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary imports\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c67e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "folder_path = 'Data/'\n",
    "test = []\n",
    "train = []\n",
    "validation = []\n",
    "for dirname in os.listdir(folder_path):\n",
    "    if dirname != '.DS_Store':\n",
    "        for filename in os.listdir(folder_path + dirname):\n",
    "            if filename != '.ipynb_checkpoints':\n",
    "                df = pd.read_csv(folder_path + dirname + '/' + filename)\n",
    "                transposed_df = df.transpose()\n",
    "                if dirname == 'test':\n",
    "                    test.append(transposed_df)\n",
    "                if dirname == 'train':\n",
    "                    train.append(transposed_df)\n",
    "                if dirname == 'valid':\n",
    "                    validation.append(transposed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8606521",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim=50, n_layers=2):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        lstm_output, (h,c) = self.lstm(x, hidden)\n",
    "        model_output = self.fc(lstm_output)\n",
    "        return model_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e503",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, melody, harmonies, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(melody)\n",
    "        loss = criterion(output, harmonies)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6e6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  99 Loss:  tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1099 Loss:  tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1199 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1299 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1399 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1499 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1599 Loss:  tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1799 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1899 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1999 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2099 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2299 Loss:  tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2399 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2499 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2599 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2799 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2899 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2999 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3099 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3299 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3399 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3499 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3599 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3799 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3899 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3999 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4099 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4199 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4299 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4399 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4499 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4599 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4799 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Min-Max normalization technique\n",
    "def normalize_array(array):\n",
    "    X_std = (array - 1) / (88 - 1)\n",
    "    return X_std\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "epoch = 5000\n",
    "# index = 0\n",
    "# for song in train:\n",
    "#     index = index + 1\n",
    "# print(\"training song \", index)\n",
    "song = train[0] # REMOVE\n",
    "melody = torch.tensor(normalize_array(song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1)\n",
    "harmonies = torch.tensor(normalize_array(song.iloc[1:].values.T), dtype=torch.float32).unsqueeze(0)\n",
    "model = Model(1, harmonies.shape[2])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_model(model, melody, harmonies, optimizer, criterion, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234bbe1-0257-4c91-a95f-263342853d92",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e1d90b-1d91-4fcc-a156-6edcb721d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LR=0.01 and n_layers=1 and epochs=5000 and hidden_dims=20\n",
      "Epoch:  99 Loss:  tensor(0.0023, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_size\u001b[38;5;241m=\u001b[39mharmonies\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], n_layers\u001b[38;5;241m=\u001b[39mn_layer, hidden_dim\u001b[38;5;241m=\u001b[39mdims)\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR)\n\u001b[0;32m---> 16\u001b[0m train_model(model, melody, harmonies, optimizer, criterion, epoch)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(melody)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, melody, harmonies, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(melody)\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, harmonies)\n\u001b[0;32m----> 6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning = [0.01]\n",
    "n_layers= [1,2,3]\n",
    "hidden_dim = [20, 40, 50]\n",
    "epochs= [5000]\n",
    "best_loss = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "\n",
    "for LR in learning:\n",
    "    for n_layer in n_layers:\n",
    "        for epoch in epochs:\n",
    "            for dims in hidden_dim:\n",
    "                print(f\"Training with LR={LR} and n_layers={n_layer} and epochs={epoch} and hidden_dims={dims}\")\n",
    "                model = Model(input_size=1, output_size=harmonies.shape[2], n_layers=n_layer, hidden_dim=dims)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "                train_model(model, melody, harmonies, optimizer, criterion, epoch)\n",
    "                with torch.no_grad():\n",
    "                    output = model(melody)\n",
    "                    loss = criterion(output, harmonies)\n",
    "                    print(f\"Final Loss: {loss.item()}\")        \n",
    "                # Keep track of the best model (with lowest loss)\n",
    "                if loss.item() < best_loss:\n",
    "                    best_loss = loss.item()\n",
    "                    best_params = {'learning': LR, 'n_layers': n_layer, 'epochs': epoch, 'hidden_dim': dims}\n",
    "print(\"BEST: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny = pd.DataFrame([[67,62,59,43], [68,62,59,43]]).transpose()\n",
    "# melody = torch.tensor(tiny.iloc[0], dtype=torch.float32).unsqueeze(0).reshape(1,2,1)\n",
    "# harmonies = torch.transpose(torch.tensor(tiny.iloc[1:].values, dtype=torch.float32),0,1).unsqueeze(0)\n",
    "# model = Model(1, harmonies.shape[2])\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# train_model(model, melody, harmonies, optimizer, criterion, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9e5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_array(array):\n",
    "    X_scaled = array * (88 - 1) + 1\n",
    "    return X_scaled\n",
    "\n",
    "def output_to_sheet_music(melody, result):\n",
    "    result_numpy = result.detach().numpy()\n",
    "    inversed = inverse_array(np.squeeze(result_numpy)).T\n",
    "    \n",
    "    score = stream.Score()\n",
    "    melody_part = stream.Part()\n",
    "    alto_part = stream.Part()\n",
    "    tenor_part = stream.Part()\n",
    "    bass_part = stream.Part()\n",
    "\n",
    "    for pitch in melody:\n",
    "        melody_note = note.Note(int(pitch), quarterLength=0.25)\n",
    "        melody_part.append(melody_note)\n",
    "\n",
    "    alto_notes = inversed[0]\n",
    "    tenor_notes = inversed[1]\n",
    "    bass_notes = inversed[2]  \n",
    "\n",
    "    for pitch in alto_notes:\n",
    "        alto_note = note.Note(int(pitch.item()), quarterLength=0.25)\n",
    "        alto_part.append(alto_note)\n",
    "    for pitch in tenor_notes:\n",
    "        tenor_note = note.Note(int(pitch.item()), quarterLength=0.25)\n",
    "        tenor_part.append(tenor_note)\n",
    "    for pitch in bass_notes:\n",
    "        bass_note = note.Note(int(pitch.item()), quarterLength=0.25)\n",
    "        bass_part.append(bass_note)\n",
    "    score.append(melody_part)\n",
    "    score.append(alto_part)\n",
    "    score.append(tenor_part)\n",
    "    score.append(bass_part)\n",
    "    score.show('midi')\n",
    "    score.write('musicxml', 'output.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84fb48c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv51919\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv51919_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv51919\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,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\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv51919_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv51919_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "melody = train[0].iloc[0]\n",
    "# melody = torch.tensor((song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1)\n",
    "# print(\"melody is: \", torch.tensor(normalize_array(song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1))\n",
    "# harmonies = torch.tensor(normalize_array(song.iloc[1:].values.T), dtype=torch.float32).unsqueeze(0)\n",
    "result = model(torch.tensor(normalize_array(song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1))\n",
    "output_to_sheet_music(melody, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune (hyperparameters, move around test data (refer to notes), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new data + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet music + audio (musicAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new models if time permits (follow steps 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end ** if time permits\n",
    "# - Interactive sheet music\n",
    "# - musescore front end??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121de9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real one and generated compare\n",
    "# train on all songs + test on a different song\n",
    "# measure the test loss not just the training loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
