{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d361ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary imports\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from music21 import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c67e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "folder_path = 'Data/'\n",
    "test = []\n",
    "train = []\n",
    "validation = []\n",
    "for dirname in os.listdir(folder_path):\n",
    "    if dirname != '.DS_Store':\n",
    "        for filename in os.listdir(folder_path + dirname):\n",
    "            df = pd.read_csv(folder_path + dirname + '/' + filename)\n",
    "            transposed_df = df.transpose()\n",
    "            if dirname == 'test':\n",
    "                test.append(transposed_df)\n",
    "            if dirname == 'train':\n",
    "                train.append(transposed_df)\n",
    "            if dirname == 'valid':\n",
    "                validation.append(transposed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8606521",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "551e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim=50, n_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        lstm_output, (h,c) = self.lstm(x, hidden)\n",
    "        model_output = self.fc(lstm_output)\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e503",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "511051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, melody, harmonies, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(melody)\n",
    "        loss = criterion(output, harmonies)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c6e6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  99 Loss:  tensor(400.8588, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.0604, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.6534, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5560, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5542, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5530, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5521, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.5514, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5507, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5502, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(564.1576, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.2658, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.9285, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.6357, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.6318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.2490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.2760, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.4338, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.9427, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.4682, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(627.8896, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(45.0592, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7221, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0926, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0870, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0865, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.0861, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.0858, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.0659, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.0853, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(581.2262, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(46.7509, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.4261, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5293, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5171, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.5161, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.5153, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5147, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.5143, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.1685, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(511.9131, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.3603, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.2620, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.8482, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.8448, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.8441, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.8436, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.8432, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.8428, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.0967, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(547.2213, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.4800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.8106, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.4255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.4225, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.4218, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.4213, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.4209, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.4205, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.4202, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(369.4969, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.2391, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.3032, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.2494, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.2488, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.2484, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.2480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.2477, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.2475, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.2473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(422.9365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.1083, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.2270, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.6608, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.7274, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.3183, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.0758, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.1302, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.8686, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.3392, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(433.6619, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.5854, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9277, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.7387, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5658, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.6799, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(22.4952, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9642, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.8965, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.1551, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(522.4534, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.9710, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.5178, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.3100, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.3083, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.3076, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.3070, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.3065, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.3061, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.3058, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(546.1780, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.5585, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.2041, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0661, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0643, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0632, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.7687, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3205, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.0732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7954, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(453.2471, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.6485, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.9621, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6801, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6768, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6755, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6737, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.6731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.6726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(456.6494, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.8224, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.6299, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.2546, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.2509, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.2500, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(16.2493, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.2488, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(16.2484, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.2480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(323.3290, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(18.9329, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.1772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.1204, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1184, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.1169, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1157, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.1148, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1140, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1133, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(354.2560, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(20.5923, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.9138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.8273, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.8258, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.8249, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.8034, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.0814, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.6714, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.0534, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(397.2644, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.9023, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.1630, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.1225, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.9807, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.1326, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.2586, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.7914, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.7293, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.1771, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(516.9121, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.3192, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.8726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.9719, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.0172, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.6211, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.8574, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.4488, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.4544, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.3673, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(509.3745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.7833, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.4627, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.0512, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.0480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.0476, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.0472, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.0470, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.0467, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.0465, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(344.4201, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.1964, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9554, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.8772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.8754, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.8741, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.8732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.8725, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.8720, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.8715, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(650.1168, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(58.0459, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.7095, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.9467, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.9129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.9118, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.9111, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.9105, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.9101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.9096, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(724.9745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(69.7304, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9833, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5844, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5310, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5307, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.5305, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5303, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(394.6660, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.7444, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9521, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8184, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8169, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8161, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8154, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.8149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.8144, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.8140, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(496.0884, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.6174, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.7616, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.3142, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.3097, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.4660, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.8154, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.7644, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.6301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.2844, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(455.0065, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.0227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.2736, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.8400, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.8362, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.8357, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.8353, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.8350, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.8348, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.8346, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(409.2440, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.4749, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(17.2990, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.2188, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(17.2179, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(17.1246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.4026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.5777, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.4670, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9527, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(664.8376, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(64.9501, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.4810, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.2080, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1614, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1604, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1600, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1596, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1594, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1591, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(381.2927, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.6241, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.7199, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.6109, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.6091, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.6079, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.6070, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.6063, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6057, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.6052, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(497.2432, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.5447, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.2650, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.0743, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.0725, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.0716, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.0709, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.0704, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.0699, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.0695, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(861.0795, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(106.8144, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.7584, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.3429, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.1597, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.1561, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.1557, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.1552, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.1549, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.8597, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(601.6296, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(49.8573, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.5623, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4617, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4465, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4456, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4449, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.4443, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.4439, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.4434, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(334.1406, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.5353, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.1042, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.9992, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.9982, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.9975, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.9970, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.9966, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.9962, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.9959, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(485.4095, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.1049, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1541, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.7869, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.7835, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7826, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7818, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7811, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.7806, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.7801, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(424.6270, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.1674, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.5816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.5732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.5721, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.5712, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5706, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.5700, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5696, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.5692, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(613.8784, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(57.6426, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.4327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.7580, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.7262, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.7248, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.7238, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.7230, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.7223, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.7217, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(604.4797, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(148.3351, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(98.9029, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(85.2376, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(74.9284, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(68.4264, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(63.3685, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(58.1519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(54.9594, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(50.6641, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(440.5734, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.7249, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9604, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.7707, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.7686, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.7677, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.7670, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.7664, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.7659, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.7655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(317.7911, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.4482, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.4387, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.2724, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.6095, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.3067, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.2124, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.2610, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.0162, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.5016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(510.1521, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.0140, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.4049, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8783, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8722, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8708, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8699, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.8691, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.8684, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.8679, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(499.0128, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.9682, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.8677, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.4508, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.4472, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.4465, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(16.4460, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.4495, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.7735, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.4824, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(449.2206, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.2575, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.5132, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.1512, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.1481, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.1475, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.1471, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.1467, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.1464, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.1461, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(453.0367, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.6170, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.7571, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4027, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.3987, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.3974, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.3964, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.3957, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.3951, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.3946, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(484.7561, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.4378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7829, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.3132, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.3089, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.3083, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.3079, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.3076, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.3073, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.3070, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(489.6693, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.3939, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.2827, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.0826, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.0805, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.0795, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.0788, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.0781, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.0776, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.0772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(391.7907, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.2246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(25.3073, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(25.2430, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(25.2413, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(25.2401, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(25.2393, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(25.2386, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(25.2381, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(25.2377, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(550.5671, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.6397, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.4639, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6454, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.7519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.2473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.1359, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.5924, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7162, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.2499, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(424.0191, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.8386, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.2596, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.2466, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.2449, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.2436, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.2426, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.2416, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.8259, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.6691, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(529.4644, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(43.4087, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.4902, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.7453, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.7365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.7356, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.7350, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.7344, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.7340, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.7336, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(436.3862, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.0665, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.3412, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.3387, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.6782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.4545, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.1751, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.2586, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.0553, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9279, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(397.2950, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.8991, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.3566, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.1885, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.1867, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.1858, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.1851, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.1845, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.1841, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.1837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(429.8403, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.6011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1142, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0770, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0761, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0755, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.4255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.4338, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.9446, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.7931, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(523.3765, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.9634, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.2852, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8036, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.7994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.7990, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6500, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.3559, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.5787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1889, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(648.9954, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(49.6123, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9833, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0201, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0190, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.0183, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.0177, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.0172, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.0167, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(439.3802, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.0854, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1878, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8654, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8648, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.8643, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.8639, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.8635, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(458.9812, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.0251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.8981, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.7425, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.7397, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.7380, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.7366, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.8462, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6925, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.9604, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(564.2322, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.2515, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.5393, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.2114, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.0888, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.1060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5711, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1889, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5328, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.0857, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(470.7174, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.0875, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.5745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2344, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.5080, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9223, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.6726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.5717, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.5244, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.7851, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(479.6815, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.2068, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.5899, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.4223, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.4201, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.4189, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.4180, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.4173, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.4167, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.4163, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(694.3548, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.3740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.4810, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.4759, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.4750, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.4743, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.7813, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6218, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.5747, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(437.0218, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.1710, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.1627, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.1193, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.1187, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.1182, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.1179, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.1181, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.1174, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.1172, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(446.4655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.2823, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.3526, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.0824, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.0800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.0789, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(18.0781, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(18.0774, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(17.8603, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.8333, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(420.9299, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.9887, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0583, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.9065, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.9045, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.9034, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.9025, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.9018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.9013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9008, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(380.4868, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.1245, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9806, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.9281, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.9230, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.9214, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9202, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.9193, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9185, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(462.2397, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.4492, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.0040, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.8127, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(17.8108, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(17.8129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(17.2169, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.4930, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.7559, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1679, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(398.8946, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.0854, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8075, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6790, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6779, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6774, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6769, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6765, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.6762, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.6386, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(440.7496, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.3764, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.6448, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.4972, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.4955, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.4945, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.3930, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1880, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.7030, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7901, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(399.2819, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(16.5720, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8221, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8108, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.8098, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8091, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.8085, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8080, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.5561, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.4298, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(543.3505, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.1463, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1744, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5354, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5289, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5281, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5275, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.5270, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.3732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.3843, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(518.5109, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.2415, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.4601, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.0388, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.0342, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.0328, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.0318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.0310, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.0303, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.0297, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(423.8446, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.0726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.8926, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.8659, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.8646, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.8637, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.8629, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.1451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6714, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(336.5314, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(12.8852, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.6632, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.6597, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.6585, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.6576, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.6569, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.6563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6558, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.6554, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(468.3298, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.4382, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.8593, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.5422, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.5393, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.5386, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.5380, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.5375, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.1637, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.8866, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(358.2127, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.3070, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.1994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1295, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1278, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1267, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1258, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1241, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(659.0527, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(53.8584, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8684, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8672, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8667, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8663, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.8659, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5887, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.2765, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(476.7811, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.8545, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.7935, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.7281, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.7271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.7265, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.7260, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.7256, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.7249, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.6816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(505.1805, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.5020, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.5064, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.2626, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.2606, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.2599, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.2593, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.2588, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.4424, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.8283, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(535.1134, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.7278, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.8421, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.5018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.4992, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.4987, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.4984, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.4981, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.4978, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.4976, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(526.9090, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.7873, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1071, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.0254, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.0193, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.0061, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.9737, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.9735, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.8704, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(473.5897, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(40.4478, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9510, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.2814, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.2739, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.2731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.2724, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.2718, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.2714, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.2709, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(393.8924, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.9184, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.3810, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.2747, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.2734, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.2725, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.2717, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.2711, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.2705, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.2700, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(572.8624, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.3018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7548, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0048, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9968, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.9961, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.9956, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9957, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.9948, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5683, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(390.7626, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.7581, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9427, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.8630, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.8605, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.8588, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.8575, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.8565, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.8557, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.7633, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(431.6622, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.4984, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9311, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.8958, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.8946, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.8938, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.8931, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.7090, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.3336, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.1796, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(507.6963, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.9280, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.8887, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.3579, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.3529, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.3522, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(16.3525, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.3513, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(16.3509, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.3514, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(529.2296, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.5326, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.5333, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.3596, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.3586, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.3582, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.3579, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3576, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.3574, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.3571, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(478.5823, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(39.3164, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.6740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.3204, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.3176, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.3170, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(18.3165, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.9295, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.4871, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.2698, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(424.5481, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.6573, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.1300, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.9678, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(17.9663, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.0226, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.6914, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.6774, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.8758, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.0078, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(551.3980, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(47.7815, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.2072, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.8057, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.7798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.7788, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.7782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.7777, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.7772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.7768, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(549.1434, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(55.7653, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9718, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1083, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.1941, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(7.3721, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.1280, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.3514, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.0740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(6.5994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(487.2724, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.0591, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.0589, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.0581, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8262, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6009, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3784, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5082, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.3589, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(541.4103, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(51.2217, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(20.9622, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.2507, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.1636, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.6751, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.1288, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9738, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.3452, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.4676, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(423.6257, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.0243, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(37.1614, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(37.0089, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(36.5260, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(35.9130, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(34.8553, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(36.8186, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(35.9436, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(35.0263, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(381.6534, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.6988, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1688, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.1095, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.1087, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.1081, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.1076, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.1072, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.1068, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.1065, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(439.5017, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.6569, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1949, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.9929, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.9914, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.8308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.6982, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.7419, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.6664, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.8964, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(497.4227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.5771, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.0179, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.1958, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.1853, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.1849, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.1847, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1844, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.1842, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1840, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(501.9514, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.3483, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.0826, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.8873, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.8854, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.8844, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.8837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.8831, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.8826, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8821, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(366.6638, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.0271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9498, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8771, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8762, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6276, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1637, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8369, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(629.6896, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(58.1744, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7322, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.0706, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.0415, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.0407, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.0402, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.0399, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.0395, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.0392, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(448.5282, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.8439, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.0451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.9810, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9790, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.9776, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.9766, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9758, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.9751, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9746, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(386.8661, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.2001, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.6251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4247, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4228, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4096, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.3219, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.3745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2270, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1594, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(438.7010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.0131, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9170, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8727, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8706, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.9463, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.5971, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.5378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1620, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(344.3908, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.3599, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.7992, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.7085, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.7077, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7072, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7069, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7066, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.7064, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1552, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(348.4120, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.8683, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.1548, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.0843, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.0832, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.0825, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.0819, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.0814, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.5889, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.4250, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(480.8914, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.5487, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3540, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.0631, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.0604, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.0596, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.0590, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.0585, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.0576, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9279, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(398.4777, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.7497, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(26.0323, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(25.5794, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(22.7573, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.2301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.4121, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.4630, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1596, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(616.8611, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.7401, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.9426, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.8877, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.8853, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.8831, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.8808, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.6544, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6870, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.3119, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(349.9430, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.7668, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.3129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.2558, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.2544, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.2534, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.2527, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.2521, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.2516, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.2511, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(615.7746, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(67.7089, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.9024, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.8565, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.7691, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.7548, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.0427, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.5685, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.2731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.1109, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(527.1610, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.6966, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.2848, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.0242, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.0216, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.0205, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(16.0197, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.0192, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(16.0186, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.0182, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(360.5293, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(20.3273, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0056, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.9405, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.9393, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.9385, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.9378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6356, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.0154, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.6466, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(521.0555, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.6422, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.6028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5488, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5474, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5463, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5455, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.5448, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5443, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5439, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(525.2864, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(49.3898, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(19.4434, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.6441, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.6340, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.6329, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(18.6321, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(18.6314, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(18.6309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(18.6304, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(438.3047, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.9933, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.3619, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1869, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1843, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1828, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1807, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1793, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(373.1750, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.0389, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.0731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.9646, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.9625, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.9611, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.9601, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.9593, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.9587, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.9581, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(584.3058, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.4331, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.8007, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(7.8060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(7.7945, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(7.7939, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.7935, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.7932, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.7929, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.7927, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(422.0337, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.1463, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.0509, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.0333, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.0301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.0270, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.0239, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.0207, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.5255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.4103, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(463.7424, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.1227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.7507, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4742, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.2384, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.8089, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.6494, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.9507, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.0800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.2748, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(293.1860, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.8959, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.3626, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.3336, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.3327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.3321, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.3316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.3311, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5412, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.9820, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(389.8745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.4560, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.6241, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.4244, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.4227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.4220, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(18.4215, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(18.4210, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.1360, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.4350, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(514.1647, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(40.3526, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.3966, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.8991, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.8942, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.8933, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.8926, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.8920, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.8915, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.8912, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(503.9930, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.7849, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.9788, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.6370, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.6335, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.6324, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.6316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.6310, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6306, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.6302, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(326.9909, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(16.2838, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.9229, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.8761, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.8747, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.8737, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.8729, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.8723, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.8718, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.8714, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(490.0255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.9360, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.7310, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6913, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6827, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.5687, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.5002, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.4995, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.4989, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(355.9367, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.3257, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.2855, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.1848, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.6323, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5259, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.2484, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.0813, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.1538, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.8004, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(454.1697, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(18.6810, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3854, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.2775, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.2753, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.2722, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.2958, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.5692, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9208, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7325, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(443.6495, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.4006, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.8640, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.7042, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.7028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.7022, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.7017, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.7013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.7009, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.7006, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(467.7385, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.3394, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9531, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4935, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4894, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4888, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.4310, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2718, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.6076, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(616.1607, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.9416, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.6918, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.9172, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.9090, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9088, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.9085, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.9084, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9082, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9075, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(561.7203, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.6793, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.9301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.7172, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.7147, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.7127, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.7107, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.7086, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.7064, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.7042, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(502.7147, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(40.2121, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3983, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.7176, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.7109, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7104, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7100, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7098, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.7095, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.7093, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(541.5703, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.1036, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.1365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.0737, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.0687, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.0639, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.0591, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.0542, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.0490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.0436, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(557.1877, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.4587, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.7345, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.5175, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4567, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.0744, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.5490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.4318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.3624, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.3822, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(528.0162, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.4439, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.0033, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1194, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1186, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1180, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1175, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1171, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1168, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(526.4423, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.2990, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.6454, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.0164, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.0091, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.0077, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(16.0066, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.0057, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(16.0049, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.0043, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(479.2093, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.9456, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(19.1837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.8907, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.8878, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.8868, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(18.8860, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(17.9365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.8782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.1644, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(604.2890, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(67.6533, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(19.4636, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.2816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(17.2808, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.7130, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.7258, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.9775, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.0883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.0064, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(356.5706, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.6350, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.0573, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.9520, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.9506, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.9497, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.9490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.9485, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.9177, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.7118, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(437.2941, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.8350, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.5619, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.4324, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.4309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.4301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.4296, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.4291, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.4288, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.4285, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(464.2501, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.2493, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(17.2288, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.6930, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.6877, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.6870, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(16.6864, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(16.6860, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(16.6857, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.6880, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(473.9128, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.4091, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.9599, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.8289, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.8271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.8260, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.8252, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.8245, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.8239, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8247, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(447.8194, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.6138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.4775, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.0160, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.0829, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7857, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5705, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2038, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.9812, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.5274, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(491.3244, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.1437, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.5401, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4713, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4705, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.1811, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3264, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1235, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.0373, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(407.5492, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.4823, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.4279, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2167, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1852, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9241, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.0008, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.6799, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.5421, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.4015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(401.9563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.5542, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.3928, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.7502, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.9078, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.6395, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4701, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.3773, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.6060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(542.4893, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.6413, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.8495, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.2286, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.2227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.2222, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.1872, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.2215, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.2219, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.8145, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(373.4120, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.3307, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.6289, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.4963, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4948, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.4941, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.4935, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4930, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.4926, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.4923, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(343.0719, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.8858, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.3549, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.3084, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.3063, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.3047, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.3035, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.3026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.3018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.3011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(522.2244, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.5215, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.6062, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.1599, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.1559, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.1550, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.1543, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.1537, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.1533, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.1529, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(385.6414, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.7319, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.0487, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.6651, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.0484, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(7.7184, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.7456, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.5519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.3966, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.2735, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(561.9662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(47.7251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.9291, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.9266, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.9249, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.9236, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.9226, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.9217, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.9210, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(419.1227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.6081, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7270, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5657, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5640, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.5630, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.4162, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1751, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2038, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1406, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(486.2862, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.4262, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.1904, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.9290, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.9271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9263, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.9257, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.9251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.1129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(436.4237, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.7776, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.3428, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.1885, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(16.1871, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(16.1863, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.7396, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.7206, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9660, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.4962, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(465.0544, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.7674, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.8990, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9783, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.4963, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1531, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.9561, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.8861, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.8575, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(425.1745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.3092, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(20.5174, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(20.2933, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(20.2920, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.9698, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.8060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8915, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.8043, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8831, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(459.3533, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.3588, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.1544, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.9103, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.9081, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.9073, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.9066, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.9060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.9054, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.9049, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(354.8982, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.7040, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9411, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.9378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.7764, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.0474, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1275, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.8671, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.5555, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.2052, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(511.3383, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.4299, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.1378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.7513, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.7479, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.7470, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.7464, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.7458, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.7452, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.5264, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(544.5142, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.0859, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.7310, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.2261, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.2217, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.2211, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.2206, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.2202, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.7113, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(455.5149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.5427, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.2867, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.2318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.2305, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.2297, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.6902, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.6045, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.2757, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7646, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(399.7909, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(20.0529, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.1801, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.1265, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1252, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.1243, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.0910, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4412, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.8387, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.3036, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(574.8747, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.6801, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.8012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.2567, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.2520, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.2512, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.0617, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5771, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.8052, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1691, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(450.5800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.4845, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.3014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.1405, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1380, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.1365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1353, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.1344, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1337, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1331, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(557.4833, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(43.4351, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.2393, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.4924, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.4842, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.4839, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.4836, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.4834, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.4832, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.1619, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(482.3595, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.0140, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1293, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8571, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.8545, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8535, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7763, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6492, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.6866, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.2060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(483.1626, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.8099, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.6613, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.6600, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.6592, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.6586, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.6582, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.6578, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.6575, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(508.6546, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.1709, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.9838, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6538, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6509, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6500, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6494, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.6486, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.6483, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(541.7707, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(46.2107, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9280, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.9787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.9669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.9665, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.9662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.9659, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.9657, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(336.2032, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.4625, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(17.2501, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.1840, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(17.1819, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(17.1804, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(17.1793, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(17.1784, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(17.1776, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(17.1768, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(457.5507, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.9318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.9320, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.7817, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.7803, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.7795, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.7789, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.7643, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6758, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.5142, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(528.9257, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.4463, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8847, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.7708, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.7691, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7680, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.7447, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.0698, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9153, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8361, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(637.5786, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(61.7141, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7781, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.9474, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.9153, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.9144, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.9138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.9134, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.9131, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9128, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(546.7994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.3556, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.9807, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.7126, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.7102, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.7093, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.7087, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.7082, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7077, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7074, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(376.0030, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.2473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.9341, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.8085, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.8068, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(18.8058, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(18.8050, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(18.8044, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(18.8038, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(18.4184, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(632.4642, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(49.9201, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.3892, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1235, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1217, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1207, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1199, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1192, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1187, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1185, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(399.9305, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.9307, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.2408, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.0983, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.0968, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.0960, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.0954, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.0948, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.0944, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.0940, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(711.5475, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(47.4599, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.2865, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.4765, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4683, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.4680, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.4677, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4675, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.4674, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.4672, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(379.0208, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.4480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(19.5409, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(19.4318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(19.4299, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(19.4287, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(19.4137, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.7158, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.7901, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9664, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(629.0027, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(47.8182, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.3486, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5225, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4708, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.8269, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.3919, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1622, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.0048, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(377.8394, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.4775, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7567, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.6782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.6776, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.6773, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.6115, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7364, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.5066, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.2155, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(312.7325, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(15.7508, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.4489, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.4151, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.4132, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.0450, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.1800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.6424, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.1062, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.4970, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(515.2561, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.1165, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.6524, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2722, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.2684, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.2675, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.2668, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.2658, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.2655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(264.2875, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(15.0896, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1668, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.1568, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.1538, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.1516, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.1500, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1487, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.1477, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1468, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(410.1449, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.5202, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1163, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.9865, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9850, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.9842, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.9836, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9831, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.9827, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9823, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(344.4470, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(16.8091, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.2480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.2377, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.2364, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.2355, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.2349, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.2343, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2339, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.2336, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(405.8451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(22.0112, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.3853, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.3333, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.3316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.3305, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.3295, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.0239, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9043, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.1806, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(578.8891, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.0622, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.9149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.5093, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.5059, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.5052, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5047, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.5043, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5039, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.4501, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(483.5669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.2390, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.8009, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.7309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.7300, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.7293, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.7289, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.7285, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.7281, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.4419, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(299.8978, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(15.8994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.6631, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6497, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6486, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6479, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.5278, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.8903, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.5462, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(434.8152, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.1543, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7024, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5935, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5925, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.5918, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.5756, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5908, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.5905, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.5901, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(521.2972, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(39.9045, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.9652, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.6867, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.6839, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.6824, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.6813, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.6805, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.6792, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(493.3020, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.7945, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.6550, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0704, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0642, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0634, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5274, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.3012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(535.4195, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.2781, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.6843, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6512, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6498, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6488, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6481, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.5553, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7558, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.7318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(675.1377, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(60.8656, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1638, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.2711, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.2358, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.2348, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.2343, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.2338, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.2335, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.2331, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(437.7917, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.9144, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.0565, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.9670, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9656, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.9519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.9122, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.7905, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5971, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.3022, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(365.0547, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.6583, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(17.0148, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(16.9043, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.6502, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.5105, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4231, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2685, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.7907, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9729, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(286.4128, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(17.5105, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.0780, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0620, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0604, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0579, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.2912, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.0839, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.9772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.4612, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(471.7865, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.3179, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.7969, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.6898, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.6869, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.6840, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.6810, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.6779, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6746, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.6711, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(374.1642, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(20.5138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.3096, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2337, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.2319, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.2307, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.3816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.7586, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.6487, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(548.4535, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.8457, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2256, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.2172, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.2164, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.2158, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2153, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.2148, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.2145, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(593.9967, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.0259, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(17.7873, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(17.5528, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(17.5506, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(17.5496, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(17.5489, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(17.1036, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(16.8615, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(16.6504, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(556.2228, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(40.2946, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.3731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.3674, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.3671, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.3669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3170, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.2547, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.3273, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(497.5627, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.8721, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.7165, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.4515, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.4492, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.4484, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.3802, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.3902, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.2497, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.0535, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(516.3645, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.4363, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.2129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.9036, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.9009, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.9000, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.8993, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7572, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5896, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.3132, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(516.1226, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(39.1155, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.5930, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.1105, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.1059, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.1049, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.1042, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.1036, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.1030, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.1026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(303.5359, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(16.0582, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.2031, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.1824, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.1765, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.1458, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.1429, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1408, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.1391, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(561.9128, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.0740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.3875, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.6931, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5077, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.1197, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.7539, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.4773, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2629, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.0696, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(428.3246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.4478, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.4024, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.2776, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.2747, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.2734, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.1358, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.6782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2771, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.8028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(426.6805, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.5056, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1162, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0345, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.0327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.0314, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.0304, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.0297, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.0291, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.0285, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(531.1643, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.9703, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.9334, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.9292, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.9283, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.9276, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.9235, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.9246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9180, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(655.5643, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(45.7597, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.4149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.5345, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.5242, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.5234, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.5229, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.5224, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.5221, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.5211, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(682.7791, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(53.9271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8686, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.6707, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.6547, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.6603, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.9922, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.7284, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.6641, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.6065, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(656.8661, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.3508, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.6110, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.1326, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.1280, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.1271, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.1264, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.1259, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.1255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.1251, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(659.1141, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(53.5436, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.7316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.9955, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.9897, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.6705, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.2897, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5343, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.8995, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.8563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(477.2616, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(36.9071, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.0396, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.6183, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.6137, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.6124, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.6115, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.6107, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.6101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.6096, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(766.5418, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(81.6343, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.5903, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.8352, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.7816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.7795, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.5840, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1578, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7818, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.5335, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(560.7786, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.9709, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.7654, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.9196, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.9090, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.9081, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.9074, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.9069, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.9064, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.9060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(527.6148, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.7480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.3908, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.3860, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.3850, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.3843, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3836, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6053, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7554, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(507.9115, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.0589, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.6415, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.0662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.0603, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.0598, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.0594, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.8580, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.7881, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.5346, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(437.0006, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.3968, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(18.7022, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(18.5756, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(18.5725, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(17.9280, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(17.1885, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.7309, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.7250, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1092, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(535.7058, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.4120, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9263, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.8338, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.8328, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.8322, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.8317, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.2072, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2953, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.4974, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(458.7594, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.0912, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.9007, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.4563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.4510, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.4502, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.6458, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.3731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.9401, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(432.0690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.3134, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8087, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.8071, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8061, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.8053, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8047, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.8042, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.2140, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(565.7321, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.2637, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.4185, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.2175, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.2164, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.2160, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.2156, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.2154, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.2151, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.2149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(403.3772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.0812, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.3623, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.3205, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.3198, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.3193, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.4008, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.0848, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.5895, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.3685, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(366.2082, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.6308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.5307, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.4688, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.4676, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.4669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.4663, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.4658, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.4655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.4651, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(415.2458, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(18.2388, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.0586, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(7.9783, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(7.9765, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(7.9754, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.9745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.9737, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.9731, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.9726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(365.6420, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.6475, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3256, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.2517, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.2500, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6346, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.6789, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.7124, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.9942, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.6616, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(438.0893, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.6502, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.5488, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4378, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4364, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4355, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4348, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.4342, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.4338, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.4334, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(474.4227, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.4145, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.6010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.5039, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.5019, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.5005, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.4994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.4985, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.8750, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.8926, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(885.6512, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(98.0939, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.6905, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.7961, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.7929, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.7925, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.7921, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.7918, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.7916, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7914, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(321.9573, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.7032, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.7375, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.6952, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.6941, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.0159, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5748, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.3949, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1951, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.0761, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(549.5877, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.5178, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.5458, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(7.9853, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(7.9798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(7.9792, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.9787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.9185, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.7481, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.7340, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(506.8278, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.4927, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.9033, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.5860, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.5833, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.5826, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.5820, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.5816, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5812, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.5037, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(297.3595, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(18.4632, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.0308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.0010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.9997, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.9988, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.9981, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9975, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.9971, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9815, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(421.1837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.3773, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.8181, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.6793, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.6778, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.6771, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.6764, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.6760, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.6756, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.6752, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(437.9882, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.1942, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.8534, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5367, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.5312, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.5301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5292, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.5285, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.5279, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(510.2865, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.9112, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.6010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.4494, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.2461, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.6342, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.0445, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.4261, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.7101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.3798, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(487.4974, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.6532, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.2871, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.9837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.9811, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9803, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.9797, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.9792, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9788, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9785, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(454.2870, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.9441, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.3578, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.8387, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.8327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.8316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.8308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.8301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.8296, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.8292, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(483.1538, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.5414, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.8934, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.7050, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.7035, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7022, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7017, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.7013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.7010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(645.5466, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(53.7525, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.0911, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.8947, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.8794, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.8790, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.8787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.8785, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.8154, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.3837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(349.8431, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.8206, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.4839, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.4015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4005, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.3999, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.3994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.3990, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.3986, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.3983, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(400.8350, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.3052, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.2242, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.1896, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.1872, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.1854, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.1839, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.1828, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.0181, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9554, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(419.5489, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.0465, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.6033, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.4495, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.4473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.4461, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.4451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.4443, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.4435, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.8682, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(415.6186, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(17.5241, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.5844, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.5805, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.5571, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.4836, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.4872, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4182, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.0911, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1031, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(563.6019, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.3539, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.7681, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.6334, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6322, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.6314, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.6307, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.6302, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.6298, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.6294, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(416.5007, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(23.1439, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.8617, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.8186, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.8124, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.7656, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.7633, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.7625, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.7618, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9901, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(483.8857, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.5039, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.8508, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.7994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.6485, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.9300, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.3945, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.4976, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(7.0067, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(6.4999, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(448.7435, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.5346, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.7224, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.4814, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4792, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.4784, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.4777, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.4772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.4767, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.4763, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(432.4089, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.4577, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.8144, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5824, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5799, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5788, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5779, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.5772, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5766, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5761, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(499.2362, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.8974, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.0363, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.9555, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.9495, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9384, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.9367, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.9359, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9354, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9351, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(303.4047, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(15.2978, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.1716, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1535, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1507, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1498, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1483, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1478, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(438.7487, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.8503, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.3225, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.1490, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.1473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.1464, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.1457, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.1452, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.1454, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.1445, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(564.1023, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(44.3218, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.2318, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4256, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4161, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4141, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.4134, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.3996, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.8989, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(554.2695, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.6104, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1055, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.6908, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.6878, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.6874, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.6870, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.6868, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.6865, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.6864, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(471.7563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.4888, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.8435, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4185, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4127, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4119, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7229, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.7557, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7996, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(443.3026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(28.7724, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.5520, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.4026, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.4012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.4004, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.3998, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.3994, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.0002, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.9214, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(426.9883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.6101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1293, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8541, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.6287, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.4603, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.3749, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2804, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1938, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.2759, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(216.0102, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(16.1568, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.7263, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5056, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.3568, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.2458, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.1590, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.0894, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.0325, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.9855, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(485.3305, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(27.5496, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.7817, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.5700, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.5680, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.5670, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.5662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.5656, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.5651, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.5646, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(570.8480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.1372, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.2480, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.7450, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.7404, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.7398, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.7393, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.7390, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.7387, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.7384, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(513.1492, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.7747, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.8995, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.6845, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.6829, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.6821, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.6794, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8269, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6439, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9607, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(600.2268, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.8990, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.0164, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.5535, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.5499, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.6327, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.0635, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.9366, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.4234, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.9655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(729.8259, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(68.2636, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.4701, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2529, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.2451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.2438, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.2424, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2410, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.2396, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.2381, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(382.2391, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.6320, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.4438, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.9301, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1372, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.7006, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(7.7537, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(7.2514, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(6.9536, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(6.7766, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(429.0354, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(25.0636, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.9862, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8451, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.8434, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8425, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7180, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.2411, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.0474, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.9905, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(423.2794, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(29.3192, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.8030, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5890, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5021, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.7636, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4275, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8414, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.6553, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.3693, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(565.4822, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.9199, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.5199, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.2572, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.2549, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.2539, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.2531, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.2525, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.2519, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.2515, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(476.7801, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.7932, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.9582, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.4953, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.4910, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.4905, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.4900, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.4896, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.4893, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.4891, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(588.0092, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.5677, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.5193, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5152, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5135, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.5123, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.5114, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5107, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.5101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.5096, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(604.8372, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(46.3642, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.0761, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.8641, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.8631, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.8624, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.8619, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.2881, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.9052, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8339, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(537.9902, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(45.3606, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.1802, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.3376, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.3339, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.1424, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8580, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.7289, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.3636, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(478.3546, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.1395, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.3781, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.8583, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.2915, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.1774, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.1149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.0572, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.9160, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.6840, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(623.1053, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(49.9539, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.2264, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.1204, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1053, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.1045, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1040, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.1035, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1032, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1028, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(368.8121, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.3135, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.2783, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.1858, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1843, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.1833, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1827, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.0389, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.4176, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.3098, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(753.5308, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(52.6392, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.8628, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8221, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.8101, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8096, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.8092, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8089, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.8086, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.8084, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(597.4678, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.8081, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0719, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.2882, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.2792, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.2787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.2783, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.5296, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.0774, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.6878, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(532.5267, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.5090, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.5291, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.8419, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.8347, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.8340, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.8335, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.6913, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.9216, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.3885, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(562.7380, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.0030, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.5613, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.9551, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.9491, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.9481, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.9473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.9468, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.9463, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.9459, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(430.1022, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.6201, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.0535, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.7773, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.7746, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.2787, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.3076, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7276, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.5459, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.4016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(454.4129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(34.0727, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(15.8721, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.5696, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.5669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.5662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.5655, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.5650, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.5645, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.5641, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(345.3652, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(18.7999, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9230, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.9205, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.9193, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.5422, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4033, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.9420, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.4661, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.6281, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(423.0952, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.8229, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3112, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.1768, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.1753, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.1746, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.1740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.1736, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.1732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.1729, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(450.3773, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.3424, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.5634, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.4274, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.4262, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.4257, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.4252, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.4249, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.4246, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.4243, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(347.2522, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.2951, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(24.1297, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(24.1261, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(24.1247, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(24.1236, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(24.1229, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(24.1222, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(24.1217, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(24.1213, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(465.5135, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(32.9018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1335, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.7384, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.7343, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.7334, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.7326, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.7321, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.7316, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.7186, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(497.5219, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.4966, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.4543, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.7864, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.4365, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.0097, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.4218, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.9690, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.2065, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(7.9422, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(556.8628, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(35.3222, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.5753, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.1779, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.1740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1728, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.1721, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.1715, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.1710, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.1707, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(470.2837, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(30.9266, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.3839, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.0828, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.0800, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.0792, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.0786, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.0777, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.0109, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.7255, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(378.2023, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.9783, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.8158, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.5565, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.3445, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.1361, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.8495, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.4954, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.3108, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.8827, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(513.5202, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(37.7574, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1070, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.5755, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.5700, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.5691, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.5683, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.5677, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(12.5671, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(12.5666, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(479.8612, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(24.5760, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(10.7906, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.6760, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.6742, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(10.6730, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(10.6721, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(10.6714, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(10.6708, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.6703, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(506.6215, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(31.3012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.8025, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.7151, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.7138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.7130, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.7124, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.7119, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.7115, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(14.7112, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(422.3782, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(21.3277, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.5660, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.5232, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.5218, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.5208, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.5201, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.5195, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.5190, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.5185, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(430.8027, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(26.4473, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(14.9124, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(14.8157, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(14.8146, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(14.8140, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(14.8134, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(14.8129, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(14.5093, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.9835, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(475.9456, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(19.6342, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(11.2205, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.1753, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.1745, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.1740, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.1735, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.1732, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.1729, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(547.1195, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.4030, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.1593, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(12.4825, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(12.4751, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(12.4742, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(12.4736, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(12.2844, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.2401, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.1068, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(334.0795, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(20.1662, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(13.4665, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(13.4281, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(13.4265, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(13.4253, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(13.4243, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(13.4236, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(13.4229, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(13.4224, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(456.8117, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(41.9455, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(24.3698, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(24.0946, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(24.0928, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(24.0925, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(24.0922, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(24.0920, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(24.0918, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(22.8352, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(515.5801, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(33.4330, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.1726, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(11.8286, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(11.8254, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(11.8244, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(11.8236, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(11.8230, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(11.8224, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(11.8219, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(573.9651, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(38.6234, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(8.5857, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(8.5086, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(8.5075, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(8.5067, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(8.5060, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(8.5055, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(8.5050, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(8.5046, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(508.3138, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(45.7538, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(12.0240, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(10.7560, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(10.4658, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.9883, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.8086, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.7669, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.8972, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(10.7561, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(345.0098, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(20.2950, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(9.6331, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(9.5149, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(9.5130, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(9.5119, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(9.5110, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(9.5104, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(9.5097, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(9.5094, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  99 Loss:  tensor(494.9585, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(42.5897, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(16.2371, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(15.5674, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(15.5587, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(15.5574, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(15.5563, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(15.5555, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(15.5548, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(15.5542, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "for song in train:\n",
    "    melody = torch.tensor(song.iloc[0], dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1)\n",
    "    harmonies = torch.transpose(torch.tensor(song.iloc[1:].values, dtype=torch.float32),0,1).unsqueeze(0)\n",
    "    model = Model(1, harmonies.shape[2])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_model(model, melody, harmonies, optimizer, criterion, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b889de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny = pd.DataFrame([[67,62,59,43], [68,62,59,43]]).transpose()\n",
    "# melody = torch.tensor(tiny.iloc[0], dtype=torch.float32).unsqueeze(0).reshape(1,2,1)\n",
    "# harmonies = torch.transpose(torch.tensor(tiny.iloc[1:].values, dtype=torch.float32),0,1).unsqueeze(0)\n",
    "# model = Model(1, harmonies.shape[2])\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# train_model(model, melody, harmonies, optimizer, criterion, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f9e5e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv98644\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv98644_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv98644\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,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\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv98644_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv98644_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/foodrunner/CS370/PolyphAI/Code/output.xml')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melody = train[0].iloc[0]\n",
    "result = model(torch.tensor(melody, dtype=torch.float32).unsqueeze(0).reshape(1, train[0].shape[1], 1))\n",
    "\n",
    "score = stream.Score()\n",
    "melody_part = stream.Part()\n",
    "alto_part = stream.Part()\n",
    "tenor_part = stream.Part()\n",
    "bass_part = stream.Part()\n",
    "\n",
    "for pitch in melody:\n",
    "    melody_note = note.Note(int(pitch))\n",
    "    melody_part.append(melody_note)\n",
    "\n",
    "alto_notes = result[0, :, 0]\n",
    "tenor_notes = result[0, :, 1]\n",
    "bass_notes = result[0, :, 2]  \n",
    "\n",
    "for pitch in alto_notes:\n",
    "    alto_note = note.Note(int(pitch.item()))\n",
    "    alto_part.append(alto_note)\n",
    "for pitch in tenor_notes:\n",
    "     tenor_note = note.Note(int(pitch.item()))\n",
    "     tenor_part.append(tenor_note)\n",
    "for pitch in bass_notes:\n",
    "    bass_note = note.Note(int(pitch.item()))\n",
    "    bass_part.append(bass_note)\n",
    "\n",
    "score.append(melody_part)\n",
    "score.append(alto_part)\n",
    "score.append(tenor_part)\n",
    "score.append(bass_part)\n",
    "score.show('midi')\n",
    "score.write('musicxml', 'output.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune (hyperparameters, move around test data (refer to notes), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new data + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet music + audio (musicAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new models if time permits (follow steps 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end ** if time permits\n",
    "# - Interactive sheet music\n",
    "# - musescore front end??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121de9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
