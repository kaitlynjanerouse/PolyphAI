{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d361ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary imports\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c67e7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chorale_198.csv\n",
      "chorale_173.csv\n",
      "chorale_167.csv\n",
      "chorale_007.csv\n",
      "chorale_013.csv\n",
      "chorale_239.csv\n",
      "chorale_205.csv\n",
      "chorale_211.csv\n",
      "chorale_210.csv\n",
      "chorale_204.csv\n",
      "chorale_238.csv\n",
      "chorale_012.csv\n",
      "chorale_006.csv\n",
      "chorale_166.csv\n",
      "chorale_172.csv\n",
      "chorale_199.csv\n",
      "chorale_158.csv\n",
      "chorale_164.csv\n",
      "chorale_170.csv\n",
      "chorale_038.csv\n",
      "chorale_010.csv\n",
      "chorale_004.csv\n",
      "chorale_212.csv\n",
      "chorale_206.csv\n",
      "chorale_207.csv\n",
      "chorale_213.csv\n",
      "chorale_005.csv\n",
      "chorale_011.csv\n",
      "chorale_039.csv\n",
      "chorale_171.csv\n",
      "chorale_165.csv\n",
      "chorale_159.csv\n",
      "chorale_161.csv\n",
      "chorale_175.csv\n",
      "chorale_149.csv\n",
      "chorale_015.csv\n",
      "chorale_001.csv\n",
      "chorale_029.csv\n",
      "chorale_217.csv\n",
      "chorale_203.csv\n",
      "chorale_202.csv\n",
      "chorale_216.csv\n",
      "chorale_028.csv\n",
      "chorale_000.csv\n",
      "chorale_014.csv\n",
      "chorale_148.csv\n",
      "chorale_174.csv\n",
      "chorale_160.csv\n",
      "chorale_189.csv\n",
      "chorale_176.csv\n",
      "chorale_162.csv\n",
      "chorale_002.csv\n",
      "chorale_016.csv\n",
      "chorale_200.csv\n",
      "chorale_214.csv\n",
      "chorale_228.csv\n",
      "chorale_229.csv\n",
      "chorale_215.csv\n",
      "chorale_201.csv\n",
      "chorale_017.csv\n",
      "chorale_003.csv\n",
      "chorale_163.csv\n",
      "chorale_177.csv\n",
      "chorale_188.csv\n",
      "chorale_312.csv\n",
      "chorale_306.csv\n",
      "chorale_138.csv\n",
      "chorale_110.csv\n",
      "chorale_104.csv\n",
      "chorale_058.csv\n",
      "chorale_064.csv\n",
      "chorale_070.csv\n",
      "chorale_071.csv\n",
      "chorale_065.csv\n",
      "chorale_059.csv\n",
      "chorale_105.csv\n",
      "chorale_111.csv\n",
      "chorale_139.csv\n",
      "chorale_307.csv\n",
      "chorale_313.csv\n",
      "chorale_339.csv\n",
      "chorale_305.csv\n",
      "chorale_311.csv\n",
      "chorale_107.csv\n",
      "chorale_113.csv\n",
      "chorale_098.csv\n",
      "chorale_073.csv\n",
      "chorale_067.csv\n",
      "chorale_259.csv\n",
      "chorale_265.csv\n",
      "chorale_264.csv\n",
      "chorale_258.csv\n",
      "chorale_066.csv\n",
      "chorale_072.csv\n",
      "chorale_099.csv\n",
      "chorale_112.csv\n",
      "chorale_106.csv\n",
      "chorale_310.csv\n",
      "chorale_338.csv\n",
      "chorale_314.csv\n",
      "chorale_328.csv\n",
      "chorale_102.csv\n",
      "chorale_116.csv\n",
      "chorale_089.csv\n",
      "chorale_076.csv\n",
      "chorale_062.csv\n",
      "chorale_260.csv\n",
      "chorale_248.csv\n",
      "chorale_249.csv\n",
      "chorale_261.csv\n",
      "chorale_063.csv\n",
      "chorale_077.csv\n",
      "chorale_088.csv\n",
      "chorale_117.csv\n",
      "chorale_103.csv\n",
      "chorale_329.csv\n",
      "chorale_315.csv\n",
      "chorale_317.csv\n",
      "chorale_115.csv\n",
      "chorale_101.csv\n",
      "chorale_129.csv\n",
      "chorale_061.csv\n",
      "chorale_075.csv\n",
      "chorale_049.csv\n",
      "chorale_263.csv\n",
      "chorale_262.csv\n",
      "chorale_048.csv\n",
      "chorale_074.csv\n",
      "chorale_060.csv\n",
      "chorale_128.csv\n",
      "chorale_100.csv\n",
      "chorale_114.csv\n",
      "chorale_316.csv\n",
      "chorale_333.csv\n",
      "chorale_327.csv\n",
      "chorale_119.csv\n",
      "chorale_131.csv\n",
      "chorale_125.csv\n",
      "chorale_086.csv\n",
      "chorale_092.csv\n",
      "chorale_079.csv\n",
      "chorale_045.csv\n",
      "chorale_051.csv\n",
      "chorale_247.csv\n",
      "chorale_253.csv\n",
      "chorale_252.csv\n",
      "chorale_246.csv\n",
      "chorale_050.csv\n",
      "chorale_044.csv\n",
      "chorale_078.csv\n",
      "chorale_093.csv\n",
      "chorale_087.csv\n",
      "chorale_124.csv\n",
      "chorale_130.csv\n",
      "chorale_118.csv\n",
      "chorale_326.csv\n",
      "chorale_332.csv\n",
      "chorale_318.csv\n",
      "chorale_324.csv\n",
      "chorale_330.csv\n",
      "chorale_126.csv\n",
      "chorale_132.csv\n",
      "chorale_091.csv\n",
      "chorale_085.csv\n",
      "chorale_052.csv\n",
      "chorale_046.csv\n",
      "chorale_250.csv\n",
      "chorale_244.csv\n",
      "chorale_245.csv\n",
      "chorale_251.csv\n",
      "chorale_047.csv\n",
      "chorale_053.csv\n",
      "chorale_084.csv\n",
      "chorale_090.csv\n",
      "chorale_133.csv\n",
      "chorale_127.csv\n",
      "chorale_331.csv\n",
      "chorale_325.csv\n",
      "chorale_319.csv\n",
      "chorale_321.csv\n",
      "chorale_335.csv\n",
      "chorale_309.csv\n",
      "chorale_123.csv\n",
      "chorale_137.csv\n",
      "chorale_094.csv\n",
      "chorale_080.csv\n",
      "chorale_057.csv\n",
      "chorale_043.csv\n",
      "chorale_255.csv\n",
      "chorale_241.csv\n",
      "chorale_240.csv\n",
      "chorale_254.csv\n",
      "chorale_042.csv\n",
      "chorale_056.csv\n",
      "chorale_081.csv\n",
      "chorale_095.csv\n",
      "chorale_136.csv\n",
      "chorale_122.csv\n",
      "chorale_308.csv\n",
      "chorale_334.csv\n",
      "chorale_320.csv\n",
      "chorale_336.csv\n",
      "chorale_322.csv\n",
      "chorale_134.csv\n",
      "chorale_120.csv\n",
      "chorale_108.csv\n",
      "chorale_083.csv\n",
      "chorale_097.csv\n",
      "chorale_040.csv\n",
      "chorale_054.csv\n",
      "chorale_068.csv\n",
      "chorale_242.csv\n",
      "chorale_256.csv\n",
      "chorale_257.csv\n",
      "chorale_243.csv\n",
      "chorale_069.csv\n",
      "chorale_055.csv\n",
      "chorale_041.csv\n",
      "chorale_096.csv\n",
      "chorale_082.csv\n",
      "chorale_109.csv\n",
      "chorale_121.csv\n",
      "chorale_135.csv\n",
      "chorale_323.csv\n",
      "chorale_337.csv\n",
      "chorale_191.csv\n",
      "chorale_185.csv\n",
      "chorale_152.csv\n",
      "chorale_146.csv\n",
      "chorale_026.csv\n",
      "chorale_032.csv\n",
      "chorale_218.csv\n",
      "chorale_224.csv\n",
      "chorale_230.csv\n",
      "chorale_231.csv\n",
      "chorale_225.csv\n",
      "chorale_219.csv\n",
      "chorale_033.csv\n",
      "chorale_027.csv\n",
      "chorale_147.csv\n",
      "chorale_153.csv\n",
      "chorale_184.csv\n",
      "chorale_190.csv\n",
      "chorale_186.csv\n",
      "chorale_192.csv\n",
      "chorale_179.csv\n",
      "chorale_145.csv\n",
      "chorale_151.csv\n",
      "chorale_019.csv\n",
      "chorale_031.csv\n",
      "chorale_025.csv\n",
      "chorale_233.csv\n",
      "chorale_227.csv\n",
      "chorale_226.csv\n",
      "chorale_232.csv\n",
      "chorale_024.csv\n",
      "chorale_030.csv\n",
      "chorale_018.csv\n",
      "chorale_150.csv\n",
      "chorale_144.csv\n",
      "chorale_178.csv\n",
      "chorale_193.csv\n",
      "chorale_187.csv\n",
      "chorale_342.csv\n",
      "chorale_183.csv\n",
      "chorale_197.csv\n",
      "chorale_140.csv\n",
      "chorale_154.csv\n",
      "chorale_168.csv\n",
      "chorale_034.csv\n",
      "chorale_020.csv\n",
      "chorale_008.csv\n",
      "chorale_236.csv\n",
      "chorale_222.csv\n",
      "chorale_223.csv\n",
      "chorale_237.csv\n",
      "chorale_009.csv\n",
      "chorale_021.csv\n",
      "chorale_035.csv\n",
      "chorale_169.csv\n",
      "chorale_155.csv\n",
      "chorale_141.csv\n",
      "chorale_196.csv\n",
      "chorale_182.csv\n",
      "chorale_341.csv\n",
      "chorale_194.csv\n",
      "chorale_180.csv\n",
      "chorale_157.csv\n",
      "chorale_143.csv\n",
      "chorale_023.csv\n",
      "chorale_037.csv\n",
      "chorale_221.csv\n",
      "chorale_235.csv\n",
      "chorale_209.csv\n",
      "chorale_208.csv\n",
      "chorale_234.csv\n",
      "chorale_220.csv\n",
      "chorale_036.csv\n",
      "chorale_022.csv\n",
      "chorale_142.csv\n",
      "chorale_156.csv\n",
      "chorale_181.csv\n",
      "chorale_195.csv\n",
      "chorale_340.csv\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "folder_path = 'Data/'\n",
    "test = []\n",
    "train = []\n",
    "validation = []\n",
    "for dirname in os.listdir(folder_path):\n",
    "    if dirname != '.DS_Store':\n",
    "        for filename in os.listdir(folder_path + dirname):\n",
    "            df = pd.read_csv(folder_path + dirname + '/' + filename)\n",
    "            transposed_df = df.transpose()\n",
    "            if dirname == 'test':\n",
    "                test.append(transposed_df)\n",
    "            if dirname == 'train':\n",
    "                print(filename)\n",
    "                train.append(transposed_df)\n",
    "            if dirname == 'valid':\n",
    "                validation.append(transposed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8606521",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim=50, n_layers=2):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        lstm_output, (h,c) = self.lstm(x, hidden)\n",
    "        model_output = self.fc(lstm_output)\n",
    "        return model_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09e503",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "511051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, melody, harmonies, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(melody)\n",
    "        loss = criterion(output, harmonies)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6e6252",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;241m1\u001b[39m, harmonies\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m train_model(model, melody, harmonies, optimizer, criterion, epoch)\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, melody, harmonies, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(melody)\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, harmonies)\n\u001b[0;32m----> 6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def normalize_array(array):\n",
    "    X_std = (array - 1) / (88 - 1)\n",
    "    return X_std\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "epoch = 5000\n",
    "# index = 0\n",
    "# for song in train:\n",
    "#     index = index + 1\n",
    "# print(\"training song \", index)\n",
    "song = train[0] # REMOVE\n",
    "melody = torch.tensor(normalize_array(song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1)\n",
    "harmonies = torch.tensor(normalize_array(song.iloc[1:].values.T), dtype=torch.float32).unsqueeze(0)\n",
    "model = Model(1, harmonies.shape[2])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_model(model, melody, harmonies, optimizer, criterion, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234bbe1-0257-4c91-a95f-263342853d92",
   "metadata": {},
   "source": [
    "# Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1d90b-1d91-4fcc-a156-6edcb721d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LR=0.01 and n_layers=1 and epochs=5000 and hidden_dims=20\n",
      "Epoch:  99 Loss:  tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1099 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1299 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1399 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1499 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1599 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1699 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1799 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1999 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2099 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2199 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2299 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2399 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2499 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2599 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2699 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2799 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2899 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2999 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3099 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3199 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3299 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3399 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3499 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3599 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3699 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3799 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3899 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3999 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4099 Loss:  tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4199 Loss:  tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4299 Loss:  tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4399 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4499 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4599 Loss:  tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4699 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4799 Loss:  tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4999 Loss:  tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "Final Loss: 0.001008842489682138\n",
      "Training with LR=0.01 and n_layers=1 and epochs=5000 and hidden_dims=40\n",
      "Epoch:  99 Loss:  tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1099 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1299 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1399 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1499 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1599 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1699 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1799 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1999 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2099 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2299 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2399 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2499 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2599 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2699 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2799 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2999 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3099 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3199 Loss:  tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3299 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3399 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3499 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3599 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3699 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3799 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4099 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4199 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4299 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4399 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4499 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4599 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4699 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4799 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4899 Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4999 Loss:  tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "Final Loss: 0.001759414910338819\n",
      "Training with LR=0.01 and n_layers=1 and epochs=5000 and hidden_dims=50\n",
      "Epoch:  99 Loss:  tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  199 Loss:  tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  299 Loss:  tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  399 Loss:  tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  499 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  599 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  699 Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  799 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  899 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1099 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1299 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1399 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1499 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1599 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1699 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1799 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1899 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1999 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2099 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2199 Loss:  tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2299 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2399 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2499 Loss:  tensor(0.0012, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning = [0.01]\n",
    "n_layers= [1,2,3]\n",
    "hidden_dim = [20, 40, 50]\n",
    "epochs= [5000]\n",
    "best_loss = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "\n",
    "for LR in learning:\n",
    "    for n_layer in n_layers:\n",
    "        for epoch in epochs:\n",
    "            for dims in hidden_dim:\n",
    "                print(f\"Training with LR={LR} and n_layers={n_layer} and epochs={epoch} and hidden_dims={dims}\")\n",
    "                model = Model(input_size=1, output_size=harmonies.shape[2], n_layers=n_layer, hidden_dim=dims)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "                train_model(model, melody, harmonies, optimizer, criterion, epoch)\n",
    "                with torch.no_grad():\n",
    "                    output = model(melody)\n",
    "                    loss = criterion(output, harmonies)\n",
    "                    print(f\"Final Loss: {loss.item()}\")        \n",
    "                # Keep track of the best model (with lowest loss)\n",
    "                if loss.item() < best_loss:\n",
    "                    best_loss = loss.item()\n",
    "                    best_params = {'learning': LR, 'n_layers': n_layer, 'epochs': epoch, 'hidden_dim': dims}\n",
    "print(\"BEST: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny = pd.DataFrame([[67,62,59,43], [68,62,59,43]]).transpose()\n",
    "# melody = torch.tensor(tiny.iloc[0], dtype=torch.float32).unsqueeze(0).reshape(1,2,1)\n",
    "# harmonies = torch.transpose(torch.tensor(tiny.iloc[1:].values, dtype=torch.float32),0,1).unsqueeze(0)\n",
    "# model = Model(1, harmonies.shape[2])\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# train_model(model, melody, harmonies, optimizer, criterion, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9e5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61.095417 56.924927 54.46692 ]\n",
      " [61.014168 56.7711   53.724888]\n",
      " [60.44572  58.62881  52.711792]\n",
      " [62.53965  60.53779  54.853046]\n",
      " [63.99973  61.251896 56.412106]\n",
      " [64.87079  61.464905 57.12958 ]\n",
      " [65.510666 61.479866 57.326504]\n",
      " [65.92501  61.339745 57.130173]\n",
      " [65.9298   60.97728  56.46874 ]\n",
      " [66.10088  60.748188 55.78679 ]\n",
      " [66.09665  60.409225 54.94975 ]\n",
      " [66.04195  60.099987 54.084164]\n",
      " [65.307495 59.4517   52.766994]\n",
      " [65.102196 59.18179  51.8057  ]\n",
      " [64.726326 58.784256 50.872303]\n",
      " [64.417465 58.502865 50.11869 ]\n",
      " [64.126114 58.271908 49.52571 ]\n",
      " [63.8862   58.115723 49.09307 ]\n",
      " [64.364265 58.379658 49.254307]\n",
      " [64.227554 58.318356 49.15157 ]\n",
      " [64.592316 58.66139  49.409008]\n",
      " [64.579834 58.7856   49.50655 ]\n",
      " [64.66163  59.033802 49.68127 ]\n",
      " [64.71213  59.243088 49.86792 ]\n",
      " [64.4366   59.2615   49.8342  ]\n",
      " [64.49109  59.440975 49.973137]\n",
      " [64.46853  59.490444 50.057434]\n",
      " [64.477646 59.53987  50.131577]\n",
      " [63.825466 59.194214 49.706882]\n",
      " [63.818176 59.20762  49.59432 ]\n",
      " [63.672497 59.01965  49.391716]\n",
      " [63.60034  58.886417 49.21307 ]\n",
      " [65.87004  60.01756  50.69577 ]\n",
      " [65.788765 59.813187 50.95223 ]\n",
      " [66.19861  60.317825 51.49727 ]\n",
      " [66.333916 60.61682  51.983315]\n",
      " [65.85336  60.613758 52.061092]\n",
      " [66.0221   60.94632  52.494625]\n",
      " [66.018196 61.02718  52.81239 ]\n",
      " [66.09133  61.132317 53.12117 ]\n",
      " [65.52544  60.82335  52.89662 ]\n",
      " [65.614876 60.87942  52.94481 ]\n",
      " [65.53382  60.708492 52.826275]\n",
      " [65.527466 60.59361  52.683   ]\n",
      " [65.18378  60.27207  52.249786]\n",
      " [65.150185 60.145607 51.949245]\n",
      " [65.03046  59.929817 51.591583]\n",
      " [64.94347  59.76101  51.257767]\n",
      " [64.84829  59.602077 50.94438 ]\n",
      " [64.76093  59.472458 50.67039 ]\n",
      " [64.68068  59.369583 50.44043 ]\n",
      " [64.61107  59.294636 50.256416]\n",
      " [64.881775 59.42539  50.351334]\n",
      " [64.83602  59.389675 50.31348 ]\n",
      " [64.87001  59.46781  50.34547 ]\n",
      " [64.875336 59.528885 50.389404]\n",
      " [64.89143  59.605015 50.456123]\n",
      " [64.9068   59.67645  50.532627]\n",
      " [64.92398  59.74261  50.613613]\n",
      " [64.941025 59.799564 50.693012]\n",
      " [65.612946 60.208622 51.243526]\n",
      " [65.61252  60.22096  51.444874]\n",
      " [65.7614   60.424953 51.731983]\n",
      " [65.82658  60.551674 51.987663]\n",
      " [65.90196  60.685047 52.248978]\n",
      " [65.96365  60.79014  52.494884]\n",
      " [66.0223   60.87613  52.723236]\n",
      " [66.07612  60.940823 52.928017]\n",
      " [66.75346  61.341328 53.581696]\n",
      " [66.75461  61.331078 53.87383 ]\n",
      " [66.917595 61.51399  54.256767]\n",
      " [66.9855   61.60667  54.592113]\n",
      " [67.068596 61.709896 54.92828 ]\n",
      " [67.13705  61.78451  55.24091 ]\n",
      " [67.20474  61.844368 55.530987]\n",
      " [67.268715 61.886948 55.793053]\n",
      " [66.74439  61.578117 55.56769 ]\n",
      " [66.87123  61.652126 55.64658 ]\n",
      " [66.819824 61.510326 55.56905 ]\n",
      " [66.852745 61.44091  55.487206]\n",
      " [66.26978  61.0017   54.8933  ]\n",
      " [66.31079  60.94743  54.584606]\n",
      " [66.1701   60.694397 54.131325]\n",
      " [66.095146 60.517014 53.687935]\n",
      " [65.681076 60.15094  52.99324 ]\n",
      " [65.568726 59.9904   52.46859 ]\n",
      " [65.37043  59.754944 51.927486]\n",
      " [65.20891  59.577713 51.451267]\n",
      " [65.04745  59.42072  51.033737]\n",
      " [64.904205 59.301216 50.688644]\n",
      " [64.779434 59.21466  50.414333]\n",
      " [64.67619  59.160007 50.206238]\n",
      " [63.940086 58.774406 49.58968 ]\n",
      " [63.86739  58.7827   49.36273 ]\n",
      " [63.682785 58.62562  49.11473 ]\n",
      " [63.5861   58.540676 48.936306]\n",
      " [65.86733  59.73385  50.44797 ]\n",
      " [65.77197  59.585217 50.71551 ]\n",
      " [66.1735   60.147606 51.273624]\n",
      " [66.311554 60.501965 51.786488]\n",
      " [65.82956  60.541798 51.895412]\n",
      " [66.00169  60.90924  52.36591 ]\n",
      " [65.99947  61.014153 52.71942 ]\n",
      " [66.07406  61.13579  53.060116]\n",
      " [65.50927  60.837135 52.862625]\n",
      " [65.601906 60.900208 52.933784]\n",
      " [65.21727  60.557526 52.59981 ]\n",
      " [65.21915  60.453594 52.389706]\n",
      " [65.11364  60.218132 52.065414]\n",
      " [65.044106 60.025192 51.729477]\n",
      " [64.95637  59.830093 51.382053]\n",
      " [64.869385 59.660034 51.05446 ]\n",
      " [66.410255 60.41425  51.9477  ]\n",
      " [66.30393  60.2453   52.039047]\n",
      " [66.5732   60.59873  52.398846]\n",
      " [66.64088  60.807987 52.73645 ]\n",
      " [66.10671  60.717007 52.67192 ]\n",
      " [66.22993  60.981705 52.969563]\n",
      " [66.18933  61.014465 53.16336 ]\n",
      " [66.2334   61.08799  53.366013]\n",
      " [65.6445   60.76052  53.05328 ]\n",
      " [65.71024  60.804493 53.02834 ]\n",
      " [65.60795  60.629356 52.852783]\n",
      " [65.58191  60.5145   52.66722 ]\n",
      " [65.220505 60.19665  52.205196]\n",
      " [65.172165 60.076077 51.887753]\n",
      " [65.04097  59.86831  51.52333 ]\n",
      " [64.945496 59.70858  51.19028 ]\n",
      " [64.844894 59.559383 50.88295 ]\n",
      " [64.75454  59.43943  50.618023]\n",
      " [64.67322  59.345688 50.398346]\n",
      " [64.60384  59.2789   50.224545]\n",
      " [64.87585  59.41665  50.328857]\n",
      " [64.8313   59.386414 50.29883 ]\n",
      " [64.86664  59.468796 50.3373  ]\n",
      " [64.87323  59.532795 50.386448]\n",
      " [64.890396 59.610737 50.45718 ]\n",
      " [64.90659  59.683044 50.536568]\n",
      " [64.92436  59.749367 50.61944 ]\n",
      " [64.94185  59.805973 50.699867]\n",
      " [65.61387  60.214314 51.250713]\n",
      " [65.613556 60.225784 51.452007]\n",
      " [65.76251  60.42886  51.73878 ]\n",
      " [65.82768  60.55464  51.99384 ]\n",
      " [65.90304  60.68718  52.2544  ]\n",
      " [65.964676 60.791573 52.49947 ]\n",
      " [66.02326  60.876976 52.72697 ]\n",
      " [66.07701  60.941227 52.930935]\n",
      " [66.75423  61.341385 53.58387 ]\n",
      " [66.755295 61.33091  53.875374]\n",
      " [66.91819  61.513657 54.25777 ]\n",
      " [66.986015 61.60627  54.592678]\n",
      " [67.06904  61.709465 54.92851 ]\n",
      " [67.13739  61.784084 55.24085 ]\n",
      " [67.20501  61.84398  55.530743]\n",
      " [67.26893  61.886593 55.792686]\n",
      " [66.74454  61.577812 55.56724 ]\n",
      " [66.87131  61.651875 55.646084]\n",
      " [66.81986  61.51011  55.56854 ]\n",
      " [66.85273  61.440727 55.4867  ]\n",
      " [66.26973  61.001556 54.89281 ]\n",
      " [66.310715 60.947315 54.584145]\n",
      " [65.87265  60.522476 53.90035 ]\n",
      " [65.80237  60.35227  53.374603]\n",
      " [65.61661  60.07016  52.774647]\n",
      " [65.46237  59.84546  52.208515]\n",
      " [65.29101  59.632744 51.67753 ]\n",
      " [65.12626  59.457542 51.21131 ]\n",
      " [64.97136  59.31786  50.819283]\n",
      " [64.83428  59.215958 50.504993]\n",
      " [64.71843  59.149197 50.26414 ]\n",
      " [64.625    59.113617 50.088505]\n",
      " [63.897167 58.744965 49.501278]\n",
      " [63.834793 58.768692 49.30158 ]\n",
      " [63.659252 58.62337  49.07617 ]\n",
      " [63.570023 58.54704  48.91493 ]\n",
      " [63.490295 58.468857 48.781307]\n",
      " [63.43381  58.413494 48.680416]\n",
      " [63.391373 58.37399  48.605698]\n",
      " [63.361347 58.350365 48.553493]]\n",
      "[61.095417 61.014168 60.44572  62.53965  63.99973  64.87079  65.510666\n",
      " 65.92501  65.9298   66.10088  66.09665  66.04195  65.307495 65.102196\n",
      " 64.726326 64.417465 64.126114 63.8862   64.364265 64.227554 64.592316\n",
      " 64.579834 64.66163  64.71213  64.4366   64.49109  64.46853  64.477646\n",
      " 63.825466 63.818176 63.672497 63.60034  65.87004  65.788765 66.19861\n",
      " 66.333916 65.85336  66.0221   66.018196 66.09133  65.52544  65.614876\n",
      " 65.53382  65.527466 65.18378  65.150185 65.03046  64.94347  64.84829\n",
      " 64.76093  64.68068  64.61107  64.881775 64.83602  64.87001  64.875336\n",
      " 64.89143  64.9068   64.92398  64.941025 65.612946 65.61252  65.7614\n",
      " 65.82658  65.90196  65.96365  66.0223   66.07612  66.75346  66.75461\n",
      " 66.917595 66.9855   67.068596 67.13705  67.20474  67.268715 66.74439\n",
      " 66.87123  66.819824 66.852745 66.26978  66.31079  66.1701   66.095146\n",
      " 65.681076 65.568726 65.37043  65.20891  65.04745  64.904205 64.779434\n",
      " 64.67619  63.940086 63.86739  63.682785 63.5861   65.86733  65.77197\n",
      " 66.1735   66.311554 65.82956  66.00169  65.99947  66.07406  65.50927\n",
      " 65.601906 65.21727  65.21915  65.11364  65.044106 64.95637  64.869385\n",
      " 66.410255 66.30393  66.5732   66.64088  66.10671  66.22993  66.18933\n",
      " 66.2334   65.6445   65.71024  65.60795  65.58191  65.220505 65.172165\n",
      " 65.04097  64.945496 64.844894 64.75454  64.67322  64.60384  64.87585\n",
      " 64.8313   64.86664  64.87323  64.890396 64.90659  64.92436  64.94185\n",
      " 65.61387  65.613556 65.76251  65.82768  65.90304  65.964676 66.02326\n",
      " 66.07701  66.75423  66.755295 66.91819  66.986015 67.06904  67.13739\n",
      " 67.20501  67.26893  66.74454  66.87131  66.81986  66.85273  66.26973\n",
      " 66.310715 65.87265  65.80237  65.61661  65.46237  65.29101  65.12626\n",
      " 64.97136  64.83428  64.71843  64.625    63.897167 63.834793 63.659252\n",
      " 63.570023 63.490295 63.43381  63.391373 63.361347]\n",
      "Adding for alto\n",
      "61.095417\n",
      "<music21.note.Note C#>\n",
      "Adding for alto\n",
      "61.014168\n",
      "<music21.note.Note C#>\n",
      "Adding for alto\n",
      "60.44572\n",
      "<music21.note.Note C>\n",
      "Adding for alto\n",
      "62.53965\n",
      "<music21.note.Note D>\n",
      "Adding for alto\n",
      "63.99973\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "64.87079\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "65.510666\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.92501\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.9298\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.10088\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.09665\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.04195\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.307495\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.102196\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "64.726326\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.417465\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.126114\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "63.8862\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "64.364265\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.227554\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.592316\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.579834\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.66163\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.71213\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.4366\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.49109\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.46853\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.477646\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "63.825466\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.818176\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.672497\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.60034\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "65.87004\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.788765\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.19861\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.333916\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.85336\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.0221\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.018196\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.09133\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.52544\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.614876\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.53382\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.527466\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.18378\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.150185\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.03046\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "64.94347\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.84829\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.76093\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.68068\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.61107\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.881775\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.83602\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.87001\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.875336\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.89143\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.9068\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.92398\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.941025\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "65.612946\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.61252\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.7614\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.82658\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.90196\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.96365\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.0223\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.07612\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.75346\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.75461\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.917595\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.9855\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "67.068596\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "67.13705\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "67.20474\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "67.268715\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "66.74439\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.87123\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.819824\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.852745\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.26978\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.31079\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.1701\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.095146\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.681076\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.568726\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.37043\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.20891\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.04745\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "64.904205\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.779434\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.67619\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "63.940086\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.86739\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.682785\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.5861\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "65.86733\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.77197\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.1735\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.311554\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.82956\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.00169\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.99947\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.07406\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.50927\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.601906\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.21727\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.21915\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.11364\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.044106\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "64.95637\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.869385\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "66.410255\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.30393\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.5732\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.64088\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.10671\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.22993\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.18933\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.2334\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.6445\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.71024\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.60795\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.58191\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.220505\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.172165\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.04097\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "64.945496\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.844894\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.75454\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.67322\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.60384\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.87585\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.8313\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.86664\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.87323\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.890396\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.90659\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.92436\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.94185\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "65.61387\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.613556\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.76251\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.82768\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.90304\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.964676\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "66.02326\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.07701\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.75423\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.755295\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.91819\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.986015\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "67.06904\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "67.13739\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "67.20501\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "67.26893\n",
      "<music21.note.Note G>\n",
      "Adding for alto\n",
      "66.74454\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.87131\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.81986\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.85273\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.26973\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "66.310715\n",
      "<music21.note.Note F#>\n",
      "Adding for alto\n",
      "65.87265\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.80237\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.61661\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.46237\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.29101\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "65.12626\n",
      "<music21.note.Note F>\n",
      "Adding for alto\n",
      "64.97136\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.83428\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.71843\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "64.625\n",
      "<music21.note.Note E>\n",
      "Adding for alto\n",
      "63.897167\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.834793\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.659252\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.570023\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.490295\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.43381\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.391373\n",
      "<music21.note.Note E->\n",
      "Adding for alto\n",
      "63.361347\n",
      "<music21.note.Note E->\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv103555\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv103555_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv103555\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,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\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv103555_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv103555_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kaitlynrouse/370-Fall-2024/PolyphAI/Code/output.xml')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverse_array(array):\n",
    "    X_scaled = array * (88 - 1) + 1\n",
    "    print(X_scaled)\n",
    "    return X_scaled\n",
    "\n",
    "melody = train[0].iloc[0]\n",
    "# melody = torch.tensor((song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1)\n",
    "# print(\"melody is: \", torch.tensor(normalize_array(song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1))\n",
    "result = model(torch.tensor(normalize_array(song.iloc[0].values.reshape(-1,1)), dtype=torch.float32).unsqueeze(0).reshape(1,song.shape[1],1))\n",
    "result_numpy = result.detach().numpy()\n",
    "inversed = inverse_array(np.squeeze(result_numpy)).T\n",
    "# print(\"RESULT IS: \", inversed)\n",
    "\n",
    "score = stream.Score()\n",
    "melody_part = stream.Part()\n",
    "alto_part = stream.Part()\n",
    "tenor_part = stream.Part()\n",
    "bass_part = stream.Part()\n",
    "\n",
    "for pitch in melody:\n",
    "    melody_note = note.Note(int(pitch), quarterLength=0.25)\n",
    "    melody_part.append(melody_note)\n",
    "\n",
    "alto_notes = inversed[0]\n",
    "print(alto_notes)\n",
    "tenor_notes = inversed[1]\n",
    "bass_notes = inversed[2]  \n",
    "\n",
    "for pitch in alto_notes:\n",
    "    print(\"Adding for alto\")\n",
    "    print(pitch)\n",
    "    alto_note = note.Note(int(pitch.item()), quarterLength=0.25)\n",
    "    print(alto_note)\n",
    "    alto_part.append(alto_note)\n",
    "for pitch in tenor_notes:\n",
    "    tenor_note = note.Note(int(pitch.item()), quarterLength=0.25)\n",
    "    tenor_part.append(tenor_note)\n",
    "for pitch in bass_notes:\n",
    "    bass_note = note.Note(int(pitch.item()), quarterLength=0.25)\n",
    "    bass_part.append(bass_note)\n",
    "score.append(melody_part)\n",
    "score.append(alto_part)\n",
    "score.append(tenor_part)\n",
    "score.append(bass_part)\n",
    "score.show('midi')\n",
    "score.write('musicxml', 'output.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune (hyperparameters, move around test data (refer to notes), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new data + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet music + audio (musicAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new models if time permits (follow steps 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end ** if time permits\n",
    "# - Interactive sheet music\n",
    "# - musescore front end??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121de9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
